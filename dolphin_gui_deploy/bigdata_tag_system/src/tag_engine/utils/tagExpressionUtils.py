#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡ç­¾è¡¨è¾¾å¼æž„å»ºå·¥å…·
ä¸“é—¨å¤„ç†å¹¶è¡Œæ ‡ç­¾è®¡ç®—çš„è¡¨è¾¾å¼æž„å»ºé€»è¾‘ - ä½¿ç”¨æ¨¡å—çº§å‡½æ•°é¿å…åºåˆ—åŒ–é—®é¢˜
"""
from pyspark.sql.functions import *


def buildParallelTagExpression(tagConditions):
    """æž„å»ºå¹¶è¡Œæ ‡ç­¾è®¡ç®—è¡¨è¾¾å¼ - TagGroupæ ¸å¿ƒä¼˜åŒ–é€»è¾‘
    
    å°†å¤šä¸ªæ ‡ç­¾æ¡ä»¶ç»„åˆæˆä¸€ä¸ªå¹¶è¡Œè®¡ç®—è¡¨è¾¾å¼ï¼Œä¸€æ¬¡æ€§è¯„ä¼°æ‰€æœ‰æ ‡ç­¾
    åœ¨Driverç«¯æ‰§è¡Œï¼Œè¿”å›žSpark Columnè¡¨è¾¾å¼ï¼Œå®Œå…¨é¿å…Pythonå¯¹è±¡åºåˆ—åŒ–
    
    Args:
        tagConditions: List[Dict] - æ ‡ç­¾æ¡ä»¶åˆ—è¡¨
            [{'tag_id': 1, 'condition': 'user_basic_info.age >= 30'},
             {'tag_id': 2, 'condition': 'user_asset_summary.total_assets >= 10000'}, ...]
            
    Returns:
        Column - å¹¶è¡Œæ ‡ç­¾æ•°ç»„è¡¨è¾¾å¼ï¼Œå¯ç›´æŽ¥ç”¨äºŽDataFrame.withColumn()
        
    Example:
        >>> conditions = [
        ...     {'tag_id': 1, 'condition': 'user_basic_info.age >= 30'},
        ...     {'tag_id': 2, 'condition': 'user_asset_summary.total_assets >= 10000'}
        ... ]
        >>> expr = buildParallelTagExpression(conditions)
        >>> df.withColumn("tag_ids_array", expr)
    """
    if not tagConditions:
        return array()
    
    # ðŸš€ æžç®€æ–¹æ¡ˆï¼šç›´æŽ¥ä½¿ç”¨TagRuleParserç”Ÿæˆçš„SQLæ¡ä»¶æž„å»ºCASE WHENè¡¨è¾¾å¼
    case_expressions = []
    for tagInfo in tagConditions:
        tag_id = tagInfo['tag_id']
        condition = tagInfo['condition']
        # TagRuleParserå·²ç»ç”Ÿæˆäº†å®Œæ•´çš„SQLæ¡ä»¶ï¼Œç›´æŽ¥ä½¿ç”¨
        case_expressions.append(f"case when {condition} then {tag_id} else null end")
    
    # æž„å»ºæœ€ç»ˆçš„å¹¶è¡Œæ ‡ç­¾æ•°ç»„è¡¨è¾¾å¼
    sql_expr = f"""
    array_distinct(
        array_sort(
            filter(
                array({', '.join(case_expressions)}), 
                x -> x is not null
            )
        )
    )
    """.strip().replace('\n', ' ').replace('    ', ' ')
    
    return expr(sql_expr)