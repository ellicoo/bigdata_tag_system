# 🐬 海豚调度器标签系统部署指南

## 📦 部署包内容
- `main.py` - 主程序入口（直接来自 src/tag_engine/main.py）
- `src/` - 项目源码（PySpark DSL + UDF架构）  
- `generate_test_data.py` - 测试数据生成器
- `create_test_tables.sql` - 测试表创建SQL
- `requirements.txt` - Python依赖

## 🚀 快速部署步骤

### 1. 上传部署包
1. 登录海豚调度器Web界面
2. 进入 **资源中心** → **文件管理**
3. 上传 `tag_system_dolphin.zip`

### 2. 解压部署包
**任务名称**: `unzip_deploy_package`  
**任务类型**: Shell  
**脚本内容**:
```bash
#!/bin/bash
cd /dolphinscheduler/default/resources/
unzip -o bigdata_tag_system.zip -d bigdata_tag_system/
chmod +x /dolphinscheduler/default/resources/bigdata_tag_system/main.py
chmod -R 755 /dolphinscheduler/default/resources/bigdata_tag_system/
echo "✅ 部署包解压完成到: /dolphinscheduler/default/resources/bigdata_tag_system/"
ls -la bigdata_tag_system/main.py bigdata_tag_system/src/
```

### 3. 安装Python依赖
**任务名称**: `install_dependencies`  
**任务类型**: Shell  
**依赖**: `unzip_deploy_package`
**脚本内容**:
```bash
#!/bin/bash
cd /dolphinscheduler/default/resources/bigdata_tag_system/

# 检查Python环境
python3 --version
pip3 --version

# 安装核心依赖
echo "📦 开始安装Python依赖包..."
pip3 install --user -r requirements.txt

# 验证关键依赖
echo "🔍 验证核心依赖安装..."
python3 -c "import pyspark; print(f'✅ PySpark版本: {pyspark.__version__}')"
python3 -c "import pymysql; print('✅ PyMySQL安装成功')"
python3 -c "import pandas; print(f'✅ Pandas版本: {pandas.__version__}')"

echo "✅ Python依赖安装完成"
```

### 4. 创建标签计算工作流
创建工作流名称：`标签系统完整流程`

## 📋 工作流任务配置

### 任务A: 生成测试数据 🧪
- **任务名称**: `generate_test_data`
- **任务类型**: Spark
- **依赖**: `install_dependencies`
- **部署模式**: local
- **主程序**: `/dolphinscheduler/default/resources/bigdata_tag_system/main.py`
- **主程序参数**: `--mode generate-test-data`
- **Driver内存**: 1g
- **Executor数量**: 1
- **作用**: 生成测试用户数据到Hive表

### 任务B: 系统健康检查 ⚡
- **任务名称**: `health_check`
- **任务类型**: Spark
- **依赖**: `generate_test_data`
- **部署模式**: local
- **主程序**: `/dolphinscheduler/default/resources/bigdata_tag_system/main.py`
- **主程序参数**: `--mode health`
- **Driver内存**: 1g
- **Executor数量**: 1
- **作用**: 验证MySQL、Hive连接和UDF函数

### 任务C: 全量标签计算 🏷️
- **任务名称**: `full_compute_tags`
- **任务类型**: Spark
- **依赖**: `health_check`
- **部署模式**: client
- **主程序**: `bigdata_tag_system/src/tag_engine/main.py`
- **资源文件**: 
  - ✅ 选择 `bigdata_tag_system` (整个项目目录)
- **主程序参数**: `--mode task-all`
- **其他参数**: `--jars s3://exchanges-flink-test/dolphinscheduler/default/resources/connectors/mysql-connector-j-8.0.33.jar`
- **Driver内存**: 2g
- **Executor数量**: 2
- **Executor内存**: 4g
- **作用**: 计算所有用户的所有标签并写入MySQL

### 任务D: 指定标签计算 🎯
- **任务名称**: `specific_compute_tags`
- **任务类型**: Spark
- **依赖**: `full_compute_tags`
- **部署模式**: client
- **主程序**: `bigdata_tag_system/src/tag_engine/main.py`
- **资源文件**: 
  - ✅ 选择 `bigdata_tag_system` (整个项目目录)
- **主程序参数**: `--mode task-tags --tag-ids 1,2,3,5,10`
- **其他参数**: `--jars s3://exchanges-flink-test/dolphinscheduler/default/resources/connectors/mysql-connector-j-8.0.33.jar`
- **Driver内存**: 2g
- **Executor数量**: 2
- **Executor内存**: 4g
- **作用**: 计算指定标签并验证标签合并逻辑

### 任务E: 列出所有标签 📋
- **任务名称**: `list_all_tags`
- **任务类型**: Spark
- **依赖**: `specific_compute_tags`
- **部署模式**: local
- **主程序**: `/dolphinscheduler/default/resources/bigdata_tag_system/main.py`
- **主程序参数**: `--mode list-tasks`
- **Driver内存**: 1g
- **Executor数量**: 1
- **作用**: 列出所有可用标签任务

## 🎯 支持的执行模式

### 生成测试数据
```bash
--mode generate-test-data
```
生成1000条用户测试数据到Hive表

### 健康检查
```bash
--mode health
```
验证MySQL、Hive连接和UDF函数

### 全量标签计算
```bash
--mode task-all
```
计算所有用户的所有50个标签

### 指定标签计算
```bash
--mode task-tags --tag-ids 1,2,3,5,10
```
计算指定用户的指定标签

### 列出标签任务
```bash
--mode list-tasks
```
查看所有可用的50个标签定义

## ⚙️ Spark任务通用配置

### 本地模式配置（推荐）
- **部署模式**: local
- **Driver核心数**: 1
- **Driver内存**: 1g-2g
- **Executor数量**: 1-2
- **Executor核心数**: 2
- **Executor内存**: 2g-4g
- **失败重试次数**: 2
- **任务超时**: 30分钟

### 集群模式配置（生产环境）
- **部署模式**: cluster
- **Driver核心数**: 2
- **Driver内存**: 4g
- **Executor数量**: 5
- **Executor核心数**: 2
- **Executor内存**: 8g
- **YARN队列**: default

## 🔧 MySQL连接配置

系统通过环境变量配置MySQL连接：
```bash
export MYSQL_HOST="cex-mysql-test.c5mgk4qm8m2z.ap-southeast-1.rds.amazonaws.com"
export MYSQL_PORT="3358"
export MYSQL_DATABASE="biz_statistics"
export MYSQL_USER="root"
export MYSQL_PASSWORD="ayjUzzH8b7gcQYRh"
```

### JDBC连接参数
- **字符编码**: 使用 `connectionCollation=utf8mb4_unicode_ci`
- **SSL**: 禁用 `useSSL=false`
- **时区**: 设置 `serverTimezone=UTC`

## 📊 数据模型说明

### 标签数据结构
- **50个标签定义**：覆盖数值、字符串、日期、布尔、枚举、列表等所有数据类型
- **10个标签分类**：用户价值、行为特征、风险等级、生命周期等
- **用户标签存储**：一个用户一条记录，标签ID存储为JSON数组

### 测试数据规模
- **用户数据**: 1000个测试用户
- **标签规则**: 50条完整规则
- **数据表**: user_basic_info, user_asset_summary, user_activity_summary

## 💡 最佳实践

### 1. 首次部署
1. 先运行 `install_dependencies` 安装Python依赖
2. 然后运行 `generate_test_data` 生成测试数据
3. 再运行 `health_check` 验证环境
4. 最后进行标签计算任务

### 2. 参数化配置
工作流中可使用全局参数：
- `tag_ids`: 指定标签ID列表
- `mode`: 执行模式选择

### 3. 监控建议
- 查看Spark UI监控资源使用情况：http://driver:4040
- 监控MySQL标签数据增长
- 定期执行健康检查验证系统状态

## 🚨 故障排除

### MySQL连接问题
```
❌ java.sql.SQLException: Unsupported character encoding 'utf8mb4'
```
**解决**: 已修复JDBC连接参数为 `connectionCollation=utf8mb4_unicode_ci`

### Python依赖问题
```
❌ ModuleNotFoundError: No module named 'pyspark'
```
**解决**: 确保先运行 `install_dependencies` 任务安装所有依赖

### Hive表访问问题
- 确保测试数据已生成：先运行 `generate_test_data` 任务
- 检查表分区：确认 `dt` 分区数据存在

### 性能调优
- **小数据量**: 使用local模式，1-2个Executor
- **大数据量**: 使用cluster模式，增加Executor数量和内存

## 📈 扩展配置

### 生产环境建议
- 使用cluster部署模式
- 增加Driver和Executor内存配置
- 配置YARN资源队列
- 设置合适的并行度参数

### 自定义标签
- 修改 `environments/local/init_database.sql` 添加新标签
- 重新初始化MySQL数据库
- 运行 `list-tasks` 验证新标签加载