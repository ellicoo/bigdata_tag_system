# å¤§æ•°æ®æ ‡ç­¾ç³»ç»Ÿ

åŸºäºPySparkçš„åˆ†å¸ƒå¼æ ‡ç­¾è®¡ç®—ç³»ç»Ÿï¼Œä½¿ç”¨DSLå’ŒSparkå†…ç½®å‡½æ•°ä»S3 Hiveè¡¨è¯»å–ç”¨æˆ·æ•°æ®ï¼Œç»“åˆMySQLè§„åˆ™è¿›è¡Œæ ‡ç­¾è®¡ç®—ï¼Œä¸“ä¸ºæµ·è±šè°ƒåº¦å™¨éƒ¨ç½²è®¾è®¡ã€‚

## é¡¹ç›®æ¶æ„

### æ ¸å¿ƒç‰¹æ€§
- PySpark DSL + Sparkå†…ç½®å‡½æ•°ï¼šå……åˆ†åˆ©ç”¨Spark DataFrame APIå’Œå†…ç½®å‡½æ•°ï¼Œé¿å…é›†ç¾¤ç‰ˆæœ¬å…¼å®¹é—®é¢˜
- æ™ºèƒ½å¹¶è¡Œå¤„ç†ï¼šåŸºäºè¡¨ä¾èµ–å…³ç³»çš„æ™ºèƒ½åˆ†ç»„å’Œå¹¶å‘è®¡ç®—  
- æ ‡ç­¾åˆå¹¶æœºåˆ¶ï¼šæ”¯æŒæ–°è€æ ‡ç­¾æ™ºèƒ½åˆå¹¶ï¼Œé¿å…æ•°æ®ä¸¢å¤±
- æµ·è±šè°ƒåº¦å™¨é›†æˆï¼šåŸç”Ÿæ”¯æŒDolphinScheduleréƒ¨ç½²å’Œè°ƒåº¦
- å¤šç¯å¢ƒæ”¯æŒï¼šæœ¬åœ°å¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒæ— ç¼åˆ‡æ¢

### æŠ€æœ¯æ ˆ
- è®¡ç®—å¼•æ“ï¼šPySpark 3.5+ (Spark SQL + DataFrame API)
- æ•°æ®æºï¼šS3 Hive Tables (Parquetæ ¼å¼)  
- è§„åˆ™å­˜å‚¨ï¼šMySQL (JSONæ ¼å¼è§„åˆ™)
- è°ƒåº¦ç³»ç»Ÿï¼šDolphinScheduler
- éƒ¨ç½²æ–¹å¼ï¼šYARN Clusteræ¨¡å¼

## é¡¹ç›®ç»“æ„

```
src/tag_engine/
â”œâ”€â”€ main.py                 # å‘½ä»¤è¡Œå…¥å£ï¼Œæ”¯æŒå¤šç§æ‰§è¡Œæ¨¡å¼
â”œâ”€â”€ engine/                 # æ ¸å¿ƒè®¡ç®—å¼•æ“
â”‚   â”œâ”€â”€ TagEngine.py       # ä¸»ç¼–æ’å¼•æ“ï¼Œå·¥ä½œæµåè°ƒ
â”‚   â””â”€â”€ TagGroup.py        # æ™ºèƒ½åˆ†ç»„ï¼ŒåŸºäºè¡¨ä¾èµ–çš„å¹¶è¡Œå¤„ç†
â”œâ”€â”€ meta/                  # æ•°æ®æºç®¡ç†
â”‚   â”œâ”€â”€ HiveMeta.py        # Hiveè¡¨æ“ä½œï¼Œæ™ºèƒ½ç¼“å­˜ä¸ä¼˜åŒ–
â”‚   â””â”€â”€ MysqlMeta.py       # MySQLè§„åˆ™å’Œç»“æœç®¡ç†
â”œâ”€â”€ parser/                # è§„åˆ™è§£æä¸SQLç”Ÿæˆ
â”‚   â””â”€â”€ TagRuleParser.py   # JSONè§„åˆ™è½¬SQLæ¡ä»¶
â””â”€â”€ utils/                 # å·¥å…·å‡½æ•°å’ŒSparkå†…ç½®å‡½æ•°å°è£…
    â”œâ”€â”€ SparkUdfs.py       # Sparkå†…ç½®å‡½æ•°å·¥å…·åŒ–å°è£…ï¼ˆé¿å…é›†ç¾¤ç‰ˆæœ¬é—®é¢˜ï¼‰
    â””â”€â”€ tagExpressionUtils.py  # å¹¶è¡Œæ ‡ç­¾è¡¨è¾¾å¼æ„å»ºå·¥å…·
```

## å¿«é€Ÿå¼€å§‹

### æœ¬åœ°å¼€å‘ç¯å¢ƒ

```bash
# 1. å¯åŠ¨æœ¬åœ°ç¯å¢ƒ (MySQL + MinIO)
cd environments/local
./setup.sh

# 2. åˆå§‹åŒ–æ•°æ®åº“å’Œæµ‹è¯•æ•°æ®
./init_data.sh

# 3. è¿è¡Œå¥åº·æ£€æŸ¥
cd ../../
python src/tag_engine/main.py --mode health

# 4. æ‰§è¡Œå…¨é‡æ ‡ç­¾è®¡ç®—
python src/tag_engine/main.py --mode task-all

# 5. è®¡ç®—æŒ‡å®šæ ‡ç­¾
python src/tag_engine/main.py --mode task-tags --tag-ids 1,2,3
```

### æµ·è±šè°ƒåº¦å™¨éƒ¨ç½²

```bash
# 1. ç”Ÿæˆéƒ¨ç½²åŒ…
python dolphin_deploy_package.py

# 2. ä¸Šä¼ åˆ°DolphinSchedulerèµ„æºä¸­å¿ƒ
# å°†ç”Ÿæˆçš„ dolphin_gui_deploy/tag_system_dolphin.zip ä¸Šä¼ åˆ°æµ·è±šè°ƒåº¦å™¨èµ„æºç®¡ç†

# 3. åˆ›å»ºSparkä»»åŠ¡
# ä¸»ç¨‹åº: /dolphinscheduler/default/resources/bigdata_tag_system/main.py
# ç¨‹åºå‚æ•°: --mode task-all
# è¯´æ˜: main.pyæ˜¯ç”±dolphin_deploy_package.pyä»src/tag_engine/main.pyè‡ªåŠ¨ç”Ÿæˆ
```

## æ ¸å¿ƒåŠŸèƒ½

### 1. æ™ºèƒ½æ ‡ç­¾åˆ†ç»„ä¸å¹¶è¡Œè®¡ç®— (TagGroup.py)

ç³»ç»Ÿæ ¹æ®æ ‡ç­¾è§„åˆ™çš„è¡¨ä¾èµ–å…³ç³»è¿›è¡Œæ™ºèƒ½åˆ†ç»„ï¼Œå®ç°æœ€ä¼˜å¹¶è¡Œè®¡ç®—ï¼š

#### **åˆ†ç»„ç­–ç•¥ç¤ºä¾‹**
```python
# ç»„1: æ ‡ç­¾[1,2,3] â†’ ä¾èµ–è¡¨[user_basic_info, user_asset_summary]  
# ç»„2: æ ‡ç­¾[4,5] â†’ ä¾èµ–è¡¨[user_activity_summary]
# ç»„3: æ ‡ç­¾[6] â†’ ä¾èµ–è¡¨[user_basic_info, user_activity_summary]
```

#### **ç»„å†…å¹¶è¡Œè®¡ç®—æ‰§è¡Œæµç¨‹å¯è§†åŒ–**

```
ç¬¬1æ­¥ï¼šJOINåçš„ç”¨æˆ·æ•°æ® (ç»„å†…å…±äº«)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ user_id â”‚ age â”‚ assets â”‚ trade_count â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ user001 â”‚ 35  â”‚ 15000  â”‚ 8           â”‚
â”‚ user002 â”‚ 25  â”‚ 5000   â”‚ 2           â”‚
â”‚ user003 â”‚ 40  â”‚ 8000   â”‚ 12          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç¬¬2æ­¥ï¼šæ ‡ç­¾è§„åˆ™å¹¶è¡Œè§£æ
- æ ‡ç­¾1: age >= 30      (é«˜é¾„ç”¨æˆ·)
- æ ‡ç­¾2: assets >= 10000 (é«˜å‡€å€¼ç”¨æˆ·) 
- æ ‡ç­¾3: trade_count > 5 (æ´»è·ƒäº¤æ˜“ç”¨æˆ·)

ç¬¬3æ­¥ï¼šå¹¶è¡Œæ ‡ç­¾è¡¨è¾¾å¼æ„å»º (å…³é”®ä¼˜åŒ–)
# ä½¿ç”¨tagExpressionUtilså·¥å…·æ„å»ºå¹¶è¡Œè¡¨è¾¾å¼ï¼š
from ..utils.tagExpressionUtils import buildParallelTagExpression

tagConditions = [
    {'tag_id': 1, 'condition': 'age >= 30'},
    {'tag_id': 2, 'condition': 'assets >= 10000'}, 
    {'tag_id': 3, 'condition': 'trade_count > 5'}
]
combined_tags_expr = buildParallelTagExpression(tagConditions)

# å†…éƒ¨ä½¿ç”¨SQLè¡¨è¾¾å¼å’Œfilteré«˜é˜¶å‡½æ•°ç¡®ä¿è¿”å›ç©ºæ•°ç»„è€Œénull

ç¬¬4æ­¥ï¼šæ¯è¡Œå¹¶è¡Œè®¡ç®—ç»“æœ
user001: [when(35>=30,1)â†’1, when(15000>=10000,2)â†’2, when(8>5,3)â†’3] 
         â†’ array_remove([1,2,3], null) â†’ [1,2,3]

user002: [when(25>=30,1)â†’null, when(5000>=10000,2)â†’null, when(2>5,3)â†’null]
         â†’ array_remove([null,null,null], null) â†’ [] (è¢«è¿‡æ»¤)

user003: [when(40>=30,1)â†’1, when(8000>=10000,2)â†’null, when(12>5,3)â†’3]
         â†’ array_remove([1,null,3], null) â†’ [1,3]

ç¬¬5æ­¥ï¼šæœ€ç»ˆèšåˆç»“æœ (ä¸€æ­¥åˆ°ä½)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ user_id â”‚ tag_ids_array â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ user001 â”‚ [1, 2, 3]     â”‚  â† åŒ¹é…3ä¸ªæ ‡ç­¾
â”‚ user003 â”‚ [1, 3]        â”‚  â† åŒ¹é…2ä¸ªæ ‡ç­¾  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **æ€§èƒ½ä¼˜åŠ¿**
- âš¡ **çœŸæ­£å¹¶è¡Œ**ï¼šæ‰€æœ‰æ ‡ç­¾æ¡ä»¶åœ¨åŒä¸€DataFrameæ“ä½œä¸­å¹¶è¡Œè¯„ä¼°
- ğŸ”„ **ä¸€æ¬¡æ‰«æ**ï¼šé¿å…é‡å¤è¯»å–JOINåçš„æ•°æ®ï¼Œæ˜¾è‘—æå‡I/Oæ•ˆç‡
- ğŸ¯ **ç›´æ¥èšåˆ**ï¼šæ— éœ€ä¸­é—´ç»“æœæ”¶é›†ï¼Œä¸€æ­¥ç”Ÿæˆç”¨æˆ·æ ‡ç­¾æ•°ç»„
- ğŸš€ **SparkåŸç”Ÿä¼˜åŒ–**ï¼šå……åˆ†åˆ©ç”¨CatalystæŸ¥è¯¢ä¼˜åŒ–å™¨å’Œé›†ç¾¤å¹¶è¡Œèƒ½åŠ›

### 2. PySpark DSLåº”ç”¨

å……åˆ†åˆ©ç”¨Spark DataFrame APIè¿›è¡Œåˆ†å¸ƒå¼è®¡ç®—ï¼š

```python
# Hiveè¡¨æ™ºèƒ½ç¼“å­˜å’ŒJOIN
cachedDF = spark.sql(f"SELECT * FROM {table_name}") \
               .persist(StorageLevel.MEMORY_AND_DISK)

# æ ‡ç­¾æ¡ä»¶è¿‡æ»¤
tagDF = joinedDF.filter(expr(sqlCondition)) \
               .select("user_id") \
               .withColumn("tag_id", lit(tagId))

# ğŸš€ å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨å¹¶è¡Œæ ‡ç­¾è¡¨è¾¾å¼å·¥å…·ï¼Œä¸€æ¬¡æ€§ç”Ÿæˆæ ‡ç­¾æ•°ç»„
from src.tag_engine.utils.tagExpressionUtils import buildParallelTagExpression

# æ„å»ºå¹¶è¡Œæ ‡ç­¾æ¡ä»¶
tag_conditions = [
    {'tag_id': 1, 'condition': 'age >= 30'},
    {'tag_id': 2, 'condition': 'assets >= 10000'}
]

# ä¸€æ¬¡æ€§å¹¶è¡Œè®¡ç®—æ‰€æœ‰æ ‡ç­¾
combined_expr = buildParallelTagExpression(tag_conditions)
userTagsDF = joinedDF.select("user_id") \
                   .withColumn("tag_ids_array", combined_expr) \
                   .filter(size(col("tag_ids_array")) > 0)
```

### 3. æ™ºèƒ½æ ‡ç­¾åˆå¹¶æœºåˆ¶

ç³»ç»Ÿé‡‡ç”¨**Sparkå†…ç½®å‡½æ•°å·¥å…·åŒ–åŒ…è£…**ç­–ç•¥ï¼Œé¿å…é›†ç¾¤å¤šç‰ˆæœ¬é—®é¢˜ï¼Œç¡®ä¿ç±»å‹å®‰å…¨å’Œé«˜æ€§èƒ½ï¼š

#### å†…å­˜æ ‡ç­¾åˆå¹¶ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
```python
# ä½¿ç”¨Sparkå†…ç½®å‡½æ•°è¿›è¡Œæ ‡ç­¾åˆå¹¶ï¼Œé¿å…UDFåºåˆ—åŒ–å¼€é”€
finalDF = mergedDF.groupBy("user_id").agg(
    array_distinct(
        array_sort(
            flatten(collect_list("tag_ids_array"))
        )
    ).alias("merged_tag_ids")
)
```

#### Sparkå†…ç½®å‡½æ•°å·¥å…·åŒ–åŒ…è£…ï¼ˆé¿å…é›†ç¾¤å¤šç‰ˆæœ¬é—®é¢˜ï¼‰
```python

def merge_with_existing_tags(new_tags_col, existing_tags_col):
    """æ–°è€æ ‡ç­¾æ™ºèƒ½åˆå¹¶ - ä½¿ç”¨Sparkå†…ç½®å‡½æ•°
    è‡ªåŠ¨å¤„ç†nullå€¼ï¼Œé¿å…é›†ç¾¤ç¯å¢ƒä¸‹çš„Pythonå¯¹è±¡åºåˆ—åŒ–é—®é¢˜
    """
    new_tags = coalesce(new_tags_col, array())
    existing_tags = coalesce(existing_tags_col, array())
    return array_distinct(array_sort(array_union(new_tags, existing_tags)))

def array_to_json(array_col):
    """æ•°ç»„è½¬JSON - ä½¿ç”¨Sparkå†…ç½®å‡½æ•°"""
    return coalesce(to_json(array_col), lit('[]'))

def json_to_array(json_col):
    """JSONè½¬æ•°ç»„ - ä½¿ç”¨Sparkå†…ç½®å‡½æ•°"""
    return coalesce(from_json(json_col, ArrayType(IntegerType())), array())
```

**å…³é”®ä¼˜åŠ¿**ï¼š
- âœ… **é¿å…é›†ç¾¤ç‰ˆæœ¬é—®é¢˜**ï¼šä¸ä½¿ç”¨ä¼ ç»Ÿ@udfè£…é¥°å™¨ï¼Œé¿å…Driverå’ŒExecutorçš„Pythonç‰ˆæœ¬å†²çª
- âœ… **æ— åºåˆ—åŒ–å¼€é”€**ï¼šSparkå†…ç½®å‡½æ•°ç›´æ¥åœ¨JVMä¸­æ‰§è¡Œï¼Œæ— Pythonå¯¹è±¡åºåˆ—åŒ–
- âœ… **é›†ç¾¤å…¼å®¹æ€§**ï¼šé€‚ç”¨äºå¼‚æ„é›†ç¾¤ç¯å¢ƒï¼Œä¸ä¾èµ–ç‰¹å®šPythonç‰ˆæœ¬
- âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šå……åˆ†åˆ©ç”¨Spark Catalystä¼˜åŒ–å™¨å’Œå‘é‡åŒ–æ‰§è¡Œ

### 4. JSONè§„åˆ™ç³»ç»Ÿ

æ”¯æŒå¤æ‚çš„ä¸šåŠ¡è§„åˆ™å®šä¹‰ï¼š

```json
{
  "logic": "AND",
  "conditions": [
    {
      "fields": [
        {
          "table": "user_basic_info",
          "field": "age",
          "operator": ">=", 
          "value": 30,
          "type": "number"
        },
        {
          "table": "user_asset_summary", 
          "field": "total_assets",
          "operator": ">=",
          "value": 100000,
          "type": "number"
        }
      ]
    }
  ]
}
```

## æ€§èƒ½ä¼˜åŒ–

### 1. æ™ºèƒ½ç¼“å­˜ç­–ç•¥
- **è¡¨çº§ç¼“å­˜**ï¼šé¢‘ç¹è®¿é—®çš„Hiveè¡¨ç¼“å­˜åˆ°å†…å­˜ï¼Œä½¿ç”¨`persist(StorageLevel.MEMORY_AND_DISK)`
- **åˆ†åŒºä¼˜åŒ–**ï¼šåŠ¨æ€è°ƒæ•´åˆ†åŒºæ•°æå‡å¹¶è¡Œåº¦ï¼Œé¿å…å°æ–‡ä»¶é—®é¢˜
- **å­—æ®µæŠ•å½±**ï¼šåªåŠ è½½å¿…è¦å­—æ®µå‡å°‘I/Oï¼Œä½¿ç”¨`select()`ç²¾ç¡®é€‰æ‹©å­—æ®µ

### 2. ç±»å‹å®‰å…¨ä¸æ€§èƒ½å¹¶é‡
- **Sparkå†…ç½®å‡½æ•°ä¼˜å…ˆ**ï¼šä½¿ç”¨`array_distinct`ã€`array_sort`ã€`array_union`ã€`coalesce`ç­‰åŸç”Ÿå‡½æ•°
- **å·¥å…·åŒ–åŒ…è£…ç­–ç•¥**ï¼šå°†Sparkå†…ç½®å‡½æ•°å°è£…ä¸ºå·¥å…·å‡½æ•°ï¼Œæä¾›ç»Ÿä¸€æ¥å£
- **åºåˆ—åŒ–ä¼˜åŒ–**ï¼šå®Œå…¨é¿å…ä¼ ç»ŸUDFï¼Œæ¶ˆé™¤Python-JVMåºåˆ—åŒ–å¼€é”€å’Œé›†ç¾¤ç‰ˆæœ¬å†²çª

### 3. å¹¶è¡Œå¤„ç†ä¼˜åŒ–  
- **ä¾èµ–åˆ†æ**ï¼šåŸºäºè¡¨ä¾èµ–å…³ç³»çš„æ™ºèƒ½åˆ†ç»„ï¼Œæœ€å°åŒ–JOINæ“ä½œ
- **æ‰¹é‡è®¡ç®—**ï¼šåŒç»„æ ‡ç­¾å¹¶è¡Œè®¡ç®—ï¼Œå…±äº«è¡¨è¯»å–å’ŒJOINç»“æœ
- **èµ„æºç®¡ç†**ï¼šåˆç†çš„Sparkèµ„æºé…ç½®å’Œå†…å­˜ç®¡ç†

### 4. é«˜æ€§èƒ½åˆ†å¸ƒå¼å†™å…¥æ¶æ„

ç³»ç»Ÿé‡‡ç”¨**ä¸´æ—¶è¡¨+MySQLå†…éƒ¨UPSERT**çš„åˆ›æ–°æ¶æ„ï¼Œå®ç°æœ€å°åŒ–ç½‘ç»œä¼ è¾“çš„é«˜æ€§èƒ½åˆ†å¸ƒå¼å†™å…¥ã€‚

#### **ä¸¤é˜¶æ®µå†™å…¥æ¨¡å¼**

**é˜¶æ®µ1ï¼šåˆ†å¸ƒå¼å†™å…¥MySQLä¸´æ—¶è¡¨**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    JDBCå†™å…¥    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Executor-1  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚   MySQLä¸´æ—¶è¡¨         â”‚
â”‚ Executor-2  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ user_tags_temp_xxx   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚                      â”‚
â”‚ Executor-3  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ (è‡ªåŠ¨åˆ›å»º+æ•°æ®å†™å…¥)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ•°æ®æµï¼šSpark Executors â†’ MySQLä¸´æ—¶è¡¨ (åˆ†å¸ƒå¼å¹¶è¡Œå†™å…¥)
```

**æ ¸å¿ƒå®ç°**ï¼š
```python
# æ¯æ¬¡ç”Ÿæˆå”¯ä¸€ä¸´æ—¶è¡¨åï¼Œé¿å…å†²çª
temp_table = f"user_tags_temp_{int(time.time())}"

# Sparkåˆ†å¸ƒå¼JDBCå†™å…¥ï¼Œå„Executorç›´æ¥è¿MySQL
resultsDF.select("user_id", col("final_tag_ids_json").alias("tag_id_list")) \
    .write \
    .format("jdbc") \
    .option("url", self.jdbcUrl) \
    .option("dbtable", temp_table) \
    .mode("overwrite") \  # åˆ é™¤+åˆ›å»º+æ’å…¥ï¼Œç¡®ä¿å¹²å‡€ç¯å¢ƒ
    .save()
```

**é˜¶æ®µ2ï¼šMySQLå†…éƒ¨æ•°æ®è½¬ç§»**
```
MySQLå†…éƒ¨æ“ä½œï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    SELECT + UPSERT    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ä¸´æ—¶è¡¨              â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚   ä¸šåŠ¡è¡¨              â”‚
â”‚ user_tags_temp_xxx   â”‚                      â”‚ user_tag_relation    â”‚
â”‚                      â”‚    (æ•°æ®ä¸ç¦»å¼€MySQL)   â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ•°æ®æµï¼šMySQLä¸´æ—¶è¡¨ â†’ MySQLä¸šåŠ¡è¡¨ (æ•°æ®åº“å†…éƒ¨æ“ä½œï¼Œæ— ç½‘ç»œå¼€é”€)
```

**æ ¸å¿ƒå®ç°**ï¼š
```python
def _executeSimpleUpsert(self, temp_table: str, record_count: int) -> bool:
    connection = pymysql.connect(**self.mysqlConfig)  # Driverå•ç‚¹è¿æ¥
    
    # å¤æ‚UPSERTé€»è¾‘åœ¨MySQLå†…éƒ¨æ‰§è¡Œ
    upsert_sql = f"""
    INSERT INTO user_tag_relation (user_id, tag_id_list)
    SELECT user_id, tag_id_list FROM {temp_table}
    ON DUPLICATE KEY UPDATE
        updated_time = CASE 
            WHEN JSON_EXTRACT(user_tag_relation.tag_id_list, '$') <> JSON_EXTRACT(VALUES(tag_id_list), '$')
            THEN CURRENT_TIMESTAMP 
            ELSE user_tag_relation.updated_time 
        END,
        tag_id_list = VALUES(tag_id_list)
    """
    
    cursor.execute(upsert_sql)  # å•ä¸ªSQLå¤„ç†æ‰€æœ‰æ•°æ®
```

#### **æ¶æ„ä¼˜åŠ¿å¯¹æ¯”**

| æ–¹æ¡ˆ | ç½‘ç»œå¾€è¿” | Driverå†…å­˜ | å¹¶å‘å†™å…¥ | å¤æ‚UPSERT |
|------|----------|------------|----------|------------|
| é€è¡ŒUPSERT | Næ¬¡ | é«˜å‹åŠ› | âŒ | âœ… |
| Sparkç›´å†™ | 1æ¬¡ | ä½å‹åŠ› | âœ… | âŒ |
| **ä¸´æ—¶è¡¨æ–¹æ¡ˆ** | **1æ¬¡** | **ä½å‹åŠ›** | **âœ…** | **âœ…** |

#### **æ€§èƒ½ç¤ºä¾‹**
å‡è®¾å¤„ç†100ä¸‡æ¡æ ‡ç­¾ç»“æœï¼š
```python
# é˜¶æ®µ1: Sparkåˆ†å¸ƒå¼å†™å…¥ (å‡è®¾4ä¸ªåˆ†åŒº)
Executor-1: å†™å…¥25ä¸‡è¡Œåˆ° user_tags_temp_1691234567
Executor-2: å†™å…¥25ä¸‡è¡Œåˆ° user_tags_temp_1691234567  
Executor-3: å†™å…¥25ä¸‡è¡Œåˆ° user_tags_temp_1691234567
Executor-4: å†™å…¥25ä¸‡è¡Œåˆ° user_tags_temp_1691234567

# é˜¶æ®µ2: MySQLå†…éƒ¨UPSERT (å•ä¸ªé«˜æ•ˆæ“ä½œ)
INSERT INTO user_tag_relation (user_id, tag_id_list)
SELECT user_id, tag_id_list FROM user_tags_temp_1691234567
ON DUPLICATE KEY UPDATE ...
-- å¤„ç†100ä¸‡è¡Œï¼Œä½†æ•°æ®ä¸ç¦»å¼€MySQLæœåŠ¡å™¨

# é˜¶æ®µ3: æ¸…ç†ä¸´æ—¶è¡¨
DROP TABLE user_tags_temp_1691234567
```

#### **å…³é”®åˆ›æ–°ç‚¹**
- âœ… **æ•°æ®æœ¬åœ°æ€§**ï¼šæœ€å°åŒ–æ•°æ®ä¼ è¾“ï¼Œåˆ©ç”¨MySQLå†…éƒ¨ä¼˜åŒ–
- âœ… **åˆ†å¸ƒå¼èƒ½åŠ›**ï¼šå……åˆ†åˆ©ç”¨Sparké›†ç¾¤çš„å¹¶è¡Œå†™å…¥èƒ½åŠ›
- âœ… **å¤æ‚é€»è¾‘æ”¯æŒ**ï¼šæ”¯æŒJSONæ¯”è¾ƒã€æ¡ä»¶æ›´æ–°ç­‰å¤æ‚ä¸šåŠ¡é€»è¾‘
- âœ… **é«˜å¯é æ€§**ï¼šäº‹åŠ¡ä¿è¯ã€è‡ªåŠ¨æ¸…ç†ã€é”™è¯¯æ¢å¤æœºåˆ¶

### 5. ä¼ ç»Ÿæ•°æ®å†™å…¥ä¼˜åŒ–
- **æ‰¹é‡UPSERT**ï¼šé«˜æ•ˆçš„MySQLæ‰¹é‡æ›´æ–°ï¼Œæ”¯æŒæ ‡ç­¾åˆå¹¶
- **æ ‡ç­¾åˆå¹¶ç®—æ³•**ï¼š
  ```
  å†…å­˜åˆå¹¶: Array[Array[Int]] â†’ flatten â†’ Array[Int] â†’ distinct â†’ sort
  MySQLåˆå¹¶: newTags + existingTags â†’ merge â†’ deduplicate â†’ JSON
  ```
- **æ—¶é—´æˆ³ç®¡ç†**ï¼šç²¾ç¡®çš„åˆ›å»ºå’Œæ›´æ–°æ—¶é—´è¿½è¸ªï¼Œæ”¯æŒå¹‚ç­‰æ“ä½œ

### 6. æ¶æ„ä¼˜åŒ–äº®ç‚¹
- **é›¶æ•°æ®ä¸¢å¤±**ï¼šæ™ºèƒ½æ ‡ç­¾åˆå¹¶ï¼Œæ–°è€æ ‡ç­¾å®Œç¾èåˆ
- **ç±»å‹å…¼å®¹**ï¼šæ”¯æŒ`List[int]`ã€`Array[int]`ã€åµŒå¥—æ•°ç»„ç­‰å¤šç§ç±»å‹
- **é”™è¯¯æ¢å¤**ï¼šå•ä¸ªæ ‡ç­¾ç»„å¤±è´¥ä¸å½±å“å…¶ä»–ç»„è®¡ç®—
- **èµ„æºæ¸…ç†**ï¼šè‡ªåŠ¨ç¼“å­˜æ¸…ç†å’ŒSparkä¼šè¯ç®¡ç†

## æ‰§è¡Œæ¨¡å¼

ç³»ç»Ÿæ”¯æŒå¤šç§æ‰§è¡Œæ¨¡å¼ï¼Œé€‚é…ä¸åŒä¸šåŠ¡åœºæ™¯ï¼š

| æ¨¡å¼ | å‘½ä»¤ | è¯´æ˜ |
|------|------|------|
| å¥åº·æ£€æŸ¥ | --mode health | æ£€æŸ¥Hiveå’ŒMySQLè¿æ¥çŠ¶æ€ |
| å…¨é‡è®¡ç®— | --mode task-all | è®¡ç®—æ‰€æœ‰æ¿€æ´»æ ‡ç­¾ |
| æŒ‡å®šæ ‡ç­¾ | --mode task-tags --tag-ids 1,2,3 | è®¡ç®—æŒ‡å®šæ ‡ç­¾ID |
| æµ‹è¯•æ•°æ®ç”Ÿæˆ | --mode generate-test-data --dt 2025-01-20 | ç”Ÿæˆæµ‹è¯•æ•°æ® |
| ä»»åŠ¡åˆ—è¡¨ | --mode list-tasks | åˆ—å‡ºå¯ç”¨æ ‡ç­¾ä»»åŠ¡ |

## æµ·è±šè°ƒåº¦å™¨é›†æˆ

### éƒ¨ç½²é…ç½®

```python
# environments/dolphinscheduler/config.py
class DolphinschedulerConfig(BaseConfig):
    def __init__(self):
        super().__init__(
            environment='dolphinscheduler',
            spark=SparkConfig(
                app_name="BigDataTagSystem-Dolphin",
                master="yarn",
                executor_memory="4g",
                driver_memory="2g",
                executor_cores=2,
                num_executors=10
            )
        )
```

### ä»»åŠ¡è°ƒåº¦ç¤ºä¾‹

```bash
# æµ·è±šè°ƒåº¦å™¨Sparkä»»åŠ¡é…ç½®
ä¸»ç¨‹åº: /dolphinscheduler/default/resources/bigdata_tag_system/main.py
ç¨‹åºå‚æ•°: --mode task-all
éƒ¨ç½²æ¨¡å¼: cluster  
é©±åŠ¨ç¨‹åºå†…å­˜: 2g
æ‰§è¡Œå™¨å†…å­˜: 4g
æ‰§è¡Œå™¨æ•°é‡: 10

# æ³¨æ„: main.pyæ˜¯ä»src/tag_engine/main.pyåŠ¨æ€ç”Ÿæˆçš„ç»Ÿä¸€å…¥å£
```

## æ•°æ®æµæ¶æ„

```
S3 Hive Tables â†’ TagEngine â†’ Smart Grouping â†’ Parallel Computation â†’ Tag Merging â†’ MySQL Results
     â†“              â†“            â†“                   â†“                â†“             â†“
  ç”¨æˆ·æ•°æ®        è§„åˆ™åŠ è½½      ä¾èµ–åˆ†æ           å¹¶è¡Œæ ‡ç­¾è®¡ç®—         ç»“æœåˆå¹¶      æŒä¹…åŒ–å­˜å‚¨
```

### æ•°æ®æ¨¡å‹

è¾“å…¥æ•°æ®:
- user_basic_info: ç”¨æˆ·åŸºç¡€ä¿¡æ¯ (å¹´é¾„ã€æ€§åˆ«ã€æ³¨å†Œæ—¶é—´ç­‰)
- user_asset_summary: ç”¨æˆ·èµ„äº§æ±‡æ€» (æ€»èµ„äº§ã€ç°é‡‘ä½™é¢ç­‰)  
- user_activity_summary: ç”¨æˆ·æ´»åŠ¨æ±‡æ€» (äº¤æ˜“æ¬¡æ•°ã€ç™»å½•æ—¶é—´ç­‰)

è¾“å‡ºç»“æœ:
- user_tagsè¡¨: user_id â†’ tag_ids (JSONæ•°ç»„æ ¼å¼: [1,2,3,5])

## ç›‘æ§å’Œè¿ç»´

### ç³»ç»Ÿå¥åº·æ£€æŸ¥
```bash
python src/tag_engine/main.py --mode health
```

è¾“å‡ºç¤ºä¾‹:
```
[INFO] Hiveè¿æ¥çŠ¶æ€: âœ“ æ­£å¸¸ (3ä¸ªè¡¨å¯ç”¨)
[INFO] MySQLè¿æ¥çŠ¶æ€: âœ“ æ­£å¸¸ (5ä¸ªæ¿€æ´»æ ‡ç­¾)
[INFO] ç³»ç»Ÿå†…å­˜ä½¿ç”¨: 2.1GB / 8GB  
[INFO] Sparkæ‰§è¡Œå™¨çŠ¶æ€: 10ä¸ªæ‰§è¡Œå™¨æ­£å¸¸è¿è¡Œ
```

### æ€§èƒ½æŒ‡æ ‡
- è®¡ç®—é€Ÿåº¦ï¼š100ä¸‡ç”¨æˆ· Ã— 10ä¸ªæ ‡ç­¾ â‰ˆ 5-8åˆ†é’Ÿ
- å†…å­˜æ•ˆç‡ï¼šæ™ºèƒ½ç¼“å­˜ + åˆ†åŒºä¼˜åŒ–ï¼Œå†…å­˜ä½¿ç”¨ç‡ < 70%
- å‡†ç¡®æ€§ï¼šæ ‡ç­¾åˆå¹¶é›¶ä¸¢å¤±ï¼Œæ”¯æŒå¹‚ç­‰æ“ä½œ

## æµ‹è¯•æ¡†æ¶

### æµ‹è¯•æ¶æ„
é¡¹ç›®é‡‡ç”¨ **pytest + PySpark** æµ‹è¯•æ¡†æ¶ï¼Œæä¾›å®Œæ•´çš„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•èƒ½åŠ›ã€‚

### æµ‹è¯•è¿è¡Œ

#### 1. è¿è¡Œå…¨éƒ¨æµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆæ¨èï¼‰
python -m pytest tests/ -v

# å¸¦è¦†ç›–ç‡æŠ¥å‘Š
python -m pytest tests/ -v --cov=src/tag_engine --cov-report=html
```

#### 2. è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
```bash
# è§„åˆ™è§£æå™¨æµ‹è¯•
python -m pytest tests/test_rule_parser.py -v

# æ ‡ç­¾åˆ†ç»„æµ‹è¯•  
python -m pytest tests/test_tag_grouping.py -v

# è¿è¡Œç‰¹å®šæµ‹è¯•ç”¨ä¾‹
python -m pytest tests/test_rule_parser.py::TestTagRuleParser::test_not_logic -v
```

#### 3. æµ‹è¯•ç»“æœç¤ºä¾‹
```
======================== test session starts ========================
tests/test_rule_parser.py::TestTagRuleParser::test_init PASSED [  4%]
tests/test_rule_parser.py::TestTagRuleParser::test_simple_number_condition_sql_generation PASSED [  9%]
tests/test_rule_parser.py::TestTagRuleParser::test_complex_multi_condition_and_logic PASSED [ 36%]
tests/test_rule_parser.py::TestTagRuleParser::test_not_logic PASSED [ 45%]
tests/test_tag_grouping.py::TestTagGrouping::test_analyze_dependencies_single_table PASSED [ 68%]
tests/test_tag_grouping.py::TestTagGrouping::test_group_tags_complex_scenario PASSED [ 90%]
======================== 22 passed, 1 warning in 13.07s ========================
```

### æµ‹è¯•è¦†ç›–èŒƒå›´

#### **è§„åˆ™è§£æå™¨æµ‹è¯•** (14ä¸ªæµ‹è¯•ç”¨ä¾‹)
- âœ… **åŸºç¡€åŠŸèƒ½**: åˆå§‹åŒ–ã€SQLç”Ÿæˆã€æ¡ä»¶è§£æ
- âœ… **æ•°æ®ç±»å‹**: æ•°å€¼ã€å­—ç¬¦ä¸²ã€æšä¸¾ã€æ—¥æœŸã€å¸ƒå°”æ¡ä»¶
- âœ… **æ“ä½œç¬¦æ”¯æŒ**: `=`, `!=`, `>=`, `<=`, `LIKE`, `IN`, `BETWEEN`, `IS NULL` ç­‰
- âœ… **å¤æ‚é€»è¾‘**: AND/OR/NOT åµŒå¥—æ¡ä»¶ã€å­—æ®µé€»è¾‘ä¼˜å…ˆçº§
- âœ… **å­—ç¬¦ä¸²åŒ¹é…**: `contains`, `starts_with`, `ends_with` æ¨¡å¼
- âœ… **åˆ—è¡¨æ“ä½œ**: `contains_any`, `contains_all`, `array_contains`
- âœ… **å¼‚å¸¸å¤„ç†**: æ— æ•ˆJSONã€ç©ºè§„åˆ™ã€è¾¹ç•Œæƒ…å†µ

#### **æ ‡ç­¾åˆ†ç»„æµ‹è¯•** (8ä¸ªæµ‹è¯•ç”¨ä¾‹)  
- âœ… **ä¾èµ–åˆ†æ**: å•è¡¨ä¾èµ–ã€å¤šè¡¨ä¾èµ–ã€å­—æ®µä¾èµ–åˆ†æ
- âœ… **æ™ºèƒ½åˆ†ç»„**: ç›¸åŒè¡¨åˆ†ç»„ã€ä¸åŒè¡¨åˆ†ç»„ã€å¤æ‚åœºæ™¯ç»„åˆ
- âœ… **åˆ†ç»„ä¼˜åŒ–**: ä¾èµ–è¡¨ç»„åˆçš„å‡†ç¡®æ€§å’Œæ•ˆç‡éªŒè¯
- âœ… **è¾¹ç•Œå¤„ç†**: ç©ºè§„åˆ™ã€æ— æ•ˆè§„åˆ™çš„å¥å£®æ€§æµ‹è¯•

#### **æ ‡ç­¾è¡¨è¾¾å¼å·¥å…·æµ‹è¯•** (7ä¸ªæµ‹è¯•ç”¨ä¾‹)
- âœ… **å¹¶è¡Œè¡¨è¾¾å¼æ„å»º**: åŸºç¡€åŠŸèƒ½ã€å¤æ‚æ¡ä»¶ã€ä¸šåŠ¡é›†æˆæµ‹è¯•
- âœ… **ç©ºå€¼å¤„ç†**: ç©ºæ¡ä»¶åˆ—è¡¨ã€Noneæ¡ä»¶çš„è¾¹ç•Œæƒ…å†µ
- âœ… **å»é‡æ’åº**: é‡å¤æ ‡ç­¾å»é‡ã€æ ‡ç­¾IDè‡ªåŠ¨æ’åº
- âœ… **SQLè§£æ**: JOINåDataFrameçš„SQLæ¡ä»¶æ­£ç¡®è§£æ
- âœ… **ç±»å‹å®‰å…¨**: ç¡®ä¿è¿”å›ç©ºæ•°ç»„è€Œénullï¼Œæ”¯æŒä¸šåŠ¡è¿‡æ»¤é€»è¾‘

#### **SparkUdfsé›†æˆæµ‹è¯•** (7ä¸ªæµ‹è¯•ç”¨ä¾‹)
- âœ… **æ ‡ç­¾åˆå¹¶åŠŸèƒ½**: merge_with_existing_tagsæ–°è€æ ‡ç­¾åˆå¹¶æµ‹è¯•
- âœ… **JSONè½¬æ¢**: array_to_jsonã€json_to_arrayåŒå‘è½¬æ¢æµ‹è¯•
- âœ… **å¾€è¿”è½¬æ¢**: JSONå’Œæ•°ç»„çš„å®Œæ•´å¾€è¿”è½¬æ¢éªŒè¯
- âœ… **TagEngineé›†æˆ**: æ¨¡æ‹Ÿå®é™…TagEngineä½¿ç”¨åœºæ™¯
- âœ… **ç±»å‹å®‰å…¨**: å¤šç§è¾“å…¥ç±»å‹çš„å…¼å®¹æ€§å’Œé”™è¯¯å¤„ç†

### æµ‹è¯•æ•°æ®æ¨¡å‹

#### **æµ‹è¯•ç¯å¢ƒé…ç½®** (`tests/conftest.py`)
```python
@pytest.fixture(scope="session")
def spark():
    """æœ¬åœ°Sparkä¼šè¯ - æµ‹è¯•ä¼˜åŒ–é…ç½®"""
    return SparkSession.builder \
        .appName("TagSystem_Test") \
        .master("local[2]") \
        .config("spark.sql.adaptive.enabled", "false") \
        .getOrCreate()

@pytest.fixture  
def sample_user_data():
    """çœŸå®ä¸šåŠ¡åœºæ™¯æµ‹è¯•æ•°æ®"""
    return {
        "user_basic_info": [
            ("user001", 30, "VIP2", "verified", True),
            ("user002", 25, "VIP1", "verified", False),
            # ... æ›´å¤šæµ‹è¯•ç”¨æˆ·
        ],
        "user_asset_summary": [...],
        "user_activity_summary": [...]
    }
```

#### **å¤æ‚è§„åˆ™æµ‹è¯•ç”¨ä¾‹**
```python
# æµ‹è¯•é«˜å‡€å€¼ç”¨æˆ·æ ‡ç­¾ï¼ˆå¤šæ¡ä»¶ANDï¼‰
{
    "logic": "AND",
    "conditions": [
        {
            "condition": {
                "logic": "OR", 
                "fields": [
                    {"table": "user_basic_info", "field": "user_level", "operator": "belongs_to", "value": ["VIP2", "VIP3"]},
                    {"table": "user_asset_summary", "field": "total_asset_value", "operator": ">=", "value": "100000"}
                ]
            }
        },
        {
            "condition": {
                "logic": "AND",
                "fields": [
                    {"table": "user_basic_info", "field": "kyc_status", "operator": "=", "value": "verified"},
                    {"table": "user_activity_summary", "field": "trade_count_30d", "operator": ">", "value": "5"}
                ]
            }
        }
    ]
}
```

### æµ‹è¯•æœ€ä½³å®è·µ

#### **å•å…ƒæµ‹è¯•åŸåˆ™**
```python
def test_simple_number_condition_sql_generation(self):
    """æµ‹è¯•æ•°å€¼æ¡ä»¶SQLç”Ÿæˆ - è¦†ç›–å•è¡¨å’Œå¤šè¡¨åœºæ™¯"""
    parser = TagRuleParser()
    
    # æµ‹è¯•å¤šè¡¨åœºæ™¯
    sql = parser.parseRuleToSql(rule_json, ["user_asset_summary", "user_basic_info"])
    expected = "`tag_system.user_asset_summary`.`total_asset_value` >= 100000"
    assert expected in sql
    
    # æµ‹è¯•å•è¡¨åœºæ™¯  
    sql_single = parser.parseRuleToSql(rule_json, ["user_asset_summary"])
    expected_single = "`user_asset_summary`.`total_asset_value` >= 100000"
    assert expected_single in sql_single
```

#### **é›†æˆæµ‹è¯•ç­–ç•¥**
- **ä¾èµ–éš”ç¦»**: ä½¿ç”¨å†…å­˜DataFrameæ¨¡æ‹ŸHiveè¡¨ï¼Œé¿å…å¤–éƒ¨ä¾èµ–
- **æ•°æ®é©±åŠ¨**: å‚æ•°åŒ–æµ‹è¯•è¦†ç›–å¤šç§ä¸šåŠ¡åœºæ™¯
- **æ–­è¨€å®Œæ•´**: éªŒè¯SQLè¯­æ³•ã€é€»è¾‘ç»“æ„ã€è¾¹ç•Œæƒ…å†µ

### æŒç»­é›†æˆæ”¯æŒ

#### **GitHub Actionsé…ç½®**
```yaml
# .github/workflows/test.yml
name: Test Suite
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.12
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: python -m pytest tests/ -v --cov=src/tag_engine
```

#### **æµ‹è¯•æ€§èƒ½åŸºå‡†**
- **æµ‹è¯•é€Ÿåº¦**: 35ä¸ªæµ‹è¯•ç”¨ä¾‹ â‰ˆ 18ç§’ (ä¼˜åŒ–åçš„tagExpressionUtilså’ŒSparkUdfsæµ‹è¯•)
- **è¦†ç›–ç‡ç›®æ ‡**: > 85% ä»£ç è¦†ç›–
- **æµ‹è¯•ç¨³å®šæ€§**: 100% é€šè¿‡ç‡ï¼Œæ— éšæœºå¤±è´¥

## å¼€å‘æŒ‡å—

### æ–°å¢æ ‡ç­¾æ­¥éª¤

1. MySQLè§„åˆ™é…ç½®:
```sql
INSERT INTO tag_rules (tag_id, rule_content, status) VALUES 
(æ–°æ ‡ç­¾ID, JSONè§„åˆ™, 'active');
```

2. æµ‹è¯•éªŒè¯:
```bash
# å…ˆè¿è¡Œç›¸å…³æµ‹è¯•éªŒè¯è§„åˆ™è§£æ
python -m pytest tests/test_rule_parser.py -v

# å†æµ‹è¯•æ ‡ç­¾è®¡ç®—
python src/tag_engine/main.py --mode task-tags --tag-ids æ–°æ ‡ç­¾ID
```

3. æµ·è±šè°ƒåº¦å™¨éƒ¨ç½²:
```bash
python dolphin_deploy_package.py
# ä¸Šä¼ æ–°çš„éƒ¨ç½²åŒ…åˆ°èµ„æºä¸­å¿ƒ
```

### è‡ªå®šä¹‰å·¥å…·å¼€å‘

#### **1. å¹¶è¡Œè¡¨è¾¾å¼å·¥å…· (tagExpressionUtils.py)**
```python
# æ·»åŠ æ–°çš„å¹¶è¡Œè®¡ç®—è¡¨è¾¾å¼æ„å»ºå‡½æ•°
def buildCustomParallelExpression(conditions):
    """è‡ªå®šä¹‰å¹¶è¡Œè¡¨è¾¾å¼æ„å»º - ä½¿ç”¨æ¨¡å—çº§å‡½æ•°é¿å…åºåˆ—åŒ–
    é€‚ç”¨äºå¤æ‚çš„å¤šæ¡ä»¶å¹¶è¡Œè®¡ç®—åœºæ™¯
    """
    if not conditions:
        return array()
    
    # æ„å»ºSQLè¡¨è¾¾å¼ï¼Œä½¿ç”¨filteré«˜é˜¶å‡½æ•°ç¡®ä¿ç±»å‹å®‰å…¨
    case_expressions = []
    for condition in conditions:
        case_expressions.append(f"case when {condition['sql']} then {condition['result']} else null end")
    
    sql_expr = f"array_distinct(array_sort(filter(array({', '.join(case_expressions)}), x -> x is not null)))"
    return expr(sql_expr)
```

#### **2. Sparkå†…ç½®å‡½æ•°å·¥å…·å¼€å‘ (SparkUdfs.py)**
```python
# æ¨èï¼šä½¿ç”¨Sparkå†…ç½®å‡½æ•°å°è£…ï¼Œé¿å…é›†ç¾¤ç‰ˆæœ¬é—®é¢˜
def custom_tag_merge(tag_arrays):
    """è‡ªå®šä¹‰æ ‡ç­¾åˆå¹¶é€»è¾‘ - ä½¿ç”¨Sparkå†…ç½®å‡½æ•°
    é¿å…ä¼ ç»ŸUDFçš„é›†ç¾¤Pythonç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜
    """
    # ä½¿ç”¨flatten + array_distinct + array_sortç»„åˆ
    return array_distinct(array_sort(flatten(tag_arrays)))

def conditional_tag_assignment(condition_col, tag_id):
    """æ¡ä»¶æ ‡ç­¾åˆ†é… - ä½¿ç”¨Sparkå†…ç½®å‡½æ•°"""
    return when(condition_col, array(lit(tag_id))).otherwise(array())

# ä»…åœ¨æå…¶å¤æ‚ä¸”æ— æ³•ç”¨Sparkå†…ç½®å‡½æ•°å®ç°æ—¶æ‰è€ƒè™‘UDF
# æ³¨æ„ï¼šéœ€è¦ç¡®ä¿é›†ç¾¤æ‰€æœ‰èŠ‚ç‚¹Pythonç‰ˆæœ¬ä¸€è‡´
```

### æµ‹è¯•é©±åŠ¨å¼€å‘æµç¨‹

1. **ç¼–å†™æµ‹è¯•ç”¨ä¾‹**:
```python
def test_new_feature_logic(self):
    """æ–°åŠŸèƒ½æµ‹è¯• - å…ˆå†™æµ‹è¯•ï¼Œå†å†™å®ç°"""
    parser = TagRuleParser()
    result = parser.new_feature_method(test_input)
    assert result == expected_output
```

2. **è¿è¡Œæµ‹è¯•éªŒè¯**:
```bash
python -m pytest tests/test_new_feature.py::test_new_feature_logic -v
```

3. **å®ç°åŠŸèƒ½ä»£ç **:
```python
def new_feature_method(self, input_data):
    """å®ç°æ–°åŠŸèƒ½ï¼Œç¡®ä¿æµ‹è¯•é€šè¿‡"""
    return processed_result
```

4. **å®Œæ•´æµ‹è¯•éªŒè¯**:
```bash
python -m pytest tests/ -v  # ç¡®ä¿ä¸ç ´åç°æœ‰åŠŸèƒ½
```

## ğŸ”§ æŠ€æœ¯äº®ç‚¹æ€»ç»“

### ç±»å‹å®‰å…¨ä¿éšœ
- âœ… **å®Œæ•´ç±»å‹æµ**ï¼š`Array[Array[Int]] â†’ flatten â†’ Array[Int] â†’ distinct â†’ sort`
- âœ… **UDFç±»å‹å…¼å®¹**ï¼šæ”¯æŒ`List[int]`ã€`Array[int]`ã€åµŒå¥—æ•°ç»„ç­‰å¤šç§è¾“å…¥
- âœ… **è¾¹ç•Œæƒ…å†µå¤„ç†**ï¼šNoneå€¼è¿‡æ»¤ã€ç©ºæ•°ç»„å¤„ç†ã€å¼‚å¸¸æ¢å¤

### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
- âš¡ **Sparkå†…ç½®å‡½æ•°ä¼˜å…ˆ**ï¼šé¿å…UDFåºåˆ—åŒ–å¼€é”€ï¼Œæå‡è®¡ç®—æ€§èƒ½
- âš¡ **æ™ºèƒ½ç¼“å­˜æœºåˆ¶**ï¼šè¡¨çº§ç¼“å­˜ + å­—æ®µæŠ•å½±ï¼Œå‡å°‘é‡å¤I/O
- âš¡ **å¹¶è¡Œè®¡ç®—ä¼˜åŒ–**ï¼šè¡¨ä¾èµ–åˆ†ç»„ + æ‰¹é‡è®¡ç®—ï¼Œæœ€å¤§åŒ–èµ„æºåˆ©ç”¨

### æ¶æ„è®¾è®¡äº®ç‚¹
- ğŸ—ï¸ **æ¨¡å—åŒ–è®¾è®¡**ï¼šTagEngineã€TagGroupã€å·¥å…·å‡½æ•°èŒè´£æ¸…æ™°åˆ†ç¦»
- ğŸ—ï¸ **ç»Ÿä¸€å…¥å£ç®¡ç†**ï¼š`src/tag_engine/main.py`ä½œä¸ºå”¯ä¸€çœŸå®æ¥æº
- ğŸ—ï¸ **å¤šç¯å¢ƒæ”¯æŒ**ï¼šæœ¬åœ°å¼€å‘ã€æµ·è±šè°ƒåº¦å™¨éƒ¨ç½²æ— ç¼åˆ‡æ¢
- ğŸ—ï¸ **é›†ç¾¤å…¼å®¹æ€§**ï¼šå®Œå…¨é¿å…ä¼ ç»ŸUDFï¼Œè§£å†³å¼‚æ„é›†ç¾¤Pythonç‰ˆæœ¬å…¼å®¹é—®é¢˜

### ç”Ÿäº§å°±ç»ªç‰¹æ€§
- ğŸš€ **æµ·è±šè°ƒåº¦å™¨é›†æˆ**ï¼šåŸç”Ÿæ”¯æŒYARNé›†ç¾¤éƒ¨ç½²
- ğŸš€ **å¥åº·æ£€æŸ¥æœºåˆ¶**ï¼šå®Œæ•´çš„ç³»ç»ŸçŠ¶æ€ç›‘æ§
- ğŸš€ **é”™è¯¯æ¢å¤èƒ½åŠ›**ï¼šå•ç‚¹å¤±è´¥ä¸å½±å“å…¨å±€è®¡ç®—

---

## ğŸ¯ è®©æ•°æ®é©±åŠ¨ä¸šåŠ¡ï¼Œè®©æ ‡ç­¾åˆ›é€ ä»·å€¼ï¼

**åŸºäºPySpark DSL + Sparkå†…ç½®å‡½æ•°çš„ä¼ä¸šçº§æ ‡ç­¾è®¡ç®—ç³»ç»Ÿï¼ŒåŠ©åŠ›ç²¾å‡†è¥é”€å’Œç”¨æˆ·æ´å¯Ÿ**