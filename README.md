# ğŸ·ï¸ å¤§æ•°æ®æ ‡ç­¾ç³»ç»Ÿ

ä¼ä¸šçº§çš„å¤§æ•°æ®æ ‡ç­¾è®¡ç®—ç³»ç»Ÿï¼Œæ”¯æŒå¤šç¯å¢ƒéƒ¨ç½²ï¼ˆæœ¬åœ°ã€AWS Glueå¼€å‘ã€AWS Glueç”Ÿäº§ï¼‰ï¼Œé€šè¿‡PySparkä»S3è¯»å–æ•°æ®ï¼Œç»“åˆMySQLä¸­çš„è§„åˆ™è¿›è¡Œå¹¶è¡Œæ ‡ç­¾è®¡ç®—ï¼Œå¹¶å°†ç»“æœå­˜å‚¨å›MySQLã€‚

## ğŸ¯ ç³»ç»ŸåŠŸèƒ½

### æ ¸å¿ƒåŠŸèƒ½
- âœ… ä»S3è¯»å–Hiveè¡¨æ•°æ®
- âœ… ä»MySQLè¯»å–æ ‡ç­¾è§„åˆ™é…ç½®
- âœ… åŸºäºè§„åˆ™å¼•æ“è®¡ç®—ç”¨æˆ·æ ‡ç­¾
- âœ… æ”¯æŒæ ‡ç­¾åˆå¹¶å’Œå»é‡
- âœ… å°†æ ‡ç­¾ç»“æœå†™å…¥MySQL
- âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

### ğŸš€ æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§
- âœ… **å¤šæ ‡ç­¾å¹¶è¡Œè®¡ç®—**ï¼šæ”¯æŒå¤šä¸ªæ ‡ç­¾åŒæ—¶è®¡ç®—ï¼Œå¤§å¹…æå‡æ€§èƒ½
- âœ… **æ™ºèƒ½ç¼“å­˜ç­–ç•¥**ï¼šé¢„ç¼“å­˜MySQLæ ‡ç­¾æ•°æ®ï¼Œä½¿ç”¨ `persist(StorageLevel.MEMORY_AND_DISK)` 
- âœ… **åˆ†åŒºä¼˜åŒ–å†™å…¥**ï¼šæ ¹æ®æ•°æ®é‡åŠ¨æ€è°ƒæ•´åˆ†åŒºæ•°ï¼Œé¿å…å°æ–‡ä»¶é—®é¢˜

### ğŸ”„ æ•°æ®ä¸€è‡´æ€§ä¿éšœ
- âœ… **æ™ºèƒ½æ ‡ç­¾åˆå¹¶**ï¼šå†…å­˜åˆå¹¶ + MySQLç°æœ‰æ ‡ç­¾åˆå¹¶ï¼Œç¡®ä¿æ ‡ç­¾ä¸€è‡´æ€§
- âœ… **UPSERTå†™å…¥ç­–ç•¥**ï¼š`INSERT ON DUPLICATE KEY UPDATE`ï¼Œé¿å…æ•°æ®è¦†ç›–
- âœ… **æ—¶é—´æˆ³ç®¡ç†**ï¼šè‡ªåŠ¨ç»´æŠ¤ `created_time` å’Œ `updated_time`ï¼Œä¸é‡å¤æ›´æ–°åˆ›å»ºæ—¶é—´

### ğŸ“Š 6ç§è®¡ç®—åœºæ™¯
- âœ… **åœºæ™¯1**: å…¨é‡ç”¨æˆ·æ‰“å…¨é‡æ ‡ç­¾ï¼ˆ`full-parallel`ï¼‰
- âœ… **åœºæ™¯2**: å…¨é‡ç”¨æˆ·æ‰“æŒ‡å®šæ ‡ç­¾ï¼ˆ`tags-parallel`ï¼‰- æ”¯æŒæ ‡ç­¾åˆå¹¶
- âœ… **åœºæ™¯3**: å¢é‡ç”¨æˆ·æ‰“å…¨é‡æ ‡ç­¾ï¼ˆ`incremental-parallel`ï¼‰
- âœ… **åœºæ™¯4**: å¢é‡ç”¨æˆ·æ‰“æŒ‡å®šæ ‡ç­¾ï¼ˆ`incremental-tags-parallel`ï¼‰
- âœ… **åœºæ™¯5**: æŒ‡å®šç”¨æˆ·æ‰“å…¨é‡æ ‡ç­¾ï¼ˆ`users-parallel`ï¼‰
- âœ… **åœºæ™¯6**: æŒ‡å®šç”¨æˆ·æ‰“æŒ‡å®šæ ‡ç­¾ï¼ˆ`user-tags-parallel`ï¼‰- æ”¯æŒæ ‡ç­¾åˆå¹¶

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
bigdata_tag_system/
â”œâ”€â”€ src/                          # ğŸ”§ æ ¸å¿ƒæºç 
â”‚   â”œâ”€â”€ config/                   # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ readers/                  # æ•°æ®è¯»å–å™¨
â”‚   â”œâ”€â”€ engine/                   # æ ‡ç­¾è®¡ç®—å¼•æ“
â”‚   â”œâ”€â”€ merger/                   # æ•°æ®åˆå¹¶å™¨
â”‚   â”œâ”€â”€ writers/                  # ç»“æœå†™å…¥å™¨
â”‚   â””â”€â”€ scheduler/                # ä¸»è°ƒåº¦å™¨
â”œâ”€â”€ environments/                 # ğŸŒ ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ local/                    # æœ¬åœ°Dockerç¯å¢ƒ
â”‚   â”œâ”€â”€ glue-dev/                 # AWS Glueå¼€å‘ç¯å¢ƒ
â”‚   â””â”€â”€ glue-prod/                # AWS Glueç”Ÿäº§ç¯å¢ƒ
â”œâ”€â”€ tests/                        # ğŸ§ª æµ‹è¯•ä»£ç 
â”œâ”€â”€ docs/                         # ğŸ“š æ–‡æ¡£
â””â”€â”€ main.py                       # ğŸ“ ç»Ÿä¸€å…¥å£
```

## âš¡ å¿«é€Ÿå¼€å§‹

### ğŸ”§ ç¯å¢ƒè¦æ±‚

- Python 3.8+
- Docker & Docker Compose (æœ¬åœ°ç¯å¢ƒ)
- AWS CLI (Glueç¯å¢ƒ)

### ğŸš€ æœ¬åœ°ç¯å¢ƒ

```bash
# 1. ä¸€é”®éƒ¨ç½²åŸºç¡€ç¯å¢ƒ
cd environments/local
./setup.sh                    # å¯åŠ¨DockeræœåŠ¡ + å®‰è£…ä¾èµ–

# 2. ä¸€é”®åˆå§‹åŒ–æ•°æ®
./init_data.sh                # åˆå§‹åŒ–æ•°æ®åº“ + ç”Ÿæˆæµ‹è¯•æ•°æ®

# 3. è¿è¡Œæ ‡ç­¾è®¡ç®— - 6ç§å¹¶è¡Œè®¡ç®—åœºæ™¯
cd ../../
python main.py --env local --mode health                           # å¥åº·æ£€æŸ¥
python main.py --env local --mode full-parallel                    # åœºæ™¯1: å…¨é‡ç”¨æˆ·æ‰“å…¨é‡æ ‡ç­¾
python main.py --env local --mode tags-parallel --tag-ids 1,3,5    # åœºæ™¯2: å…¨é‡ç”¨æˆ·æ‰“æŒ‡å®šæ ‡ç­¾
python main.py --env local --mode incremental-parallel --days 7    # åœºæ™¯3: å¢é‡ç”¨æˆ·æ‰“å…¨é‡æ ‡ç­¾
python main.py --env local --mode incremental-tags-parallel --days 7 --tag-ids 1,3,5  # åœºæ™¯4: å¢é‡ç”¨æˆ·æ‰“æŒ‡å®šæ ‡ç­¾
python main.py --env local --mode users-parallel --user-ids user_000001,user_000002    # åœºæ™¯5: æŒ‡å®šç”¨æˆ·æ‰“å…¨é‡æ ‡ç­¾
python main.py --env local --mode user-tags-parallel --user-ids user_000001,user_000002 --tag-ids 1,3,5  # åœºæ™¯6: æŒ‡å®šç”¨æˆ·æ‰“æŒ‡å®šæ ‡ç­¾
```

**æœ¬åœ°ç¯å¢ƒç®¡ç†å‘½ä»¤ï¼š**
```bash
# éƒ¨ç½²ç®¡ç†
./setup.sh                    # éƒ¨ç½²åŸºç¡€ç¯å¢ƒï¼ˆé»˜è®¤ï¼‰
./setup.sh start              # å¯åŠ¨å·²æœ‰ç¯å¢ƒ
./setup.sh stop               # åœæ­¢ç¯å¢ƒ
./setup.sh clean              # æ¸…ç†ç¯å¢ƒ

# æ•°æ®ç®¡ç†  
./init_data.sh                # åˆå§‹åŒ–æ•°æ®ï¼ˆé»˜è®¤ï¼‰
./init_data.sh reset          # é‡ç½®æ‰€æœ‰æ•°æ®
./init_data.sh clean          # æ¸…ç†æ•°æ®
./init_data.sh db-only        # ä»…åˆå§‹åŒ–æ•°æ®åº“
./init_data.sh data-only      # ä»…ç”Ÿæˆæµ‹è¯•æ•°æ®
```

### â˜ï¸ AWS Glueå¼€å‘ç¯å¢ƒ

```bash
# 1. éƒ¨ç½²åˆ°Glue
cd environments/glue-dev
python deploy.py

# 2. è¿è¡Œä½œä¸š - 6ç§å¹¶è¡Œè®¡ç®—åœºæ™¯
aws glue start-job-run --job-name tag-compute-dev --arguments='--mode=full-parallel'
aws glue start-job-run --job-name tag-compute-dev --arguments='--mode=tags-parallel,--tag-ids=1,3,5'
aws glue start-job-run --job-name tag-compute-dev --arguments='--mode=incremental-parallel,--days=7'
aws glue start-job-run --job-name tag-compute-dev --arguments='--mode=incremental-tags-parallel,--days=7,--tag-ids=1,3,5'
aws glue start-job-run --job-name tag-compute-dev --arguments='--mode=users-parallel,--user-ids=user_000001,user_000002'
aws glue start-job-run --job-name tag-compute-dev --arguments='--mode=user-tags-parallel,--user-ids=user_000001,user_000002,--tag-ids=1,3,5'
```

### ğŸ­ AWS Glueç”Ÿäº§ç¯å¢ƒ

```bash
# 1. éƒ¨ç½²åˆ°Glue
cd environments/glue-prod  
python deploy.py

# 2. è¿è¡Œä½œä¸š - 6ç§å¹¶è¡Œè®¡ç®—åœºæ™¯
aws glue start-job-run --job-name tag-compute-prod --arguments='--mode=full-parallel'
aws glue start-job-run --job-name tag-compute-prod --arguments='--mode=tags-parallel,--tag-ids=1,3,5'
aws glue start-job-run --job-name tag-compute-prod --arguments='--mode=incremental-parallel,--days=7'
aws glue start-job-run --job-name tag-compute-prod --arguments='--mode=incremental-tags-parallel,--days=7,--tag-ids=1,3,5'
aws glue start-job-run --job-name tag-compute-prod --arguments='--mode=users-parallel,--user-ids=user_000001,user_000002'
aws glue start-job-run --job-name tag-compute-prod --arguments='--mode=user-tags-parallel,--user-ids=user_000001,user_000002,--tag-ids=1,3,5'
```

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# Sparké…ç½®
export SPARK_APP_NAME=TagComputeSystem
export SPARK_MASTER=local[4]
export SPARK_EXECUTOR_MEMORY=4g
export SPARK_DRIVER_MEMORY=2g

# S3é…ç½®
export S3_BUCKET=your-data-bucket
export S3_ACCESS_KEY=your-access-key
export S3_SECRET_KEY=your-secret-key
export S3_ENDPOINT=http://localhost:9000  # å¯é€‰ï¼Œç”¨äºminio
export S3_REGION=us-east-1

# MySQLé…ç½®
export MYSQL_HOST=localhost
export MYSQL_PORT=3306
export MYSQL_DATABASE=tag_system
export MYSQL_USERNAME=root
export MYSQL_PASSWORD=your-password

# ç³»ç»Ÿé…ç½®
export BATCH_SIZE=10000
export MAX_RETRIES=3
export ENABLE_CACHE=true
export LOG_LEVEL=INFO
```

### ä»£ç é…ç½®

```python
from config.base_config import TagSystemConfig, SparkConfig, S3Config, MySQLConfig

config = TagSystemConfig(
    spark=SparkConfig(
        app_name="TagComputeSystem",
        master="local[4]",
        executor_memory="4g",
        driver_memory="2g"
    ),
    s3=S3Config(
        bucket="your-data-bucket",
        access_key="your-access-key",
        secret_key="your-secret-key"
    ),
    mysql=MySQLConfig(
        host="localhost",
        database="tag_system",
        username="root",
        password="password"
    )
)
```

## ğŸ“Š æ•°æ®è¡¨ç»“æ„

### MySQLæ ‡ç­¾è§„åˆ™è¡¨

```sql
-- æ ‡ç­¾åˆ†ç±»è¡¨
CREATE TABLE tag_category (
    id INT PRIMARY KEY AUTO_INCREMENT,
    category_name VARCHAR(50) NOT NULL,
    category_code VARCHAR(50) NOT NULL UNIQUE,
    status TINYINT DEFAULT 1,
    created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ ‡ç­¾å®šä¹‰è¡¨
CREATE TABLE tag_definition (
    id INT PRIMARY KEY AUTO_INCREMENT,
    tag_name VARCHAR(100) NOT NULL,
    tag_code VARCHAR(100) NOT NULL UNIQUE,
    category_id INT NOT NULL,
    tag_type ENUM('AUTO', 'MANUAL') NOT NULL,
    status TINYINT DEFAULT 1,
    created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (category_id) REFERENCES tag_category(id)
);

-- æ ‡ç­¾è§„åˆ™è¡¨
CREATE TABLE tag_rules (
    id INT PRIMARY KEY AUTO_INCREMENT,
    tag_id INT NOT NULL,
    rule_name VARCHAR(100),
    rule_description TEXT,
    condition_logic ENUM('AND', 'OR', 'NOT') DEFAULT 'AND',
    rule_conditions JSON,
    target_table VARCHAR(100),
    target_fields TEXT,
    status TINYINT DEFAULT 1,
    created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (tag_id) REFERENCES tag_definition(id)
);

-- ç”¨æˆ·æ ‡ç­¾ç»“æœè¡¨ï¼ˆé‡æ„åçš„ä¸€ä¸ªç”¨æˆ·ä¸€æ¡è®°å½•è®¾è®¡ï¼‰
CREATE TABLE user_tags (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id VARCHAR(100) NOT NULL COMMENT 'ç”¨æˆ·ID',
    tag_ids JSON NOT NULL COMMENT 'ç”¨æˆ·çš„æ‰€æœ‰æ ‡ç­¾IDæ•°ç»„ [1,2,3,5]',
    tag_details JSON COMMENT 'æ ‡ç­¾è¯¦ç»†ä¿¡æ¯ {"1": {"tag_name": "é«˜å‡€å€¼ç”¨æˆ·"}}',
    created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
    updated_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
    INDEX idx_user_id (user_id),
    INDEX idx_created_time (created_time),
    INDEX idx_updated_time (updated_time),
    UNIQUE KEY uk_user_id (user_id)
);
```

### S3 Hiveè¡¨ç»“æ„ç¤ºä¾‹

```sql
-- ç”¨æˆ·åŸºç¡€ä¿¡æ¯è¡¨ (S3: s3://bucket/warehouse/user_basic_info/)
user_basic_info:
- user_id: string
- register_time: timestamp  
- register_country: string
- kyc_status: string
- user_level: string
- updated_time: timestamp

-- ç”¨æˆ·èµ„äº§æ±‡æ€»è¡¨ (S3: s3://bucket/warehouse/user_asset_summary/) 
user_asset_summary:
- user_id: string
- total_asset_value: decimal
- total_deposit_amount: decimal
- total_withdraw_amount: decimal
- updated_time: timestamp

-- ç”¨æˆ·æ´»åŠ¨æ±‡æ€»è¡¨ (S3: s3://bucket/warehouse/user_activity_summary/)
user_activity_summary:
- user_id: string
- last_login_time: timestamp
- login_count_7d: int
- trading_count_30d: int
- last_trading_time: timestamp
- updated_time: timestamp
```

## ğŸ”§ æ ‡ç­¾è§„åˆ™é…ç½®

### è§„åˆ™JSONæ ¼å¼

```json
{
  "logic": "AND",
  "conditions": [
    {
      "field": "total_asset_value",
      "operator": ">=",
      "value": 100000,
      "type": "number"
    },
    {
      "field": "kyc_status", 
      "operator": "=",
      "value": "verified",
      "type": "string"
    }
  ]
}
```

### æ”¯æŒçš„æ“ä½œç¬¦

| æ“ä½œç¬¦ | è¯´æ˜ | ç¤ºä¾‹ |
|-------|------|------|
| `=` | ç­‰äº | `{"field": "status", "operator": "=", "value": "active"}` |
| `!=` | ä¸ç­‰äº | `{"field": "status", "operator": "!=", "value": "inactive"}` |
| `>`, `<`, `>=`, `<=` | æ•°å€¼æ¯”è¾ƒ | `{"field": "amount", "operator": ">=", "value": 1000}` |
| `in` | åŒ…å« | `{"field": "level", "operator": "in", "value": ["VIP1", "VIP2"]}` |
| `not_in` | ä¸åŒ…å« | `{"field": "country", "operator": "not_in", "value": ["US", "UK"]}` |
| `in_range` | èŒƒå›´å†… | `{"field": "age", "operator": "in_range", "value": [18, 65]}` |
| `contains` | å­—ç¬¦ä¸²åŒ…å« | `{"field": "email", "operator": "contains", "value": "@gmail"}` |
| `recent_days` | æœ€è¿‘Nå¤© | `{"field": "login_time", "operator": "recent_days", "value": 7}` |
| `is_null` | ä¸ºç©º | `{"field": "phone", "operator": "is_null"}` |
| `is_not_null` | ä¸ä¸ºç©º | `{"field": "phone", "operator": "is_not_null"}` |

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šé«˜å‡€å€¼ç”¨æˆ·æ ‡ç­¾ï¼ˆå…¨é‡ç”¨æˆ·è®¡ç®—ï¼‰

```bash
# è¿è¡Œåœºæ™¯2ï¼šå…¨é‡ç”¨æˆ·æ‰“æŒ‡å®šæ ‡ç­¾ï¼ˆæ”¯æŒä¸ç°æœ‰æ ‡ç­¾åˆå¹¶ï¼‰
python main.py --env local --mode tags-parallel --tag-ids 1

# æŸ¥çœ‹ç»“æœ
mysql -h 127.0.0.1 -P 3307 -u root -proot123 -e "
USE tag_system;
SELECT user_id, tag_ids, created_time, updated_time 
FROM user_tags 
WHERE JSON_CONTAINS(tag_ids, '1') 
LIMIT 5;"
```

### ç¤ºä¾‹2ï¼šæ´»è·ƒç”¨æˆ·æ ‡ç­¾ï¼ˆå¢é‡ç”¨æˆ·è®¡ç®—ï¼‰

```bash
# è¿è¡Œåœºæ™¯4ï¼šå¢é‡ç”¨æˆ·æ‰“æŒ‡å®šæ ‡ç­¾
python main.py --env local --mode incremental-tags-parallel --days 7 --tag-ids 2

# æŸ¥çœ‹ç»“æœï¼šæ´»è·ƒç”¨æˆ·æ ‡ç­¾
mysql -h 127.0.0.1 -P 3307 -u root -proot123 -e "
USE tag_system;
SELECT user_id, 
       tag_ids, 
       JSON_EXTRACT(tag_details, '$.\"2\".tag_name') as tag_name,
       created_time, 
       updated_time 
FROM user_tags 
WHERE JSON_CONTAINS(tag_ids, '2') 
ORDER BY updated_time DESC 
LIMIT 5;"
```

### ç¤ºä¾‹3ï¼šæŒ‡å®šç”¨æˆ·å¤šæ ‡ç­¾è®¡ç®—

```bash
# è¿è¡Œåœºæ™¯6ï¼šæŒ‡å®šç”¨æˆ·æ‰“æŒ‡å®šæ ‡ç­¾ï¼ˆæ”¯æŒä¸ç°æœ‰æ ‡ç­¾åˆå¹¶ï¼‰  
python main.py --env local --mode user-tags-parallel --user-ids user_000001,user_000002 --tag-ids 1,2,3

# æŸ¥çœ‹ç‰¹å®šç”¨æˆ·çš„æ ‡ç­¾å˜åŒ–
mysql -h 127.0.0.1 -P 3307 -u root -proot123 -e "
USE tag_system;
SELECT user_id, 
       tag_ids,
       JSON_LENGTH(tag_ids) as tag_count,
       created_time,
       updated_time,
       TIMESTAMPDIFF(SECOND, created_time, updated_time) as seconds_since_creation
FROM user_tags 
WHERE user_id IN ('user_000001', 'user_000002');"
```

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œå•å…ƒæµ‹è¯•
python -m pytest tests/test_basic.py -v

# è¿è¡Œç¤ºä¾‹æµ‹è¯•
python run_examples.py validation

# è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
python run_examples.py all
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### Sparkä¼˜åŒ–

```python
# è°ƒæ•´Sparkå‚æ•°
spark_config = SparkConfig(
    executor_memory="8g",
    driver_memory="4g", 
    shuffle_partitions=200,
    max_result_size="4g"
)
```

### æ•°æ®è¯»å–ä¼˜åŒ–

```python
# ä½¿ç”¨åˆ†åŒºè¿‡æ»¤
partition_filter = "updated_time >= '2024-01-01'"
data = hive_reader.read_table_data('user_asset_summary', partition_filter=partition_filter)

# å­—æ®µè£å‰ª
required_fields = "user_id,total_asset_value,updated_time"
data = hive_reader.read_table_data('user_asset_summary', required_fields=required_fields)
```

### ç¼“å­˜ç­–ç•¥

```python
# ç¼“å­˜çƒ­ç‚¹æ•°æ®
if table_name in ['user_basic_info', 'user_asset_summary']:
    df = df.cache()
```

## ğŸ” ç›‘æ§å’Œæ—¥å¿—

### æ—¥å¿—é…ç½®

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('tag_system.log')
    ]
)
```

### å…³é”®æŒ‡æ ‡

- æ ‡ç­¾è®¡ç®—æ‰§è¡Œæ—¶é—´
- æ•°æ®è¯»å–é‡å’Œå¤„ç†é€Ÿåº¦
- æ ‡ç­¾å‘½ä¸­ç‡å’Œè¦†ç›–ç‡
- ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®ä¸€è‡´æ€§**ï¼šç¡®ä¿S3æ•°æ®å’ŒMySQLè§„åˆ™çš„ä¸€è‡´æ€§
2. **èµ„æºç®¡ç†**ï¼šåˆç†è®¾ç½®Sparkèµ„æºå‚æ•°ï¼Œé¿å…OOM
3. **é”™è¯¯å¤„ç†**ï¼šé‡è¦æ“ä½œéƒ½æœ‰é‡è¯•æœºåˆ¶å’Œé”™è¯¯æ¢å¤
4. **æ•°æ®å¤‡ä»½**ï¼šå†™å…¥å‰è‡ªåŠ¨å¤‡ä»½ç°æœ‰æ•°æ®
5. **æƒé™æ§åˆ¶**ï¼šç¡®ä¿å¯¹S3å’ŒMySQLæœ‰è¶³å¤Ÿçš„è®¿é—®æƒé™

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ã€‚

## ğŸ“„ è®¸å¯è¯

MIT License