[LOG-PATH]: /data/installed/dolphinscheduler/apache-dolphinscheduler-3.2.0-bin/worker-server/logs/20250813/18540583925120/38/16580/97773.log, [HOST]:  Host(ip=172.24.14.168, port=1234)
[INFO] 2025-08-13 02:44:35.912 +0000 - ***********************************************************************************************
[INFO] 2025-08-13 02:44:35.912 +0000 - *********************************  Initialize task context  ***********************************
[INFO] 2025-08-13 02:44:35.912 +0000 - ***********************************************************************************************
[INFO] 2025-08-13 02:44:35.912 +0000 - Begin to initialize task
[INFO] 2025-08-13 02:44:35.912 +0000 - Set task startTime: 1755053075912
[INFO] 2025-08-13 02:44:35.912 +0000 - Set task appId: 16580_97773
[INFO] 2025-08-13 02:44:35.912 +0000 - End initialize task {
  "taskInstanceId" : 97773,
  "taskName" : "specific_compute_tags",
  "firstSubmitTime" : 1755053075883,
  "startTime" : 1755053075912,
  "taskType" : "SPARK",
  "workflowInstanceHost" : "172.24.13.145:5678",
  "host" : "172.24.14.168:1234",
  "logPath" : "/data/installed/dolphinscheduler/apache-dolphinscheduler-3.2.0-bin/worker-server/logs/20250813/18540583925120/38/16580/97773.log",
  "processId" : 0,
  "processDefineCode" : 18540583925120,
  "processDefineVersion" : 38,
  "processInstanceId" : 16580,
  "scheduleTime" : 0,
  "executorId" : 6,
  "cmdTypeIfComplement" : 0,
  "tenantCode" : "default",
  "processDefineId" : 0,
  "projectId" : 0,
  "projectCode" : 18540427537920,
  "taskParams" : "{\"localParams\":[],\"rawScript\":\"\",\"resourceList\":[{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/create_test_tables.sql\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/generate_test_data.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/requirements.txt\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/__init__.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/__init__.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/main.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagEngine.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagGroup.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/__init__.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/HiveMeta.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/MysqlMeta.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/__init__.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/TagRuleParser.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/__init__.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/SparkUdfs.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/__init__.py\",\"res\":null},{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/tagExpressionUtils.py\",\"res\":null}],\"programType\":\"PYTHON\",\"mainClass\":\"\",\"mainJar\":{\"id\":-1,\"resourceName\":\"dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/main.py\",\"res\":null},\"deployMode\":\"client\",\"mainArgs\":\"--mode task-tags --tag-ids 1,2,3,4,5,6,7,8,9\",\"others\":\"--jars s3://exchanges-flink-prod/dolphinscheduler/default/resources/connectors/mysql-connector-j-8.0.33.jar\",\"yarnQueue\":\"\",\"driverCores\":1,\"driverMemory\":\"512M\",\"numExecutors\":2,\"executorMemory\":\"2G\",\"executorCores\":2,\"sqlExecutionType\":\"SCRIPT\"}",
  "prepareParamsMap" : {
    "system.task.definition.name" : {
      "prop" : "system.task.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "specific_compute_tags"
    },
    "system.project.name" : {
      "prop" : "system.project.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : null
    },
    "system.project.code" : {
      "prop" : "system.project.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "18540427537920"
    },
    "system.workflow.instance.id" : {
      "prop" : "system.workflow.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "16580"
    },
    "system.biz.curdate" : {
      "prop" : "system.biz.curdate",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20250813"
    },
    "system.biz.date" : {
      "prop" : "system.biz.date",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20250812"
    },
    "system.task.instance.id" : {
      "prop" : "system.task.instance.id",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "97773"
    },
    "system.workflow.definition.name" : {
      "prop" : "system.workflow.definition.name",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "pyspark_tag_system"
    },
    "system.task.definition.code" : {
      "prop" : "system.task.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "18639163327616"
    },
    "system.workflow.definition.code" : {
      "prop" : "system.workflow.definition.code",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "18540583925120"
    },
    "StartNodeList" : {
      "prop" : "StartNodeList",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "18639163327616"
    },
    "system.datetime" : {
      "prop" : "system.datetime",
      "direct" : "IN",
      "type" : "VARCHAR",
      "value" : "20250813024435"
    }
  },
  "taskAppId" : "16580_97773",
  "taskTimeout" : 2147483647,
  "workerGroup" : "default",
  "delayTime" : 0,
  "currentExecutionStatus" : "SUBMITTED_SUCCESS",
  "endTime" : 0,
  "resources" : {
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagEngine.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/TagRuleParser.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/__init__.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/__init__.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/__init__.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/generate_test_data.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/__init__.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/create_test_tables.sql" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/main.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/tagExpressionUtils.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/MysqlMeta.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/SparkUdfs.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/requirements.txt" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagGroup.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/HiveMeta.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/__init__.py" : "",
    "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/__init__.py" : ""
  },
  "dryRun" : 0,
  "paramsMap" : { },
  "cpuQuota" : -1,
  "memoryMax" : -1,
  "testFlag" : 0,
  "logBufferEnable" : false,
  "dispatchFailTimes" : 0
}
[INFO] 2025-08-13 02:44:35.913 +0000 - ***********************************************************************************************
[INFO] 2025-08-13 02:44:35.913 +0000 - *********************************  Load task instance plugin  *********************************
[INFO] 2025-08-13 02:44:35.913 +0000 - ***********************************************************************************************
[INFO] 2025-08-13 02:44:35.913 +0000 - Send task status RUNNING_EXECUTION master: 172.24.14.168:1234
[WARN] 2025-08-13 02:44:35.913 +0000 - Current tenant is default tenant, will use root to execute the task
[INFO] 2025-08-13 02:44:35.913 +0000 - TenantCode: default check successfully
[INFO] 2025-08-13 02:44:35.914 +0000 - WorkflowInstanceExecDir: /tmp/dolphinscheduler/exec/process/default/18540427537920/18540583925120_38/16580/97773 check successfully
[INFO] 2025-08-13 02:44:35.914 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagEngine.py
[INFO] 2025-08-13 02:44:35.955 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/TagRuleParser.py
[INFO] 2025-08-13 02:44:35.975 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/__init__.py
[INFO] 2025-08-13 02:44:35.988 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/__init__.py
[INFO] 2025-08-13 02:44:36.024 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/__init__.py
[INFO] 2025-08-13 02:44:36.056 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/generate_test_data.py
[INFO] 2025-08-13 02:44:36.075 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/__init__.py
[INFO] 2025-08-13 02:44:36.113 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/create_test_tables.sql
[INFO] 2025-08-13 02:44:36.146 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/main.py
[INFO] 2025-08-13 02:44:36.167 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/tagExpressionUtils.py
[INFO] 2025-08-13 02:44:36.193 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/MysqlMeta.py
[INFO] 2025-08-13 02:44:36.230 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/SparkUdfs.py
[INFO] 2025-08-13 02:44:36.270 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/requirements.txt
[INFO] 2025-08-13 02:44:36.292 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagGroup.py
[INFO] 2025-08-13 02:44:36.326 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/HiveMeta.py
[INFO] 2025-08-13 02:44:36.354 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/__init__.py
[INFO] 2025-08-13 02:44:36.379 +0000 - get resource file from path:dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/__init__.py
[INFO] 2025-08-13 02:44:36.453 +0000 - Download resources: {dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagEngine.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagEngine.py, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/TagRuleParser.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/TagRuleParser.py, dolphinscheduler/default/resources/bigdata_tag_system/src/__init__.py=dolphinscheduler/default/resources/bigdata_tag_system/src/__init__.py, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/__init__.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/__init__.py, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/__init__.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/__init__.py, dolphinscheduler/default/resources/bigdata_tag_system/generate_test_data.py=dolphinscheduler/default/resources/bigdata_tag_system/generate_test_data.py, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/__init__.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/__init__.py, dolphinscheduler/default/resources/bigdata_tag_system/create_test_tables.sql=dolphinscheduler/default/resources/bigdata_tag_system/create_test_tables.sql, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/main.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/main.py, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/tagExpressionUtils.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/tagExpressionUtils.py, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/MysqlMeta.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/MysqlMeta.py, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/SparkUdfs.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/SparkUdfs.py, dolphinscheduler/default/resources/bigdata_tag_system/requirements.txt=dolphinscheduler/default/resources/bigdata_tag_system/requirements.txt, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagGroup.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagGroup.py, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/HiveMeta.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/HiveMeta.py, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/__init__.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/__init__.py, dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/__init__.py=dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/__init__.py} successfully
[INFO] 2025-08-13 02:44:36.453 +0000 - Download upstream files: [] successfully
[INFO] 2025-08-13 02:44:36.453 +0000 - Task plugin instance: SPARK create successfully
[INFO] 2025-08-13 02:44:36.454 +0000 - Initialize spark task params {
  "localParams" : [ ],
  "varPool" : null,
  "mainJar" : {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/main.py",
    "res" : null
  },
  "mainClass" : "",
  "deployMode" : "client",
  "mainArgs" : "--mode task-tags --tag-ids 1,2,3,4,5,6,7,8,9",
  "driverCores" : 1,
  "driverMemory" : "512M",
  "numExecutors" : 2,
  "executorCores" : 2,
  "executorMemory" : "2G",
  "appName" : null,
  "yarnQueue" : "",
  "others" : "--jars s3://exchanges-flink-prod/dolphinscheduler/default/resources/connectors/mysql-connector-j-8.0.33.jar",
  "programType" : "PYTHON",
  "rawScript" : "",
  "namespace" : null,
  "resourceList" : [ {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/create_test_tables.sql",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/generate_test_data.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/requirements.txt",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/__init__.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/__init__.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/main.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagEngine.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/TagGroup.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/engine/__init__.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/HiveMeta.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/MysqlMeta.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/meta/__init__.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/TagRuleParser.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/parser/__init__.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/SparkUdfs.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/__init__.py",
    "res" : null
  }, {
    "id" : -1,
    "resourceName" : "dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/utils/tagExpressionUtils.py",
    "res" : null
  } ],
  "sqlExecutionType" : "SCRIPT"
}
[INFO] 2025-08-13 02:44:36.454 +0000 - Success initialized task plugin instance successfully
[INFO] 2025-08-13 02:44:36.454 +0000 - Set taskVarPool: null successfully
[INFO] 2025-08-13 02:44:36.454 +0000 - ***********************************************************************************************
[INFO] 2025-08-13 02:44:36.454 +0000 - *********************************  Execute task instance  *************************************
[INFO] 2025-08-13 02:44:36.454 +0000 - ***********************************************************************************************
[INFO] 2025-08-13 02:44:36.454 +0000 - Final Shell file is :
#!/bin/bash
BASEDIR=$(cd `dirname $0`; pwd)
cd $BASEDIR
${SPARK_HOME}/bin/spark-submit --master yarn --deploy-mode client --conf spark.driver.cores=1 --conf spark.driver.memory=512M --conf spark.executor.instances=2 --conf spark.executor.cores=2 --conf spark.executor.memory=2G --jars s3://exchanges-flink-prod/dolphinscheduler/default/resources/connectors/mysql-connector-j-8.0.33.jar dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine/main.py --mode task-tags --tag-ids 1,2,3,4,5,6,7,8,9
[INFO] 2025-08-13 02:44:36.454 +0000 - Executing shell command : sudo -u root -i /tmp/dolphinscheduler/exec/process/default/18540427537920/18540583925120_38/16580/97773/16580_97773.sh
[INFO] 2025-08-13 02:44:36.457 +0000 - process start, process id is: 2477617
[INFO] 2025-08-13 02:44:38.457 +0000 -  ->
	25/08/13 02:44:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2025-08-13 02:44:40.458 +0000 -  ->
	============================================================
	🏷️  大数据标签计算系统
	============================================================
	执行模式: task-tags
	当前工作目录: /tmp/dolphinscheduler/exec/process/default/18540427537920/18540583925120_38/16580/97773
	脚本目录: /tmp/dolphinscheduler/exec/process/default/18540427537920/18540583925120_38/16580/97773/dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine
	项目根目录: /tmp/dolphinscheduler/exec/process/default/18540427537920/18540583925120_38/16580/97773/dolphinscheduler/default/resources/bigdata_tag_system
	Python路径前3项: ['/tmp/dolphinscheduler/exec/process/default/18540427537920/18540583925120_38/16580/97773/dolphinscheduler/default/resources/bigdata_tag_system', '/tmp/dolphinscheduler/exec/process/default/18540427537920/18540583925120_38/16580/97773/dolphinscheduler/default/resources/bigdata_tag_system/src/tag_engine', '/mnt/spark/python/lib/pyspark.zip']
	指定标签: 1,2,3,4,5,6,7,8,9
	🚀 创建Spark会话: TagComputeEngine
	25/08/13 02:44:39 INFO EMRParamSideChannel: Setting FGAC mode to false
	25/08/13 02:44:39 INFO SparkContext: Running Spark version 3.5.2-amzn-1
	25/08/13 02:44:39 INFO SparkContext: OS info Linux, 6.8.0-1030-aws, amd64
	25/08/13 02:44:39 INFO SparkContext: Java version 17.0.16
	25/08/13 02:44:39 INFO ResourceUtils: ==============================================================
	25/08/13 02:44:39 INFO ResourceUtils: No custom resources configured for spark.driver.
	25/08/13 02:44:39 INFO ResourceUtils: ==============================================================
	25/08/13 02:44:39 INFO SparkContext: Submitted application: TagComputeEngine
	25/08/13 02:44:39 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	25/08/13 02:44:39 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	25/08/13 02:44:39 INFO ResourceProfileManager: Added ResourceProfile id: 0
	25/08/13 02:44:39 INFO ResourceProfile: User executor ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
	25/08/13 02:44:39 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
	25/08/13 02:44:39 INFO ResourceProfileManager: Added ResourceProfile id: 1
	25/08/13 02:44:39 INFO SecurityManager: Changing view acls to: root
	25/08/13 02:44:39 INFO SecurityManager: Changing modify acls to: root
	25/08/13 02:44:39 INFO SecurityManager: Changing view acls groups to:
	25/08/13 02:44:39 INFO SecurityManager: Changing modify acls groups to:
	25/08/13 02:44:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
	25/08/13 02:44:39 INFO Utils: Successfully started service 'sparkDriver' on port 43543.
	25/08/13 02:44:39 INFO SparkEnv: Registering MapOutputTracker
	25/08/13 02:44:40 INFO SparkEnv: Registering BlockManagerMaster
	25/08/13 02:44:40 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
	25/08/13 02:44:40 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
	25/08/13 02:44:40 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
	25/08/13 02:44:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-28d34c35-45e0-449a-ac28-faba61555040
	25/08/13 02:44:40 INFO MemoryStore: MemoryStore started with capacity 127.2 MiB
	25/08/13 02:44:40 INFO SparkEnv: Registering OutputCommitCoordinator
	25/08/13 02:44:40 INFO SubResultCacheManager: Sub-result caches are disabled.
	25/08/13 02:44:40 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
	25/08/13 02:44:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
	25/08/13 02:44:40 INFO Utils: Using 100 preallocated executors (minExecutors: 0). Set spark.dynamicAllocation.preallocateExecutors to `false` disable executor preallocation.
	25/08/13 02:44:40 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm2
	25/08/13 02:44:40 INFO ConfiguredRMFailoverProxyProvider: Failing over to rm3
[INFO] 2025-08-13 02:44:41.459 +0000 -  ->
	25/08/13 02:44:40 INFO Configuration: resource-types.xml not found
	25/08/13 02:44:40 INFO ResourceUtils: Unable to find 'resource-types.xml'.
	25/08/13 02:44:40 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (54272 MB per container)
	25/08/13 02:44:40 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
	25/08/13 02:44:40 INFO Client: Setting up container launch context for our AM
	25/08/13 02:44:40 INFO Client: Setting up the launch environment for our AM container
	25/08/13 02:44:40 INFO Client: Preparing resources for our AM container
	25/08/13 02:44:40 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/HikariCP-2.5.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/HikariCP-2.5.1.jar
	25/08/13 02:44:40 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/HikariCP-2.5.1.jar' for reading
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/JLargeArrays-1.5.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/JLargeArrays-1.5.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/JLargeArrays-1.5.jar' for reading
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/JTransforms-3.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/JTransforms-3.1.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/JTransforms-3.1.jar' for reading
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/RoaringBitmap-0.9.45.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/RoaringBitmap-0.9.45.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/RoaringBitmap-0.9.45.jar' for reading
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/ST4-4.0.4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/ST4-4.0.4.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/ST4-4.0.4.jar' for reading
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/activation-1.1.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/activation-1.1.1.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/activation-1.1.1.jar' for reading
[INFO] 2025-08-13 02:44:42.461 +0000 -  ->
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/aggdesigner-algorithm-6.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/aggdesigner-algorithm-6.0.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/aggdesigner-algorithm-6.0.jar' for reading
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/aircompressor-0.27.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/aircompressor-0.27.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/aircompressor-0.27.jar' for reading
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/algebra_2.12-2.0.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/algebra_2.12-2.0.1.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/algebra_2.12-2.0.1.jar' for reading
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/animal-sniffer-annotations-1.14.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/animal-sniffer-annotations-1.14.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/animal-sniffer-annotations-1.14.jar' for reading
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/animal-sniffer-annotations-1.23.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/animal-sniffer-annotations-1.23.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/animal-sniffer-annotations-1.23.jar' for reading
	25/08/13 02:44:41 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/annotations-16.0.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/annotations-16.0.2.jar
	25/08/13 02:44:41 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/annotations-16.0.2.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/annotations-17.0.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/annotations-17.0.0.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/annotations-17.0.0.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/annotations-4.1.1.4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/annotations-4.1.1.4.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/annotations-4.1.1.4.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/antlr-runtime-3.5.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/antlr-runtime-3.5.2.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/antlr-runtime-3.5.2.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/antlr4-runtime-4.9.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/antlr4-runtime-4.9.3.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/antlr4-runtime-4.9.3.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/aopalliance-1.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/aopalliance-1.0.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/aopalliance-1.0.jar' for reading
[INFO] 2025-08-13 02:44:43.462 +0000 -  ->
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/aopalliance-repackaged-2.6.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/aopalliance-repackaged-2.6.1.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/aopalliance-repackaged-2.6.1.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/arpack-3.0.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/arpack-3.0.3.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/arpack-3.0.3.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/arpack_combined_all-0.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/arpack_combined_all-0.1.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/arpack_combined_all-0.1.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/arrow-format-12.0.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/arrow-format-12.0.1.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/arrow-format-12.0.1.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/arrow-memory-core-12.0.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/arrow-memory-core-12.0.1.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/arrow-memory-core-12.0.1.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/arrow-memory-netty-12.0.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/arrow-memory-netty-12.0.1.jar
	25/08/13 02:44:42 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/arrow-memory-netty-12.0.1.jar' for reading
	25/08/13 02:44:42 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/arrow-vector-12.0.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/arrow-vector-12.0.1.jar
	25/08/13 02:44:43 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/arrow-vector-12.0.1.jar' for reading
	25/08/13 02:44:43 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/audience-annotations-0.12.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/audience-annotations-0.12.0.jar
	25/08/13 02:44:43 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/audience-annotations-0.12.0.jar' for reading
	25/08/13 02:44:43 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/avro-1.11.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/avro-1.11.2.jar
	25/08/13 02:44:43 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/avro-1.11.2.jar' for reading
	25/08/13 02:44:43 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/avro-ipc-1.11.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/avro-ipc-1.11.2.jar
	25/08/13 02:44:43 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/avro-ipc-1.11.2.jar' for reading
	25/08/13 02:44:43 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/avro-mapred-1.11.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/avro-mapred-1.11.2.jar
	25/08/13 02:44:43 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/avro-mapred-1.11.2.jar' for reading
[INFO] 2025-08-13 02:44:44.463 +0000 -  ->
	25/08/13 02:44:43 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/bcprov-ext-jdk15on-1.66.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/bcprov-ext-jdk15on-1.66.jar
	25/08/13 02:44:43 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/bcprov-ext-jdk15on-1.66.jar' for reading
	25/08/13 02:44:43 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/blas-3.0.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/blas-3.0.3.jar
	25/08/13 02:44:43 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/blas-3.0.3.jar' for reading
	25/08/13 02:44:43 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/bonecp-0.8.0.RELEASE.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/bonecp-0.8.0.RELEASE.jar
	25/08/13 02:44:43 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/bonecp-0.8.0.RELEASE.jar' for reading
	25/08/13 02:44:43 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/breeze-macros_2.12-2.1.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/breeze-macros_2.12-2.1.0.jar
	25/08/13 02:44:43 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/breeze-macros_2.12-2.1.0.jar' for reading
	25/08/13 02:44:43 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/breeze_2.12-2.1.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/breeze_2.12-2.1.0.jar
	25/08/13 02:44:43 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/breeze_2.12-2.1.0.jar' for reading
	25/08/13 02:44:44 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/cats-kernel_2.12-2.1.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/cats-kernel_2.12-2.1.1.jar
	25/08/13 02:44:44 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/cats-kernel_2.12-2.1.1.jar' for reading
	25/08/13 02:44:44 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/checker-qual-2.5.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/checker-qual-2.5.2.jar
	25/08/13 02:44:44 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/checker-qual-2.5.2.jar' for reading
	25/08/13 02:44:44 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/chill-java-0.10.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/chill-java-0.10.0.jar
	25/08/13 02:44:44 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/chill-java-0.10.0.jar' for reading
[INFO] 2025-08-13 02:44:45.463 +0000 -  ->
	25/08/13 02:44:44 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/chill_2.12-0.10.0.jar' for reading
	25/08/13 02:44:44 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-cli-1.5.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-cli-1.5.0.jar
	25/08/13 02:44:44 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-cli-1.5.0.jar' for reading
	25/08/13 02:44:44 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-codec-1.16.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-codec-1.16.1.jar
	25/08/13 02:44:44 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-codec-1.16.1.jar' for reading
	25/08/13 02:44:44 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-collections-3.2.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-collections-3.2.2.jar
	25/08/13 02:44:44 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-collections-3.2.2.jar' for reading
	25/08/13 02:44:44 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-collections4-4.4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-collections4-4.4.jar
	25/08/13 02:44:44 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-collections4-4.4.jar' for reading
	25/08/13 02:44:44 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-compiler-3.1.9.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-compiler-3.1.9.jar
	25/08/13 02:44:44 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-compiler-3.1.9.jar' for reading
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-compress-1.23.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-compress-1.23.0.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-compress-1.23.0.jar' for reading
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-crypto-1.1.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-crypto-1.1.0.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-crypto-1.1.0.jar' for reading
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-dbcp-1.4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-dbcp-1.4.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-dbcp-1.4.jar' for reading
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-io-2.16.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-io-2.16.1.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-io-2.16.1.jar' for reading
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-lang-2.6.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-lang-2.6.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-lang-2.6.jar' for reading
[INFO] 2025-08-13 02:44:46.464 +0000 -  ->
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-lang3-3.12.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-lang3-3.12.0.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-lang3-3.12.0.jar' for reading
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-logging-1.1.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-logging-1.1.3.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-logging-1.1.3.jar' for reading
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-math3-3.6.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-math3-3.6.1.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-math3-3.6.1.jar' for reading
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-pool-1.5.4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-pool-1.5.4.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-pool-1.5.4.jar' for reading
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/commons-text-1.10.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/commons-text-1.10.0.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/commons-text-1.10.0.jar' for reading
	25/08/13 02:44:45 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/compress-lzf-1.1.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/compress-lzf-1.1.2.jar
	25/08/13 02:44:45 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/compress-lzf-1.1.2.jar' for reading
	25/08/13 02:44:46 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/curator-client-2.13.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/curator-client-2.13.0.jar
	25/08/13 02:44:46 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/curator-client-2.13.0.jar' for reading
	25/08/13 02:44:46 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/curator-framework-2.13.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/curator-framework-2.13.0.jar
	25/08/13 02:44:46 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/curator-framework-2.13.0.jar' for reading
	25/08/13 02:44:46 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/curator-recipes-2.13.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/curator-recipes-2.13.0.jar
	25/08/13 02:44:46 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/curator-recipes-2.13.0.jar' for reading
	25/08/13 02:44:46 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/datanucleus-api-jdo-4.2.4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/datanucleus-api-jdo-4.2.4.jar
	25/08/13 02:44:46 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/datanucleus-api-jdo-4.2.4.jar' for reading
	25/08/13 02:44:46 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/datanucleus-core-4.1.17.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/datanucleus-core-4.1.17.jar
[INFO] 2025-08-13 02:44:47.466 +0000 -  ->
	25/08/13 02:44:46 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/datanucleus-core-4.1.17.jar' for reading
	25/08/13 02:44:46 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/datanucleus-rdbms-4.1.19.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/datanucleus-rdbms-4.1.19.jar
	25/08/13 02:44:46 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/datanucleus-rdbms-4.1.19.jar' for reading
	25/08/13 02:44:46 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/datasketches-java-3.3.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/datasketches-java-3.3.0.jar
	25/08/13 02:44:46 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/datasketches-java-3.3.0.jar' for reading
	25/08/13 02:44:46 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/datasketches-memory-2.1.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/datasketches-memory-2.1.0.jar
	25/08/13 02:44:46 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/datasketches-memory-2.1.0.jar' for reading
	25/08/13 02:44:46 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/derby-10.14.2.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/derby-10.14.2.0.jar
	25/08/13 02:44:46 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/derby-10.14.2.0.jar' for reading
	25/08/13 02:44:47 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/disruptor-3.3.7.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/disruptor-3.3.7.jar
	25/08/13 02:44:47 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/disruptor-3.3.7.jar' for reading
	25/08/13 02:44:47 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar
	25/08/13 02:44:47 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar' for reading
	25/08/13 02:44:47 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/emr-spark-goodies.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/emr-spark-goodies.jar
	25/08/13 02:44:47 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/emr-spark-goodies.jar' for reading
	25/08/13 02:44:47 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/emrfs-hadoop-assembly-2.66.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/emrfs-hadoop-assembly-2.66.0.jar
	25/08/13 02:44:47 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/emrfs-hadoop-assembly-2.66.0.jar' for reading
[INFO] 2025-08-13 02:44:48.467 +0000 -  ->
	25/08/13 02:44:47 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/error_prone_annotations-2.1.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/error_prone_annotations-2.1.3.jar
	25/08/13 02:44:47 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/error_prone_annotations-2.1.3.jar' for reading
	25/08/13 02:44:47 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/error_prone_annotations-2.18.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/error_prone_annotations-2.18.0.jar
	25/08/13 02:44:47 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/error_prone_annotations-2.18.0.jar' for reading
	25/08/13 02:44:47 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/findbugs-annotations-3.0.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/findbugs-annotations-3.0.1.jar
	25/08/13 02:44:47 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/findbugs-annotations-3.0.1.jar' for reading
	25/08/13 02:44:47 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/flatbuffers-java-1.12.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/flatbuffers-java-1.12.0.jar
	25/08/13 02:44:47 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/flatbuffers-java-1.12.0.jar' for reading
	25/08/13 02:44:47 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/gmetric4j-1.0.10.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/gmetric4j-1.0.10.jar
	25/08/13 02:44:47 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/gmetric4j-1.0.10.jar' for reading
	25/08/13 02:44:47 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/grpc-api-1.56.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/grpc-api-1.56.0.jar
	25/08/13 02:44:47 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/grpc-api-1.56.0.jar' for reading
	25/08/13 02:44:48 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/grpc-context-1.56.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/grpc-context-1.56.0.jar
	25/08/13 02:44:48 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/grpc-context-1.56.0.jar' for reading
	25/08/13 02:44:48 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/grpc-core-1.56.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/grpc-core-1.56.0.jar
	25/08/13 02:44:48 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/grpc-core-1.56.0.jar' for reading
	25/08/13 02:44:48 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/grpc-netty-1.56.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/grpc-netty-1.56.0.jar
	25/08/13 02:44:48 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/grpc-netty-1.56.0.jar' for reading
	25/08/13 02:44:48 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/grpc-protobuf-1.56.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/grpc-protobuf-1.56.0.jar
	25/08/13 02:44:48 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/grpc-protobuf-1.56.0.jar' for reading
	25/08/13 02:44:48 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/grpc-protobuf-lite-1.56.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/grpc-protobuf-lite-1.56.0.jar
	25/08/13 02:44:48 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/grpc-protobuf-lite-1.56.0.jar' for reading
	25/08/13 02:44:48 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/grpc-services-1.56.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/grpc-services-1.56.0.jar
	25/08/13 02:44:48 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/grpc-services-1.56.0.jar' for reading
[INFO] 2025-08-13 02:44:49.468 +0000 -  ->
	25/08/13 02:44:48 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/grpc-stub-1.56.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/grpc-stub-1.56.0.jar
	25/08/13 02:44:48 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/grpc-stub-1.56.0.jar' for reading
	25/08/13 02:44:48 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/gson-2.10.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/gson-2.10.1.jar
	25/08/13 02:44:48 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/gson-2.10.1.jar' for reading
	25/08/13 02:44:48 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/guava-14.0.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/guava-14.0.1.jar
	25/08/13 02:44:48 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/guava-14.0.1.jar' for reading
	25/08/13 02:44:49 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hadoop-client-api-3.4.0-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hadoop-client-api-3.4.0-amzn-1.jar
	25/08/13 02:44:49 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hadoop-client-api-3.4.0-amzn-1.jar' for reading
	25/08/13 02:44:49 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hadoop-client-runtime-3.4.0-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hadoop-client-runtime-3.4.0-amzn-1.jar
[INFO] 2025-08-13 02:44:50.469 +0000 -  ->
	25/08/13 02:44:49 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hadoop-client-runtime-3.4.0-amzn-1.jar' for reading
	25/08/13 02:44:50 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hadoop-shaded-guava-1.2.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hadoop-shaded-guava-1.2.0.jar
	25/08/13 02:44:50 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hadoop-shaded-guava-1.2.0.jar' for reading
	25/08/13 02:44:50 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hadoop-yarn-server-web-proxy-3.4.0-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hadoop-yarn-server-web-proxy-3.4.0-amzn-1.jar
	25/08/13 02:44:50 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hadoop-yarn-server-web-proxy-3.4.0-amzn-1.jar' for reading
	25/08/13 02:44:50 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-beeline-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-beeline-2.3.9-amzn-4.jar
	25/08/13 02:44:50 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-beeline-2.3.9-amzn-4.jar' for reading
	25/08/13 02:44:50 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-cli-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-cli-2.3.9-amzn-4.jar
	25/08/13 02:44:50 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-cli-2.3.9-amzn-4.jar' for reading
	25/08/13 02:44:50 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-common-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-common-2.3.9-amzn-4.jar
	25/08/13 02:44:50 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-common-2.3.9-amzn-4.jar' for reading
[INFO] 2025-08-13 02:44:51.470 +0000 -  ->
	25/08/13 02:44:50 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-exec-2.3.9-amzn-4-core.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-exec-2.3.9-amzn-4-core.jar
	25/08/13 02:44:50 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-exec-2.3.9-amzn-4-core.jar' for reading
	25/08/13 02:44:50 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-jdbc-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-jdbc-2.3.9-amzn-4.jar
	25/08/13 02:44:50 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-jdbc-2.3.9-amzn-4.jar' for reading
	25/08/13 02:44:50 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-llap-common-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-llap-common-2.3.9-amzn-4.jar
	25/08/13 02:44:50 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-llap-common-2.3.9-amzn-4.jar' for reading
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-metastore-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-metastore-2.3.9-amzn-4.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-metastore-2.3.9-amzn-4.jar' for reading
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-serde-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-serde-2.3.9-amzn-4.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-serde-2.3.9-amzn-4.jar' for reading
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-service-rpc-3.1.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-service-rpc-3.1.3.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-service-rpc-3.1.3.jar' for reading
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-shims-0.23-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-shims-0.23-2.3.9-amzn-4.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-shims-0.23-2.3.9-amzn-4.jar' for reading
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-shims-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-shims-2.3.9-amzn-4.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-shims-2.3.9-amzn-4.jar' for reading
[INFO] 2025-08-13 02:44:52.471 +0000 -  ->
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-shims-common-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-shims-common-2.3.9-amzn-4.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-shims-common-2.3.9-amzn-4.jar' for reading
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-shims-scheduler-2.3.9-amzn-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-shims-scheduler-2.3.9-amzn-4.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-shims-scheduler-2.3.9-amzn-4.jar' for reading
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hive-storage-api-2.8.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-storage-api-2.8.1.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hive-storage-api-2.8.1.jar' for reading
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hk2-api-2.6.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hk2-api-2.6.1.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hk2-api-2.6.1.jar' for reading
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hk2-locator-2.6.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hk2-locator-2.6.1.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hk2-locator-2.6.1.jar' for reading
	25/08/13 02:44:51 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/hk2-utils-2.6.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hk2-utils-2.6.1.jar
	25/08/13 02:44:51 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/hk2-utils-2.6.1.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/httpclient-4.5.13.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/httpclient-4.5.13.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/httpclient-4.5.13.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/httpcore-4.4.13.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/httpcore-4.4.13.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/httpcore-4.4.13.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/istack-commons-runtime-3.0.8.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/istack-commons-runtime-3.0.8.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/istack-commons-runtime-3.0.8.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/ivy-2.5.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/ivy-2.5.1.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/ivy-2.5.1.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/j2objc-annotations-1.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/j2objc-annotations-1.1.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/j2objc-annotations-1.1.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jackson-annotations-2.15.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jackson-annotations-2.15.2.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jackson-annotations-2.15.2.jar' for reading
[INFO] 2025-08-13 02:44:53.472 +0000 -  ->
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jackson-core-2.15.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jackson-core-2.15.2.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jackson-core-2.15.2.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jackson-core-asl-1.9.13.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jackson-core-asl-1.9.13.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jackson-core-asl-1.9.13.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jackson-databind-2.15.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jackson-databind-2.15.2.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jackson-databind-2.15.2.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jackson-dataformat-yaml-2.15.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jackson-dataformat-yaml-2.15.2.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jackson-dataformat-yaml-2.15.2.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jackson-datatype-jsr310-2.15.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jackson-datatype-jsr310-2.15.2.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jackson-datatype-jsr310-2.15.2.jar' for reading
	25/08/13 02:44:52 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jackson-mapper-asl-1.9.13.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jackson-mapper-asl-1.9.13.jar
	25/08/13 02:44:52 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jackson-mapper-asl-1.9.13.jar' for reading
	25/08/13 02:44:53 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jackson-module-scala_2.12-2.15.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jackson-module-scala_2.12-2.15.2.jar
	25/08/13 02:44:53 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jackson-module-scala_2.12-2.15.2.jar' for reading
	25/08/13 02:44:53 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.annotation-api-1.3.5.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jakarta.annotation-api-1.3.5.jar
	25/08/13 02:44:53 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.annotation-api-1.3.5.jar' for reading
	25/08/13 02:44:53 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.inject-2.6.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jakarta.inject-2.6.1.jar
	25/08/13 02:44:53 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.inject-2.6.1.jar' for reading
	25/08/13 02:44:53 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.servlet-api-4.0.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jakarta.servlet-api-4.0.3.jar
	25/08/13 02:44:53 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.servlet-api-4.0.3.jar' for reading
	25/08/13 02:44:53 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.validation-api-2.0.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jakarta.validation-api-2.0.2.jar
	25/08/13 02:44:53 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.validation-api-2.0.2.jar' for reading
[INFO] 2025-08-13 02:44:54.473 +0000 -  ->
	25/08/13 02:44:53 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.ws.rs-api-2.1.6.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jakarta.ws.rs-api-2.1.6.jar
	25/08/13 02:44:53 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.ws.rs-api-2.1.6.jar' for reading
	25/08/13 02:44:53 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.xml.bind-api-2.3.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jakarta.xml.bind-api-2.3.2.jar
	25/08/13 02:44:53 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jakarta.xml.bind-api-2.3.2.jar' for reading
	25/08/13 02:44:53 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/janino-3.1.9.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/janino-3.1.9.jar
	25/08/13 02:44:53 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/janino-3.1.9.jar' for reading
	25/08/13 02:44:53 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/javassist-3.29.2-GA.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/javassist-3.29.2-GA.jar
	25/08/13 02:44:53 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/javassist-3.29.2-GA.jar' for reading
	25/08/13 02:44:53 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/javax.inject-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/javax.inject-1.jar
	25/08/13 02:44:53 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/javax.inject-1.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/javax.jdo-3.2.0-m3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/javax.jdo-3.2.0-m3.jar
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/javax.jdo-3.2.0-m3.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/javax.servlet-api-3.1.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/javax.servlet-api-3.1.0.jar
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/javax.servlet-api-3.1.0.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/javolution-5.5.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/javolution-5.5.1.jar
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/javolution-5.5.1.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jaxb-runtime-2.3.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jaxb-runtime-2.3.2.jar
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jaxb-runtime-2.3.2.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jcl-over-slf4j-2.0.7.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jcl-over-slf4j-2.0.7.jar
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jcl-over-slf4j-2.0.7.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jdo-api-3.0.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jdo-api-3.0.1.jar
[INFO] 2025-08-13 02:44:55.474 +0000 -  ->
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jdo-api-3.0.1.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jersey-client-2.40.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jersey-client-2.40.jar
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jersey-client-2.40.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jersey-common-2.40.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jersey-common-2.40.jar
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jersey-common-2.40.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jersey-container-servlet-2.40.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jersey-container-servlet-2.40.jar
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jersey-container-servlet-2.40.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jersey-container-servlet-core-2.40.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jersey-container-servlet-core-2.40.jar
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jersey-container-servlet-core-2.40.jar' for reading
	25/08/13 02:44:54 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jersey-hk2-2.40.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jersey-hk2-2.40.jar
	25/08/13 02:44:54 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jersey-hk2-2.40.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jersey-server-2.40.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jersey-server-2.40.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jersey-server-2.40.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jetty-rewrite-9.3.27.v20190418.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jetty-rewrite-9.3.27.v20190418.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jetty-rewrite-9.3.27.v20190418.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jline-2.14.6.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jline-2.14.6.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jline-2.14.6.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jmespath-java-1.12.705.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jmespath-java-1.12.705.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jmespath-java-1.12.705.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/joda-time-2.12.5.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/joda-time-2.12.5.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/joda-time-2.12.5.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jodd-core-3.5.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jodd-core-3.5.2.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jodd-core-3.5.2.jar' for reading
[INFO] 2025-08-13 02:44:56.475 +0000 -  ->
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jpam-1.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jpam-1.1.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jpam-1.1.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/json-1.8.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/json-1.8.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/json-1.8.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/json4s-ast_2.12-3.7.0-M11.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/json4s-ast_2.12-3.7.0-M11.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/json4s-ast_2.12-3.7.0-M11.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/json4s-core_2.12-3.7.0-M11.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/json4s-core_2.12-3.7.0-M11.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/json4s-core_2.12-3.7.0-M11.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/json4s-jackson_2.12-3.7.0-M11.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/json4s-jackson_2.12-3.7.0-M11.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/json4s-jackson_2.12-3.7.0-M11.jar' for reading
	25/08/13 02:44:55 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/json4s-scalap_2.12-3.7.0-M11.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/json4s-scalap_2.12-3.7.0-M11.jar
	25/08/13 02:44:55 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/json4s-scalap_2.12-3.7.0-M11.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jsr305-3.0.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jsr305-3.0.0.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jsr305-3.0.0.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jsr305-3.0.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jsr305-3.0.2.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jsr305-3.0.2.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jta-1.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jta-1.1.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jta-1.1.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/jul-to-slf4j-2.0.7.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/jul-to-slf4j-2.0.7.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/jul-to-slf4j-2.0.7.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/kryo-shaded-4.0.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/kryo-shaded-4.0.2.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/kryo-shaded-4.0.2.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/lapack-3.0.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/lapack-3.0.3.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/lapack-3.0.3.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/leveldbjni-all-1.8.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/leveldbjni-all-1.8.jar
[INFO] 2025-08-13 02:44:57.477 +0000 -  ->
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/leveldbjni-all-1.8.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/libfb303-0.9.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/libfb303-0.9.3.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/libfb303-0.9.3.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/libthrift-0.12.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/libthrift-0.12.0.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/libthrift-0.12.0.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/log4j-1.2-api-2.20.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/log4j-1.2-api-2.20.0.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/log4j-1.2-api-2.20.0.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/log4j-api-2.20.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/log4j-api-2.20.0.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/log4j-api-2.20.0.jar' for reading
	25/08/13 02:44:56 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/log4j-core-2.20.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/log4j-core-2.20.0.jar
	25/08/13 02:44:56 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/log4j-core-2.20.0.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/log4j-slf4j2-impl-2.20.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/log4j-slf4j2-impl-2.20.0.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/log4j-slf4j2-impl-2.20.0.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/logging-interceptor-3.12.12.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/logging-interceptor-3.12.12.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/logging-interceptor-3.12.12.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/lz4-java-1.8.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/lz4-java-1.8.0.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/lz4-java-1.8.0.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/mariadb-connector-java.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/mariadb-connector-java.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/mariadb-connector-java.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/metrics-core-4.2.19.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/metrics-core-4.2.19.jar
[INFO] 2025-08-13 02:44:58.479 +0000 -  ->
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/metrics-graphite-4.2.19.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/metrics-graphite-4.2.19.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/metrics-graphite-4.2.19.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/metrics-jmx-4.2.19.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/metrics-jmx-4.2.19.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/metrics-jmx-4.2.19.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/metrics-json-4.2.19.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/metrics-json-4.2.19.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/metrics-json-4.2.19.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/metrics-jvm-4.2.19.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/metrics-jvm-4.2.19.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/metrics-jvm-4.2.19.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/minlog-1.3.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/minlog-1.3.0.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/minlog-1.3.0.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-all-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-all-4.1.100.Final.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-all-4.1.100.Final.jar' for reading
	25/08/13 02:44:57 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-buffer-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-buffer-4.1.100.Final.jar
	25/08/13 02:44:57 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-buffer-4.1.100.Final.jar' for reading
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-codec-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-codec-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-codec-4.1.100.Final.jar' for reading
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-codec-http-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-codec-http-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-codec-http-4.1.100.Final.jar' for reading
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-codec-http2-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-codec-http2-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-codec-http2-4.1.100.Final.jar' for reading
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-codec-socks-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-codec-socks-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-codec-socks-4.1.100.Final.jar' for reading
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-common-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-common-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-common-4.1.100.Final.jar' for reading
[INFO] 2025-08-13 02:44:59.480 +0000 -  ->
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-handler-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-handler-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-handler-4.1.100.Final.jar' for reading
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-handler-proxy-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-handler-proxy-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-handler-proxy-4.1.100.Final.jar' for reading
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-resolver-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-resolver-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-resolver-4.1.100.Final.jar' for reading
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-transport-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-4.1.100.Final.jar' for reading
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-classes-epoll-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-transport-classes-epoll-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-classes-epoll-4.1.100.Final.jar' for reading
	25/08/13 02:44:58 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-classes-kqueue-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-transport-classes-kqueue-4.1.100.Final.jar
	25/08/13 02:44:58 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-classes-kqueue-4.1.100.Final.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-native-epoll-4.1.100.Final-linux-aarch_64.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-transport-native-epoll-4.1.100.Final-linux-aarch_64.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-native-epoll-4.1.100.Final-linux-aarch_64.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-native-kqueue-4.1.100.Final-osx-aarch_64.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-transport-native-kqueue-4.1.100.Final-osx-aarch_64.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-native-kqueue-4.1.100.Final-osx-aarch_64.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-native-unix-common-4.1.100.Final.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/netty-transport-native-unix-common-4.1.100.Final.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/netty-transport-native-unix-common-4.1.100.Final.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/objenesis-2.5.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/objenesis-2.5.1.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/objenesis-2.5.1.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/objenesis-3.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/objenesis-3.3.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/objenesis-3.3.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/okhttp-3.12.12.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/okhttp-3.12.12.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/okhttp-3.12.12.jar' for reading
[INFO] 2025-08-13 02:45:00.481 +0000 -  ->
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/okio-1.15.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/okio-1.15.0.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/okio-1.15.0.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/opencsv-2.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/opencsv-2.3.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/opencsv-2.3.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/orc-core-1.9.4-shaded-protobuf.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/orc-core-1.9.4-shaded-protobuf.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/orc-core-1.9.4-shaded-protobuf.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/orc-mapreduce-1.9.4-shaded-protobuf.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/orc-mapreduce-1.9.4-shaded-protobuf.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/orc-mapreduce-1.9.4-shaded-protobuf.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/orc-shims-1.9.4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/orc-shims-1.9.4.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/orc-shims-1.9.4.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/oro-2.0.8.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/oro-2.0.8.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/oro-2.0.8.jar' for reading
	25/08/13 02:44:59 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/osgi-resource-locator-1.0.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/osgi-resource-locator-1.0.3.jar
	25/08/13 02:44:59 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/osgi-resource-locator-1.0.3.jar' for reading
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/paranamer-2.8.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/paranamer-2.8.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/paranamer-2.8.jar' for reading
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/parquet-column-1.13.1-amzn-3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/parquet-column-1.13.1-amzn-3.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/parquet-column-1.13.1-amzn-3.jar' for reading
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/parquet-common-1.13.1-amzn-3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/parquet-common-1.13.1-amzn-3.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/parquet-common-1.13.1-amzn-3.jar' for reading
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/parquet-encoding-1.13.1-amzn-3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/parquet-encoding-1.13.1-amzn-3.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/parquet-encoding-1.13.1-amzn-3.jar' for reading
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/parquet-format-structures-1.13.1-amzn-3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/parquet-format-structures-1.13.1-amzn-3.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/parquet-format-structures-1.13.1-amzn-3.jar' for reading
[INFO] 2025-08-13 02:45:01.482 +0000 -  ->
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/parquet-hadoop-1.13.1-amzn-3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/parquet-hadoop-1.13.1-amzn-3.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/parquet-hadoop-1.13.1-amzn-3.jar' for reading
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/parquet-jackson-1.13.1-amzn-3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/parquet-jackson-1.13.1-amzn-3.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/parquet-jackson-1.13.1-amzn-3.jar' for reading
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/perfmark-api-0.26.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/perfmark-api-0.26.0.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/perfmark-api-0.26.0.jar' for reading
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/pickle-1.3.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/pickle-1.3.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/pickle-1.3.jar' for reading
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/proto-google-common-protos-2.17.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/proto-google-common-protos-2.17.0.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/proto-google-common-protos-2.17.0.jar' for reading
	25/08/13 02:45:00 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/py4j-0.10.9.7.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/py4j-0.10.9.7.jar
	25/08/13 02:45:00 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/py4j-0.10.9.7.jar' for reading
	25/08/13 02:45:01 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/remotetea-oncrpc-1.1.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/remotetea-oncrpc-1.1.2.jar
	25/08/13 02:45:01 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/remotetea-oncrpc-1.1.2.jar' for reading
	25/08/13 02:45:01 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/rocksdbjni-8.3.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/rocksdbjni-8.3.2.jar
	25/08/13 02:45:01 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/rocksdbjni-8.3.2.jar' for reading
[INFO] 2025-08-13 02:45:02.484 +0000 -  ->
	25/08/13 02:45:02 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/scala-collection-compat_2.12-2.7.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/scala-collection-compat_2.12-2.7.0.jar
	25/08/13 02:45:02 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/scala-collection-compat_2.12-2.7.0.jar' for reading
	25/08/13 02:45:02 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/scala-compiler-2.12.18.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/scala-compiler-2.12.18.jar
	25/08/13 02:45:02 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/scala-compiler-2.12.18.jar' for reading
	25/08/13 02:45:02 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/scala-library-2.12.18.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/scala-library-2.12.18.jar
	25/08/13 02:45:02 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/scala-library-2.12.18.jar' for reading
	25/08/13 02:45:02 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/scala-parser-combinators_2.12-2.3.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/scala-parser-combinators_2.12-2.3.0.jar
[INFO] 2025-08-13 02:45:03.484 +0000 -  ->
	25/08/13 02:45:02 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/scala-reflect-2.12.18.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/scala-reflect-2.12.18.jar
	25/08/13 02:45:02 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/scala-reflect-2.12.18.jar' for reading
	25/08/13 02:45:02 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/scala-xml_2.12-2.1.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/scala-xml_2.12-2.1.0.jar
	25/08/13 02:45:02 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/scala-xml_2.12-2.1.0.jar' for reading
	25/08/13 02:45:02 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/shims-0.9.45.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/shims-0.9.45.jar
	25/08/13 02:45:02 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/shims-0.9.45.jar' for reading
	25/08/13 02:45:02 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/slf4j-api-2.0.7.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/slf4j-api-2.0.7.jar
	25/08/13 02:45:02 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/slf4j-api-2.0.7.jar' for reading
	25/08/13 02:45:02 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/snakeyaml-2.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/snakeyaml-2.1.jar
	25/08/13 02:45:02 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/snakeyaml-2.1.jar' for reading
	25/08/13 02:45:02 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/snakeyaml-engine-2.6.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/snakeyaml-engine-2.6.jar
	25/08/13 02:45:02 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/snakeyaml-engine-2.6.jar' for reading
	25/08/13 02:45:03 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/snappy-java-1.1.10.5.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/snappy-java-1.1.10.5.jar
	25/08/13 02:45:03 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/snappy-java-1.1.10.5.jar' for reading
	25/08/13 02:45:03 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-acl-1.0.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-acl-1.0.0.jar
	25/08/13 02:45:03 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-acl-1.0.0.jar' for reading
	25/08/13 02:45:03 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-catalyst_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-catalyst_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:03 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-catalyst_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:03 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-common-utils_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-common-utils_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:03 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-common-utils_2.12-3.5.2-amzn-1.jar' for reading
[INFO] 2025-08-13 02:45:04.485 +0000 -  ->
	25/08/13 02:45:03 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-core_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-core_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:03 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-core_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:03 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-fgac-iceberg_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-fgac-iceberg_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:03 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-fgac-iceberg_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:03 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-fgac_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-fgac_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:03 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-fgac_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:04 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-ganglia-lgpl_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-ganglia-lgpl_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:04 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-ganglia-lgpl_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:04 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-graphx_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-graphx_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:04 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-graphx_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:04 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-hive-thriftserver_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-hive-thriftserver_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:04 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-hive-thriftserver_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:04 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-hive_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-hive_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:04 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-hive_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:04 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-kvstore_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-kvstore_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:04 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-kvstore_2.12-3.5.2-amzn-1.jar' for reading
[INFO] 2025-08-13 02:45:05.486 +0000 -  ->
	25/08/13 02:45:04 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-launcher_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-launcher_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:04 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-launcher_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:04 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-mllib-local_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-mllib-local_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:04 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-mllib-local_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:04 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-mllib_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-mllib_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:04 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-mllib_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:04 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-network-common_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-network-common_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:04 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-network-common_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:04 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-network-shuffle_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-network-shuffle_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-network-shuffle_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:05 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-repl_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-repl_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-repl_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:05 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-sketch_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-sketch_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-sketch_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:05 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-sql-api_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-sql-api_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-sql-api_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:05 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-sql_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-sql_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-sql_2.12-3.5.2-amzn-1.jar' for reading
[INFO] 2025-08-13 02:45:06.487 +0000 -  ->
	25/08/13 02:45:05 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-streaming_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-streaming_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-streaming_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:05 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-tags_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-tags_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-tags_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:05 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-unsafe_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-unsafe_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-unsafe_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:05 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spark-yarn_2.12-3.5.2-amzn-1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spark-yarn_2.12-3.5.2-amzn-1.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spark-yarn_2.12-3.5.2-amzn-1.jar' for reading
	25/08/13 02:45:05 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spire-macros_2.12-0.17.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spire-macros_2.12-0.17.0.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spire-macros_2.12-0.17.0.jar' for reading
	25/08/13 02:45:05 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spire-platform_2.12-0.17.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spire-platform_2.12-0.17.0.jar
	25/08/13 02:45:05 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spire-platform_2.12-0.17.0.jar' for reading
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spire-util_2.12-0.17.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spire-util_2.12-0.17.0.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spire-util_2.12-0.17.0.jar' for reading
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/spire_2.12-0.17.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/spire_2.12-0.17.0.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/spire_2.12-0.17.0.jar' for reading
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/stax-api-1.0.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/stax-api-1.0.1.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/stax-api-1.0.1.jar' for reading
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/stream-2.9.6.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/stream-2.9.6.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/stream-2.9.6.jar' for reading
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/super-csv-2.2.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/super-csv-2.2.0.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/super-csv-2.2.0.jar' for reading
[INFO] 2025-08-13 02:45:07.489 +0000 -  ->
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/threeten-extra-1.7.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/threeten-extra-1.7.1.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/threeten-extra-1.7.1.jar' for reading
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/tink-1.9.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/tink-1.9.0.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/tink-1.9.0.jar' for reading
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/transaction-api-1.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/transaction-api-1.1.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/transaction-api-1.1.jar' for reading
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/univocity-parsers-2.9.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/univocity-parsers-2.9.1.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/univocity-parsers-2.9.1.jar' for reading
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/volcano-client-6.7.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/volcano-client-6.7.2.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/volcano-client-6.7.2.jar' for reading
	25/08/13 02:45:06 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/volcano-model-v1beta1-6.7.2.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/volcano-model-v1beta1-6.7.2.jar
	25/08/13 02:45:06 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/volcano-model-v1beta1-6.7.2.jar' for reading
	25/08/13 02:45:07 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/xbean-asm9-shaded-4.23.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/xbean-asm9-shaded-4.23.jar
	25/08/13 02:45:07 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/xbean-asm9-shaded-4.23.jar' for reading
	25/08/13 02:45:07 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/xz-1.9.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/xz-1.9.jar
	25/08/13 02:45:07 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/xz-1.9.jar' for reading
	25/08/13 02:45:07 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/zjsonpatch-0.3.0.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/zjsonpatch-0.3.0.jar
	25/08/13 02:45:07 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/zjsonpatch-0.3.0.jar' for reading
	25/08/13 02:45:07 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/zookeeper-3.9.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/zookeeper-3.9.1.jar
	25/08/13 02:45:07 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/zookeeper-3.9.1.jar' for reading
	25/08/13 02:45:07 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/zookeeper-jute-3.9.1.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/zookeeper-jute-3.9.1.jar
	25/08/13 02:45:07 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/zookeeper-jute-3.9.1.jar' for reading
	25/08/13 02:45:07 INFO Client: Uploading resource s3://exchanges-flink-prod/batch/emr/spark-jars/zstd-jni-1.5.5-4.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/zstd-jni-1.5.5-4.jar
	25/08/13 02:45:07 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/batch/emr/spark-jars/zstd-jni-1.5.5-4.jar' for reading
[INFO] 2025-08-13 02:45:08.490 +0000 -  ->
	25/08/13 02:45:07 INFO Client: Uploading resource s3://exchanges-flink-prod/dolphinscheduler/default/resources/connectors/mysql-connector-j-8.0.33.jar -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/mysql-connector-j-8.0.33.jar
	25/08/13 02:45:07 INFO S3NativeFileSystem: Opening 's3://exchanges-flink-prod/dolphinscheduler/default/resources/connectors/mysql-connector-j-8.0.33.jar' for reading
	25/08/13 02:45:07 INFO Client: Uploading resource file:/etc/spark/conf/hive-site.xml -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hive-site.xml
	25/08/13 02:45:07 INFO Client: Uploading resource file:/etc/hudi/conf/hudi-defaults.conf -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/hudi-defaults.conf
	25/08/13 02:45:07 INFO Client: Uploading resource file:/mnt/spark/python/lib/pyspark.zip -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/pyspark.zip
	25/08/13 02:45:07 INFO Client: Uploading resource file:/mnt/spark/python/lib/py4j-0.10.9.7-src.zip -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/py4j-0.10.9.7-src.zip
	25/08/13 02:45:07 INFO Client: Uploading resource file:/tmp/spark-9a3a8491-a31d-4428-8132-4fb471e7887e/__spark_conf__11448002122645098213.zip -> hdfs://ha-nn-uri/user/root/.sparkStaging/application_1754991343133_0517/__spark_conf__.zip
	25/08/13 02:45:07 INFO SecurityManager: Changing view acls to: root
	25/08/13 02:45:07 INFO SecurityManager: Changing modify acls to: root
	25/08/13 02:45:07 INFO SecurityManager: Changing view acls groups to:
	25/08/13 02:45:07 INFO SecurityManager: Changing modify acls groups to:
	25/08/13 02:45:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
	25/08/13 02:45:07 INFO Client: Submitting application application_1754991343133_0517 to ResourceManager
	25/08/13 02:45:08 INFO YarnClientImpl: Submitted application application_1754991343133_0517
[INFO] 2025-08-13 02:45:09.491 +0000 -  ->
	25/08/13 02:45:09 INFO Client: Application report for application_1754991343133_0517 (state: ACCEPTED)
	25/08/13 02:45:09 INFO Client:
		 client token: N/A
		 diagnostics: AM container is launched, waiting for AM container to Register with RM
		 ApplicationMaster host: N/A
		 ApplicationMaster RPC port: -1
		 queue: root.default
		 start time: 1755053107886
		 final status: UNDEFINED
		 tracking URL: http://ip-172-24-13-28.ap-southeast-1.compute.internal:20888/proxy/application_1754991343133_0517/
		 user: root
[INFO] 2025-08-13 02:45:15.492 +0000 -  ->
	25/08/13 02:45:14 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-24-13-28.ap-southeast-1.compute.internal, PROXY_URI_BASES -> http://ip-172-24-13-28.ap-southeast-1.compute.internal:20888/proxy/application_1754991343133_0517, RM_HA_URLS -> ip-172-24-13-28.ap-southeast-1.compute.internal:8088,ip-172-24-13-23.ap-southeast-1.compute.internal:8088,ip-172-24-14-248.ap-southeast-1.compute.internal:8088), /proxy/application_1754991343133_0517
	25/08/13 02:45:15 INFO Client: Application report for application_1754991343133_0517 (state: RUNNING)
	25/08/13 02:45:15 INFO Client:
		 client token: N/A
		 diagnostics: N/A
		 ApplicationMaster host: 172.24.13.8
		 ApplicationMaster RPC port: -1
		 queue: root.default
		 start time: 1755053107886
		 final status: UNDEFINED
		 tracking URL: http://ip-172-24-13-28.ap-southeast-1.compute.internal:20888/proxy/application_1754991343133_0517/
		 user: root
	25/08/13 02:45:15 INFO YarnClientSchedulerBackend: Application application_1754991343133_0517 has started running.
	25/08/13 02:45:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37119.
	25/08/13 02:45:15 INFO NettyBlockTransferService: Server created on ip-172-24-14-168.ap-southeast-1.compute.internal:37119
	25/08/13 02:45:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
	25/08/13 02:45:15 INFO BlockManager: external shuffle service port = 7337
	25/08/13 02:45:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-24-14-168.ap-southeast-1.compute.internal, 37119, None)
	25/08/13 02:45:15 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-24-14-168.ap-southeast-1.compute.internal:37119 with 127.2 MiB RAM, BlockManagerId(driver, ip-172-24-14-168.ap-southeast-1.compute.internal, 37119, None)
	25/08/13 02:45:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-24-14-168.ap-southeast-1.compute.internal, 37119, None)
	25/08/13 02:45:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-24-14-168.ap-southeast-1.compute.internal, 37119, None)
	25/08/13 02:45:15 INFO SingleEventLogFileWriter: Logging events to hdfs:/var/log/spark/apps/application_1754991343133_0517.inprogress
	25/08/13 02:45:15 INFO Utils: Using 100 preallocated executors (minExecutors: 0). Set spark.dynamicAllocation.preallocateExecutors to `false` disable executor preallocation.
	25/08/13 02:45:15 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /jobs: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /jobs/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /jobs/job: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /jobs/job/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /stages: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /stages/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /stages/stage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /stages/stage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /stages/pool: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /stages/pool/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /storage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /storage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /storage/rdd: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /storage/rdd/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /environment: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /environment/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /executors: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /executors/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /executors/threadDump: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /executors/threadDump/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /executors/heapHistogram: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /executors/heapHistogram/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /static: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /api: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /jobs/job/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /stages/stage/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
	25/08/13 02:45:15 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
	✅ Spark会话创建完成，版本: 3.5.2-amzn-1
	MySQL配置: rm-3ns765y13i6wf0hp3.mysql.rds.aliyuncs.com:3358/biz_user
	🗄️  HiveMeta初始化完成，将使用分区: 2025-08-13
	🗄️  MysqlMeta初始化完成
	🔍 TagRuleParser初始化完成
	🚀 TagEngine初始化完成

	🎯 执行指定标签计算: [1, 2, 3, 4, 5, 6, 7, 8, 9]
	🚀 开始标签计算，模式: task-tags
	📋 加载标签规则...
	📋 加载标签规则，指定标签: [1, 2, 3, 4, 5, 6, 7, 8, 9]
[INFO] 2025-08-13 02:47:30.506 +0000 -  ->
	❌ 加载标签规则失败: An error occurred while calling o261.load.
	: com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure

	The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
		at com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:175)
		at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:64)
		at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:825)
		at com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:446)
		at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:239)
		at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:188)
		at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
		at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)
		at org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:160)
		at org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:156)
		at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:65)
		at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:60)
		at org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241)
		at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)
		at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)
		at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:345)
		at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:272)
		at org.apache.spark.sql.DataFrameReader.$anonfun$load$1(DataFrameReader.scala:210)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)
		at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
		at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.base/java.lang.reflect.Method.invoke(Method.java:569)
		at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
		at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
		at py4j.Gateway.invoke(Gateway.java:282)
		at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
		at py4j.commands.CallCommand.execute(CallCommand.java:79)
		at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
		at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
		at java.base/java.lang.Thread.run(Thread.java:840)
	Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure

	The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.
		at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
		at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
		at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
		at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
		at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
		at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:62)
		at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:105)
		at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:150)
		at com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:166)
		at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:89)
		at com.mysql.cj.NativeSession.connect(NativeSession.java:121)
		at com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:945)
		at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:815)
		... 30 more
	Caused by: java.net.ConnectException: Connection timed out
		at java.base/sun.nio.ch.Net.connect0(Native Method)
		at java.base/sun.nio.ch.Net.connect(Net.java:579)
		at java.base/sun.nio.ch.Net.connect(Net.java:568)
		at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:593)
		at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
		at java.base/java.net.Socket.connect(Socket.java:633)
		at com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:153)
		at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:63)
		... 33 more

[INFO] 2025-08-13 02:47:35.507 +0000 -  ->
	25/08/13 02:47:34 WARN TaskSetManager: Lost task 1.0 in stage 0.0 (TID 1) (ip-172-24-15-80.ap-southeast-1.compute.internal executor 101): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
	  File "/mnt3/yarn/usercache/root/appcache/application_1754991343133_0517/container_e03_1754991343133_0517_01_000159/pyspark.zip/pyspark/worker.py", line 1100, in main
	    raise PySparkRuntimeError(
	pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 9) than that in driver 3.12, PySpark cannot run with different minor versions.
	Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
		at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
		at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithoutKey_0$(Unknown Source)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
		at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:35)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hasNext(Unknown Source)
		at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:157)
		at org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)
		at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)
		at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
		at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)
		at org.apache.spark.scheduler.Task.run(Task.scala:152)
		at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
		at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)
		at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)
		at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
		at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
		at java.base/java.lang.Thread.run(Thread.java:840)

	25/08/13 02:47:34 ERROR TaskSetManager: Task 1 in stage 0.0 failed 4 times; aborting job
	❌ 标签计算异常: An error occurred while calling o278.count.
	: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 6) (ip-172-24-15-80.ap-southeast-1.compute.internal executor 101): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
	  File "/mnt3/yarn/usercache/root/appcache/application_1754991343133_0517/container_e03_1754991343133_0517_01_000159/pyspark.zip/pyspark/worker.py", line 1100, in main
	    raise PySparkRuntimeError(
	pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 9) than that in driver 3.12, PySpark cannot run with different minor versions.
	Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)
		at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)
		at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)
		at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
		at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithoutKey_0$(Unknown Source)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
		at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:35)
		at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hasNext(Unknown Source)
		at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:157)
		at org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)
		at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)
		at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
		at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)
		at org.apache.spark.scheduler.Task.run(Task.scala:152)
		at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
		at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)
		at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)
		at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
		at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
		at java.base/java.lang.Thread.run(Thread.java:840)

	Driver stacktrace:
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3083)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3019)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3018)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3018)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1324)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1324)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1324)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3301)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3235)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3224)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
		at org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.checkNoFailures(AdaptiveExecutor.scala:175)
		at org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.doRun(AdaptiveExecutor.scala:97)
		at org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.tryRunningAndGetFuture(AdaptiveExecutor.scala:75)
		at org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.execute(AdaptiveExecutor.scala:59)
		at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:290)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:901)
		at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:289)
		at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:583)
		at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:545)
		at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3662)
		at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3661)
		at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4392)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:711)
		at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4390)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:108)
		at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:384)
		at org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:157)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$10(SQLExecution.scala:220)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:108)
		at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:384)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$9(SQLExecution.scala:220)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:405)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:219)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:901)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:83)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:74)
		at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4390)
		at org.apache.spark.sql.Dataset.count(Dataset.scala:3661)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
		at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)