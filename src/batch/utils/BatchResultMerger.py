"""
æ‰¹å¤„ç†ç»“æœåˆå¹¶å™¨ - é‡æ„ä¸ºé©¼å³°å‘½åé£æ ¼
å®ç°ä¸MySQLç°æœ‰æ ‡ç­¾çš„æ™ºèƒ½åˆå¹¶ï¼Œæ”¯æŒæ ‡ç­¾æ•°ç»„åˆå¹¶å’Œå»é‡
"""

import logging
from typing import List, Dict, Any, Optional
from pyspark.sql import DataFrame, SparkSession
from pyspark.sql.functions import col, array_union, array_distinct, when, isnan, isnull, size
from pyspark import StorageLevel

from src.batch.config.BaseConfig import MySQLConfig

logger = logging.getLogger(__name__)


class BatchResultMerger:
    """æ‰¹å¤„ç†ç»“æœåˆå¹¶å™¨ï¼ˆåŸAdvancedTagMergerå’ŒUnifiedTagMergeråŠŸèƒ½ï¼‰"""
    
    def __init__(self, mysqlConfig: MySQLConfig):
        self.mysqlConfig = mysqlConfig
        self.logger = logging.getLogger(__name__)
    
    def mergeWithExistingTags(self, newTagsDataFrame: DataFrame, 
                             existingTagsDataFrame: Optional[DataFrame] = None) -> DataFrame:
        """
        å°†æ–°è®¡ç®—çš„æ ‡ç­¾ä¸MySQLç°æœ‰æ ‡ç­¾è¿›è¡Œæ™ºèƒ½åˆå¹¶
        
        Args:
            newTagsDataFrame: æ–°è®¡ç®—çš„æ ‡ç­¾æ•°æ® (user_id, tag_ids)
            existingTagsDataFrame: ç°æœ‰æ ‡ç­¾æ•°æ®ï¼ŒNoneæ—¶è‡ªåŠ¨åŠ è½½
            
        Returns:
            DataFrame: åˆå¹¶åçš„æ ‡ç­¾æ•°æ®
        """
        try:
            self.logger.info("ğŸ”„ å¼€å§‹æ ‡ç­¾åˆå¹¶...")
            
            # éªŒè¯æ–°æ ‡ç­¾æ•°æ®æ ¼å¼
            if not self._validateDataFrameFormat(newTagsDataFrame, ['user_id', 'tag_ids']):
                raise ValueError("æ–°æ ‡ç­¾æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
            
            # åŠ è½½ç°æœ‰æ ‡ç­¾æ•°æ®
            if existingTagsDataFrame is None:
                existingTagsDataFrame = self._loadExistingTags()
            
            # å¦‚æœæ²¡æœ‰ç°æœ‰æ ‡ç­¾ï¼Œç›´æ¥è¿”å›æ–°æ ‡ç­¾
            if existingTagsDataFrame is None or existingTagsDataFrame.count() == 0:
                self.logger.info("â„¹ï¸ æ²¡æœ‰ç°æœ‰æ ‡ç­¾ï¼Œç›´æ¥ä½¿ç”¨æ–°æ ‡ç­¾")
                return self._formatFinalResult(newTagsDataFrame)
            
            # æ‰§è¡Œæ™ºèƒ½åˆå¹¶
            mergedDataFrame = self._performIntelligentMerge(newTagsDataFrame, existingTagsDataFrame)
            
            # è®°å½•åˆå¹¶ç»Ÿè®¡
            self._logMergeStatistics(newTagsDataFrame, existingTagsDataFrame, mergedDataFrame)
            
            return mergedDataFrame
            
        except Exception as e:
            self.logger.error(f"âŒ æ ‡ç­¾åˆå¹¶å¤±è´¥: {str(e)}")
            raise
    
    def _loadExistingTags(self) -> Optional[DataFrame]:
        """
        åŠ è½½ç°æœ‰æ ‡ç­¾æ•°æ®
        
        Returns:
            DataFrame: ç°æœ‰æ ‡ç­¾æ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            from src.batch.utils.RuleReader import RuleReader
            
            spark = SparkSession.getActiveSession()
            ruleReader = RuleReader(spark, self.mysqlConfig)
            
            existingDataFrame = ruleReader.loadExistingUserTags()
            
            if existingDataFrame is not None:
                # åªä¿ç•™éœ€è¦çš„åˆ—å¹¶é‡å‘½å
                cleanedDataFrame = existingDataFrame.select(
                    col("user_id"),
                    col("tag_ids_array").alias("existing_tag_ids")
                )
                
                recordCount = cleanedDataFrame.count()
                self.logger.info(f"âœ… åŠ è½½ç°æœ‰æ ‡ç­¾: {recordCount} ä¸ªç”¨æˆ·")
                return cleanedDataFrame
            else:
                self.logger.info("â„¹ï¸ æ²¡æœ‰ç°æœ‰æ ‡ç­¾æ•°æ®")
                return None
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ åŠ è½½ç°æœ‰æ ‡ç­¾å¤±è´¥: {str(e)}")
            return None
    
    def _performIntelligentMerge(self, newTagsDataFrame: DataFrame, 
                                existingTagsDataFrame: DataFrame) -> DataFrame:
        """
        æ‰§è¡Œæ™ºèƒ½æ ‡ç­¾åˆå¹¶
        
        Args:
            newTagsDataFrame: æ–°æ ‡ç­¾æ•°æ®
            existingTagsDataFrame: ç°æœ‰æ ‡ç­¾æ•°æ®
            
        Returns:
            DataFrame: åˆå¹¶åçš„æ•°æ®
        """
        try:
            self.logger.info("ğŸ§© æ‰§è¡Œæ™ºèƒ½æ ‡ç­¾åˆå¹¶...")
            
            # Left join: ä¿ç•™æ‰€æœ‰æ–°æ ‡ç­¾ç”¨æˆ·ï¼Œåˆå¹¶ç°æœ‰æ ‡ç­¾
            joinedDataFrame = newTagsDataFrame.join(
                existingTagsDataFrame,
                on="user_id",
                how="left"
            )
            
            # æ™ºèƒ½åˆå¹¶é€»è¾‘
            mergedDataFrame = joinedDataFrame.select(
                col("user_id"),
                when(col("existing_tag_ids").isNull(), col("tag_ids"))
                .otherwise(array_distinct(array_union(col("tag_ids"), col("existing_tag_ids"))))
                .alias("tag_ids")
            )
            
            # è¿‡æ»¤æ‰ç©ºæ ‡ç­¾çš„ç”¨æˆ·
            finalDataFrame = mergedDataFrame.filter(
                col("tag_ids").isNotNull() & (size(col("tag_ids")) > 0)
            )
            
            self.logger.info("âœ… æ™ºèƒ½æ ‡ç­¾åˆå¹¶å®Œæˆ")
            return finalDataFrame
            
        except Exception as e:
            self.logger.error(f"âŒ æ™ºèƒ½æ ‡ç­¾åˆå¹¶å¤±è´¥: {str(e)}")
            raise
    
    def _formatFinalResult(self, dataFrame: DataFrame) -> DataFrame:
        """
        æ ¼å¼åŒ–æœ€ç»ˆç»“æœ
        
        Args:
            dataFrame: è¾“å…¥æ•°æ®
            
        Returns:
            DataFrame: æ ¼å¼åŒ–åçš„æ•°æ®
        """
        try:
            # ç¡®ä¿æ ‡ç­¾æ•°ç»„å»é‡å¹¶è¿‡æ»¤ç©ºå€¼
            formattedDataFrame = dataFrame.select(
                col("user_id"),
                array_distinct(col("tag_ids")).alias("tag_ids")
            ).filter(
                col("tag_ids").isNotNull() & (size(col("tag_ids")) > 0)
            )
            
            return formattedDataFrame
            
        except Exception as e:
            self.logger.error(f"âŒ æ ¼å¼åŒ–ç»“æœå¤±è´¥: {str(e)}")
            raise
    
    def _validateDataFrameFormat(self, dataFrame: DataFrame, requiredColumns: List[str]) -> bool:
        """
        éªŒè¯DataFrameæ ¼å¼
        
        Args:
            dataFrame: è¦éªŒè¯çš„DataFrame
            requiredColumns: å¿…éœ€çš„åˆ—ååˆ—è¡¨
            
        Returns:
            bool: æ ¼å¼æ˜¯å¦æ­£ç¡®
        """
        try:
            if dataFrame is None:
                return False
            
            missingColumns = set(requiredColumns) - set(dataFrame.columns)
            if missingColumns:
                self.logger.error(f"âŒ ç¼ºå°‘å¿…éœ€åˆ—: {missingColumns}")
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ DataFrameæ ¼å¼éªŒè¯å¤±è´¥: {str(e)}")
            return False
    
    def _logMergeStatistics(self, newTagsDataFrame: DataFrame, 
                           existingTagsDataFrame: DataFrame, 
                           mergedDataFrame: DataFrame):
        """
        è®°å½•åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            newTagsDataFrame: æ–°æ ‡ç­¾æ•°æ®
            existingTagsDataFrame: ç°æœ‰æ ‡ç­¾æ•°æ®  
            mergedDataFrame: åˆå¹¶åæ•°æ®
        """
        try:
            newUsers = newTagsDataFrame.count()
            existingUsers = existingTagsDataFrame.count()
            finalUsers = mergedDataFrame.count()
            
            # è®¡ç®—åˆå¹¶ç”¨æˆ·æ•°ï¼ˆåŒæ—¶æœ‰æ–°æ ‡ç­¾å’Œæ—§æ ‡ç­¾çš„ç”¨æˆ·ï¼‰
            mergeJoinDataFrame = newTagsDataFrame.join(
                existingTagsDataFrame.select("user_id").distinct(),
                on="user_id",
                how="inner"
            )
            mergedUsers = mergeJoinDataFrame.count()
            
            statistics = {
                'new_tagged_users': newUsers,
                'existing_tagged_users': existingUsers,
                'merged_users': mergedUsers,
                'final_tagged_users': finalUsers,
                'new_only_users': newUsers - mergedUsers
            }
            
            self.logger.info(f"ğŸ“Š åˆå¹¶ç»Ÿè®¡: {statistics}")
            
            # è¯¦ç»†æ—¥å¿—
            self.logger.info(f"   ğŸ‘¥ æ–°å¢æ ‡ç­¾ç”¨æˆ·: {newUsers}")
            self.logger.info(f"   ğŸ“š ç°æœ‰æ ‡ç­¾ç”¨æˆ·: {existingUsers}")
            self.logger.info(f"   ğŸ”„ åˆå¹¶ç”¨æˆ·æ•°: {mergedUsers}")
            self.logger.info(f"   âœ¨ ä»…æ–°æ ‡ç­¾ç”¨æˆ·: {statistics['new_only_users']}")
            self.logger.info(f"   ğŸ¯ æœ€ç»ˆç”¨æˆ·æ€»æ•°: {finalUsers}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ è®°å½•åˆå¹¶ç»Ÿè®¡å¤±è´¥: {str(e)}")
    
    def mergeMultipleTagResults(self, tagResultsList: List[DataFrame]) -> DataFrame:
        """
        åˆå¹¶å¤šä¸ªæ ‡ç­¾è®¡ç®—ç»“æœ
        
        Args:
            tagResultsList: æ ‡ç­¾ç»“æœDataFrameåˆ—è¡¨
            
        Returns:
            DataFrame: åˆå¹¶åçš„ç»“æœ
        """
        try:
            if not tagResultsList:
                raise ValueError("æ ‡ç­¾ç»“æœåˆ—è¡¨ä¸ºç©º")
            
            self.logger.info(f"ğŸ”— åˆå¹¶ {len(tagResultsList)} ä¸ªæ ‡ç­¾ç»“æœ...")
            
            # éªŒè¯æ‰€æœ‰DataFrameæ ¼å¼
            for i, df in enumerate(tagResultsList):
                if not self._validateDataFrameFormat(df, ['user_id', 'tag_id']):
                    raise ValueError(f"ç¬¬ {i+1} ä¸ªæ ‡ç­¾ç»“æœæ ¼å¼ä¸æ­£ç¡®")
            
            # åˆå¹¶æ‰€æœ‰ç»“æœ
            allResults = None
            for tagResult in tagResultsList:
                if allResults is None:
                    allResults = tagResult
                else:
                    allResults = allResults.union(tagResult)
            
            # æŒ‰ç”¨æˆ·èšåˆæ ‡ç­¾
            from pyspark.sql.functions import collect_list, array_distinct
            
            aggregatedResult = allResults.groupBy("user_id").agg(
                array_distinct(collect_list("tag_id")).alias("tag_ids")
            )
            
            finalCount = aggregatedResult.count()
            self.logger.info(f"âœ… å¤šæ ‡ç­¾ç»“æœåˆå¹¶å®Œæˆ: {finalCount} ä¸ªç”¨æˆ·")
            
            return aggregatedResult
            
        except Exception as e:
            self.logger.error(f"âŒ å¤šæ ‡ç­¾ç»“æœåˆå¹¶å¤±è´¥: {str(e)}")
            raise
    
    def getDetailedMergeTrace(self, newTagsDataFrame: DataFrame, 
                             existingTagsDataFrame: Optional[DataFrame] = None,
                             sampleCount: int = 5) -> Dict[str, Any]:
        """
        è·å–è¯¦ç»†çš„åˆå¹¶è¿½è¸ªä¿¡æ¯
        
        Args:
            newTagsDataFrame: æ–°æ ‡ç­¾æ•°æ®
            existingTagsDataFrame: ç°æœ‰æ ‡ç­¾æ•°æ®
            sampleCount: æŠ½æ ·ç”¨æˆ·æ•°é‡
            
        Returns:
            Dict[str, Any]: è¯¦ç»†è¿½è¸ªä¿¡æ¯
        """
        try:
            self.logger.info(f"ğŸ” ç”Ÿæˆè¯¦ç»†åˆå¹¶è¿½è¸ªï¼ˆæŠ½æ · {sampleCount} ä¸ªç”¨æˆ·ï¼‰...")
            
            # åŠ è½½ç°æœ‰æ ‡ç­¾æ•°æ®
            if existingTagsDataFrame is None:
                existingTagsDataFrame = self._loadExistingTags()
            
            # æŠ½æ ·é€‰æ‹©æœ‰æ ‡ç­¾çš„ç”¨æˆ·è¿›è¡Œè¿½è¸ª
            sampleUsers = newTagsDataFrame.select("user_id").limit(sampleCount).rdd.map(
                lambda row: row['user_id']
            ).collect()
            
            traceInfo = {
                'sample_users': sampleUsers,
                'merge_details': []
            }
            
            for userId in sampleUsers:
                # è·å–ç”¨æˆ·çš„æ–°æ ‡ç­¾
                newUserTags = newTagsDataFrame.filter(col("user_id") == userId).select("tag_ids").first()
                newTags = newUserTags['tag_ids'] if newUserTags else []
                
                # è·å–ç”¨æˆ·çš„ç°æœ‰æ ‡ç­¾
                existingTags = []
                if existingTagsDataFrame is not None:
                    existingUserTags = existingTagsDataFrame.filter(col("user_id") == userId).select("existing_tag_ids").first()
                    existingTags = existingUserTags['existing_tag_ids'] if existingUserTags else []
                
                # è®¡ç®—åˆå¹¶åæ ‡ç­¾
                mergedTags = list(set(newTags + existingTags)) if existingTags else newTags
                
                userTrace = {
                    'user_id': userId,
                    'new_tags': newTags,
                    'existing_tags': existingTags,
                    'merged_tags': mergedTags
                }
                
                traceInfo['merge_details'].append(userTrace)
                
                self.logger.info(f"   ğŸ‘¤ ç”¨æˆ· {userId}:")
                self.logger.info(f"      ğŸ†• æ–°æ ‡ç­¾: {newTags}")
                self.logger.info(f"      ğŸ“š ç°æœ‰æ ‡ç­¾: {existingTags}")
                self.logger.info(f"      ğŸ”„ åˆå¹¶å: {mergedTags}")
            
            return traceInfo
            
        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆåˆå¹¶è¿½è¸ªå¤±è´¥: {str(e)}")
            return {}
    
    def validateMergeLogic(self, newTagsDataFrame: DataFrame) -> bool:
        """
        éªŒè¯åˆå¹¶é€»è¾‘æ˜¯å¦æ­£ç¡®
        
        Args:
            newTagsDataFrame: æ–°æ ‡ç­¾æ•°æ®
            
        Returns:
            bool: åˆå¹¶é€»è¾‘æ˜¯å¦æ­£ç¡®
        """
        try:
            self.logger.info("ğŸ” éªŒè¯åˆå¹¶é€»è¾‘...")
            
            # æ‰§è¡Œåˆå¹¶
            mergedResult = self.mergeWithExistingTags(newTagsDataFrame)
            
            # åŸºæœ¬éªŒè¯ï¼šåˆå¹¶åç”¨æˆ·æ•°ä¸åº”è¯¥å°‘äºæ–°æ ‡ç­¾ç”¨æˆ·æ•°
            newUserCount = newTagsDataFrame.count()
            mergedUserCount = mergedResult.count()
            
            if mergedUserCount < newUserCount:
                self.logger.error(f"âŒ åˆå¹¶åç”¨æˆ·æ•°å‡å°‘: {newUserCount} -> {mergedUserCount}")
                return False
            
            # éªŒè¯æ ‡ç­¾æ•°ç»„æ ¼å¼
            invalidTags = mergedResult.filter(
                col("tag_ids").isNull() | (size(col("tag_ids")) == 0)
            ).count()
            
            if invalidTags > 0:
                self.logger.error(f"âŒ å‘ç° {invalidTags} ä¸ªç”¨æˆ·çš„æ ‡ç­¾æ•°ç»„æ— æ•ˆ")
                return False
            
            self.logger.info("âœ… åˆå¹¶é€»è¾‘éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ åˆå¹¶é€»è¾‘éªŒè¯å¤±è´¥: {str(e)}")
            return False