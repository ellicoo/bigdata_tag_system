#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MySQLæ•°æ®æºç®¡ç†ç±»
è´Ÿè´£æ ‡ç­¾è§„åˆ™ã€ç°æœ‰æ ‡ç­¾æ•°æ®çš„è¯»å–å’Œæ ‡ç­¾ç»“æœçš„å†™å…¥
"""
import pymysql
from typing import List, Dict, Optional
from pyspark.sql import SparkSession, DataFrame
from pyspark.sql.functions import *
from pyspark.sql.types import *


class MysqlMeta:
    """MySQLæ•°æ®æºç®¡ç†å™¨
    
    èŒè´£ï¼š
    1. åŠ è½½æ ‡ç­¾è§„åˆ™æ•°æ®
    2. åŠ è½½ç°æœ‰ç”¨æˆ·æ ‡ç­¾æ•°æ®
    3. å†™å…¥æ ‡ç­¾è®¡ç®—ç»“æœ
    4. ç®¡ç†MySQLè¿æ¥å’ŒJDBCé…ç½®
    """
    
    def __init__(self, spark: SparkSession, mysqlConfig: Dict[str, str]):
        """åˆå§‹åŒ–MySQLæ•°æ®æºç®¡ç†å™¨
        
        Args:
            spark: Sparkä¼šè¯
            mysqlConfig: MySQLè¿æ¥é…ç½®
        """
        self.spark = spark
        self.mysqlConfig = mysqlConfig
        self.jdbcUrl = self._buildJdbcUrl()
        
        print("ğŸ—„ï¸  MysqlMetaåˆå§‹åŒ–å®Œæˆ")
    
    def _buildJdbcUrl(self) -> str:
        """æ„å»ºJDBCè¿æ¥URL"""
        host = self.mysqlConfig['host']
        port = self.mysqlConfig['port']
        database = self.mysqlConfig['database']
        
        # ä½¿ç”¨connectionCollationå‚æ•°æ”¯æŒutf8mb4ç¼–ç 
        return f"jdbc:mysql://{host}:{port}/{database}?useSSL=false&useUnicode=true&connectionCollation=utf8mb4_unicode_ci&serverTimezone=UTC"
    
    def loadTagRules(self, tagIds: Optional[List[int]] = None) -> DataFrame:
        """åŠ è½½æ ‡ç­¾è§„åˆ™DataFrame
        
        Args:
            tagIds: æŒ‡å®šåŠ è½½çš„æ ‡ç­¾IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºåŠ è½½æ‰€æœ‰æ´»è·ƒæ ‡ç­¾
            
        Returns:
            DataFrame: æ ‡ç­¾è§„åˆ™DataFrameï¼ŒåŒ…å«å­—æ®µï¼štag_id, rule_conditions, tag_name
        """
        print(f"ğŸ“‹ åŠ è½½æ ‡ç­¾è§„åˆ™ï¼ŒæŒ‡å®šæ ‡ç­¾: {tagIds}")
        
        # æ„å»ºæŸ¥è¯¢SQL
        query = """
        (SELECT tr.tag_id, tr.rule_conditions, td.tag_name, td.description
         FROM tag_rules tr
         LEFT JOIN tag_definition td ON tr.tag_id = td.tag_id
         WHERE tr.is_active = 1
        """
        
        if tagIds:
            tagIdsStr = ','.join(map(str, tagIds))
            query += f" AND tr.tag_id IN ({tagIdsStr})"
        
        query += " ORDER BY tr.tag_id) as tag_rules"
        
        try:
            rulesDF = self.spark.read \
                .format("jdbc") \
                .option("url", self.jdbcUrl) \
                .option("dbtable", query) \
                .option("user", self.mysqlConfig['user']) \
                .option("password", self.mysqlConfig['password']) \
                .option("driver", "com.mysql.cj.jdbc.Driver") \
                .load()
            
            print(f"âœ… æ ‡ç­¾è§„åˆ™åŠ è½½å®Œæˆ: {rulesDF.count()} ä¸ªæ ‡ç­¾")
            return rulesDF
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ ‡ç­¾è§„åˆ™å¤±è´¥: {e}")
            return self._createEmptyRulesDataFrame()
    
    def loadExistingTags(self) -> DataFrame:
        """åŠ è½½ç°æœ‰ç”¨æˆ·æ ‡ç­¾DataFrame
        
        Returns:
            DataFrame: ç°æœ‰æ ‡ç­¾DataFrameï¼ŒåŒ…å«å­—æ®µï¼šuser_id, existing_tag_ids(Array)
        """
        print("ğŸ“– åŠ è½½ç°æœ‰ç”¨æˆ·æ ‡ç­¾æ•°æ®...")
        
        query = "(SELECT user_id, tag_ids FROM user_tags WHERE tag_ids IS NOT NULL) as existing_tags"
        
        try:
            existingDF = self.spark.read \
                .format("jdbc") \
                .option("url", self.jdbcUrl) \
                .option("dbtable", query) \
                .option("user", self.mysqlConfig['user']) \
                .option("password", self.mysqlConfig['password']) \
                .option("driver", "com.mysql.cj.jdbc.Driver") \
                .load()
            
            # å¯¼å…¥UDF
            from ..utils.TagUdfs import tagUdfs
            
            # å°†JSONå­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°ç»„
            existingDF = existingDF.withColumn(
                "existing_tag_ids",
                tagUdfs.jsonToArray(col("tag_ids"))
            ).select("user_id", "existing_tag_ids")
            
            print(f"âœ… ç°æœ‰æ ‡ç­¾æ•°æ®åŠ è½½å®Œæˆ: {existingDF.count()} ä¸ªç”¨æˆ·")
            return existingDF
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç°æœ‰æ ‡ç­¾æ•°æ®å¤±è´¥: {e}")
            return self._createEmptyExistingTagsDataFrame()
    
    def writeTagResults(self, resultsDF: DataFrame) -> bool:
        """å†™å…¥æ ‡ç­¾è®¡ç®—ç»“æœåˆ°MySQL
        
        Args:
            resultsDF: ç»“æœDataFrameï¼ŒåŒ…å«å­—æ®µï¼šuser_id, final_tag_ids_json
            
        Returns:
            bool: å†™å…¥æ˜¯å¦æˆåŠŸ
        """
        print("ğŸ’¾ å¼€å§‹å†™å…¥æ ‡ç­¾ç»“æœåˆ°MySQL...")
        
        try:
            # æ”¶é›†ç»“æœåˆ°Driverå†…å­˜
            results = resultsDF.select("user_id", "final_tag_ids_json").collect()
            
            if not results:
                print("âš ï¸  æ²¡æœ‰ç»“æœéœ€è¦å†™å…¥")
                return True
            
            print(f"ğŸ“¤ å‡†å¤‡å†™å…¥ {len(results)} æ¡æ ‡ç­¾è®°å½•...")
            
            # ä½¿ç”¨pymysqlè¿›è¡Œæ‰¹é‡UPSERT
            connection = pymysql.connect(**self.mysqlConfig)
            
            try:
                with connection.cursor() as cursor:
                    upsertSql = """
                    INSERT INTO user_tags (user_id, tag_ids) 
                    VALUES (%s, %s)
                    ON DUPLICATE KEY UPDATE
                        updated_time = CASE 
                            WHEN JSON_EXTRACT(tag_ids, '$') <> JSON_EXTRACT(VALUES(tag_ids), '$')
                            THEN CURRENT_TIMESTAMP 
                            ELSE updated_time 
                        END,
                        tag_ids = VALUES(tag_ids)
                    """
                    
                    # å‡†å¤‡æ‰¹é‡æ•°æ®
                    batchData = [(row['user_id'], row['final_tag_ids_json']) for row in results]
                    
                    # åˆ†æ‰¹æ‰§è¡Œï¼ˆé¿å…å•æ¬¡æ’å…¥è¿‡å¤šæ•°æ®ï¼‰
                    batchSize = 1000
                    successCount = 0
                    
                    for i in range(0, len(batchData), batchSize):
                        batch = batchData[i:i + batchSize]
                        cursor.executemany(upsertSql, batch)
                        successCount += len(batch)
                        
                        if i + batchSize < len(batchData):
                            print(f"   ğŸ“Š å·²å†™å…¥ {successCount}/{len(batchData)} æ¡è®°å½•...")
                    
                    connection.commit()
                    print(f"âœ… æ ‡ç­¾ç»“æœå†™å…¥æˆåŠŸ: {successCount} æ¡è®°å½•")
                    return True
                    
            finally:
                connection.close()
                
        except Exception as e:
            print(f"âŒ å†™å…¥æ ‡ç­¾ç»“æœå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def getTagStatistics(self) -> Dict[str, int]:
        """è·å–æ ‡ç­¾ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            connection = pymysql.connect(**self.mysqlConfig)
            
            try:
                with connection.cursor() as cursor:
                    # ç»Ÿè®¡æ´»è·ƒæ ‡ç­¾æ•°
                    cursor.execute("SELECT COUNT(*) FROM tag_rules WHERE is_active = 1")
                    activeTagCount = cursor.fetchone()[0]
                    
                    # ç»Ÿè®¡æœ‰æ ‡ç­¾çš„ç”¨æˆ·æ•°
                    cursor.execute("SELECT COUNT(*) FROM user_tags WHERE tag_ids IS NOT NULL")
                    taggedUserCount = cursor.fetchone()[0]
                    
                    # ç»Ÿè®¡æ€»ç”¨æˆ·æ ‡ç­¾æ•°
                    cursor.execute("SELECT SUM(JSON_LENGTH(tag_ids)) FROM user_tags WHERE tag_ids IS NOT NULL")
                    totalTagCount = cursor.fetchone()[0] or 0
                    
                    return {
                        "activeTagCount": activeTagCount,
                        "taggedUserCount": taggedUserCount,
                        "totalTagCount": totalTagCount,
                        "avgTagsPerUser": round(totalTagCount / taggedUserCount, 2) if taggedUserCount > 0 else 0
                    }
                    
            finally:
                connection.close()
                
        except Exception as e:
            print(f"âŒ è·å–æ ‡ç­¾ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    def testConnection(self) -> bool:
        """æµ‹è¯•MySQLè¿æ¥
        
        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            connection = pymysql.connect(**self.mysqlConfig)
            connection.close()
            print("âœ… MySQLè¿æ¥æµ‹è¯•æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ MySQLè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def _createEmptyRulesDataFrame(self) -> DataFrame:
        """åˆ›å»ºç©ºçš„æ ‡ç­¾è§„åˆ™DataFrame"""
        schema = StructType([
            StructField("tag_id", IntegerType(), False),
            StructField("rule_conditions", StringType(), True),
            StructField("tag_name", StringType(), True),
            StructField("description", StringType(), True)
        ])
        
        return self.spark.createDataFrame([], schema)
    
    def _createEmptyExistingTagsDataFrame(self) -> DataFrame:
        """åˆ›å»ºç©ºçš„ç°æœ‰æ ‡ç­¾DataFrame"""
        schema = StructType([
            StructField("user_id", StringType(), False),
            StructField("existing_tag_ids", ArrayType(IntegerType()), True)
        ])
        
        return self.spark.createDataFrame([], schema)