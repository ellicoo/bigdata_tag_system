#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MySQLæ•°æ®æºç®¡ç†ç±»
è´Ÿè´£æ ‡ç­¾è§„åˆ™ã€ç°æœ‰æ ‡ç­¾æ•°æ®çš„è¯»å–å’Œæ ‡ç­¾ç»“æœçš„å†™å…¥
"""
import pymysql
from typing import List, Dict, Optional
from pyspark.sql import SparkSession, DataFrame
from pyspark.sql.functions import *
from pyspark.sql.types import *
from ..utils.SparkUdfs import json_to_array


class MysqlMeta:
    """MySQLæ•°æ®æºç®¡ç†å™¨
    
    èŒè´£ï¼š
    1. åŠ è½½æ ‡ç­¾è§„åˆ™æ•°æ®
    2. åŠ è½½ç°æœ‰ç”¨æˆ·æ ‡ç­¾æ•°æ®
    3. å†™å…¥æ ‡ç­¾è®¡ç®—ç»“æœ
    4. ç®¡ç†MySQLè¿æ¥å’ŒJDBCé…ç½®
    """
    
    def __init__(self, spark: SparkSession, mysqlConfig: Dict[str, str]):
        """åˆå§‹åŒ–MySQLæ•°æ®æºç®¡ç†å™¨
        
        Args:
            spark: Sparkä¼šè¯
            mysqlConfig: MySQLè¿æ¥é…ç½®
        """
        self.spark = spark
        self.mysqlConfig = mysqlConfig
        self.jdbcUrl = self._buildJdbcUrl()
        
        print("ğŸ—„ï¸  MysqlMetaåˆå§‹åŒ–å®Œæˆ")
    
    def _buildJdbcUrl(self) -> str:
        """æ„å»ºJDBCè¿æ¥URL"""
        host = self.mysqlConfig['host']
        port = self.mysqlConfig['port']
        database = self.mysqlConfig['database']
        
        # ä½¿ç”¨connectionCollationå‚æ•°æ”¯æŒutf8mb4ç¼–ç 
        return f"jdbc:mysql://{host}:{port}/{database}?useSSL=false&useUnicode=true&connectionCollation=utf8mb4_unicode_ci&serverTimezone=UTC"
    
    def loadTagRules(self, tagIds: Optional[List[int]] = None) -> DataFrame:
        """åŠ è½½æ ‡ç­¾è§„åˆ™DataFrame
        
        Args:
            tagIds: æŒ‡å®šåŠ è½½çš„æ ‡ç­¾IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºåŠ è½½æ‰€æœ‰æ´»è·ƒæ ‡ç­¾
            
        Returns:
            DataFrame: æ ‡ç­¾è§„åˆ™DataFrameï¼ŒåŒ…å«å­—æ®µï¼štag_id, rule_conditions, tag_name
        """
        print(f"ğŸ“‹ åŠ è½½æ ‡ç­¾è§„åˆ™ï¼ŒæŒ‡å®šæ ‡ç­¾: {tagIds}")
        
        # æ„å»ºæŸ¥è¯¢SQL
        query = """
        (SELECT tr.tag_id, tr.rule_conditions, td.tag_name, td.description
         FROM tag_rules tr
         LEFT JOIN tag_definition td ON tr.tag_id = td.tag_id
         WHERE tr.is_active = 1
        """
        
        if tagIds:
            tagIdsStr = ','.join(map(str, tagIds))
            query += f" AND tr.tag_id IN ({tagIdsStr})"
        
        query += " ORDER BY tr.tag_id) as tag_rules"
        
        try:
            rulesDF = self.spark.read \
                .format("jdbc") \
                .option("url", self.jdbcUrl) \
                .option("dbtable", query) \
                .option("user", self.mysqlConfig['user']) \
                .option("password", self.mysqlConfig['password']) \
                .option("driver", "com.mysql.cj.jdbc.Driver") \
                .load()
            
            print(f"âœ… æ ‡ç­¾è§„åˆ™åŠ è½½å®Œæˆ: {rulesDF.count()} ä¸ªæ ‡ç­¾")
            return rulesDF
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ ‡ç­¾è§„åˆ™å¤±è´¥: {e}")
            return self._createEmptyRulesDataFrame()
    
    def loadExistingTags(self) -> DataFrame:
        """åŠ è½½ç°æœ‰ç”¨æˆ·æ ‡ç­¾DataFrame
        
        Returns:
            DataFrame: ç°æœ‰æ ‡ç­¾DataFrameï¼ŒåŒ…å«å­—æ®µï¼šuser_id, existing_tag_ids(Array)
        """
        print("ğŸ“– åŠ è½½ç°æœ‰ç”¨æˆ·æ ‡ç­¾æ•°æ®...")
        
        query = "(SELECT user_id, tag_ids FROM user_tags WHERE tag_ids IS NOT NULL) as existing_tags"
        
        try:
            existingDF = self.spark.read \
                .format("jdbc") \
                .option("url", self.jdbcUrl) \
                .option("dbtable", query) \
                .option("user", self.mysqlConfig['user']) \
                .option("password", self.mysqlConfig['password']) \
                .option("driver", "com.mysql.cj.jdbc.Driver") \
                .load()
            
            # ä½¿ç”¨SparkUdfsæ¨¡å—è½¬æ¢JSONä¸ºArray
            existingDF = existingDF.withColumn(
                "existing_tag_ids",
                json_to_array(col("tag_ids"))
            ).select("user_id", "existing_tag_ids")
            
            print(f"âœ… ç°æœ‰æ ‡ç­¾æ•°æ®åŠ è½½å®Œæˆ: {existingDF.count()} ä¸ªç”¨æˆ·")
            return existingDF
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç°æœ‰æ ‡ç­¾æ•°æ®å¤±è´¥: {e}")
            return self._createEmptyExistingTagsDataFrame()
    
    def writeTagResults(self, resultsDF: DataFrame) -> bool:
        """å†™å…¥æ ‡ç­¾è®¡ç®—ç»“æœåˆ°MySQL - ä¸´æ—¶è¡¨+åŸç”ŸSQLæ–¹æ¡ˆ
        
        ä½¿ç”¨SparkåŸç”ŸJDBCå†™å…¥ä¸´æ—¶è¡¨ï¼Œç„¶åç”¨çº¯SQLæ‰§è¡ŒUPSERT
        å®Œå…¨é¿å…Pythonç‰ˆæœ¬å†²çªé—®é¢˜
        
        Args:
            resultsDF: ç»“æœDataFrameï¼ŒåŒ…å«å­—æ®µï¼šuser_id, final_tag_ids_json
            
        Returns:
            bool: å†™å…¥æ˜¯å¦æˆåŠŸ
        """
        print("ğŸ’¾ å¼€å§‹å†™å…¥æ ‡ç­¾ç»“æœåˆ°MySQLï¼ˆä¸´æ—¶è¡¨+åŸç”ŸSQLæ–¹æ¡ˆï¼‰...")
        
        try:
            # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®éœ€è¦å†™å…¥
            totalCount = resultsDF.count()
            if totalCount == 0:
                print("âš ï¸  æ²¡æœ‰ç»“æœéœ€è¦å†™å…¥")
                return True
            
            print(f"ğŸ“¤ å‡†å¤‡å†™å…¥ {totalCount} æ¡æ ‡ç­¾è®°å½•...")
            
            # ğŸš€ æ­¥éª¤1ï¼šå†™å…¥ä¸´æ—¶è¡¨ï¼ˆåªè¦user_id, final_tag_ids_jsonï¼‰
            import time
            temp_table = f"user_tags_temp_{int(time.time())}"
            print(f"ğŸ“‹ åˆ›å»ºä¸´æ—¶è¡¨: {temp_table}")
            
            # ä½¿ç”¨SparkåŸç”ŸJDBCå†™å…¥ï¼Œå®Œå…¨é¿å…Pythonä»£ç åˆ†å‘
            resultsDF.select("user_id", col("final_tag_ids_json").alias("tag_ids")) \
                .write \
                .format("jdbc") \
                .option("url", self.jdbcUrl) \
                .option("dbtable", temp_table) \
                .option("user", self.mysqlConfig['user']) \
                .option("password", self.mysqlConfig['password']) \
                .option("driver", "com.mysql.cj.jdbc.Driver") \
                .option("createTableOptions", "ENGINE=InnoDB DEFAULT CHARSET=utf8mb4") \
                .mode("overwrite") \
                .save()
            
            print(f"âœ… ä¸´æ—¶è¡¨ {temp_table} å†™å…¥å®Œæˆ")
            
            # ğŸš€ æ­¥éª¤2ï¼šæ‰§è¡ŒUPSERT
            upsert_success = self._executeSimpleUpsert(temp_table, totalCount)
            
            # ğŸš€ æ­¥éª¤3ï¼šæ¸…ç†ä¸´æ—¶è¡¨
            self._dropTempTable(temp_table)
            
            if upsert_success:
                print(f"âœ… æ ‡ç­¾ç»“æœå†™å…¥å®Œæˆ: {totalCount} æ¡è®°å½•")
                return True
            else:
                return False
            
        except Exception as e:
            print(f"âŒ å†™å…¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def testConnection(self) -> bool:
        """æµ‹è¯•MySQLè¿æ¥
        
        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            connection = pymysql.connect(**self.mysqlConfig)
            connection.close()
            print("âœ… MySQLè¿æ¥æµ‹è¯•æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ MySQLè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def _createEmptyRulesDataFrame(self) -> DataFrame:
        """åˆ›å»ºç©ºçš„æ ‡ç­¾è§„åˆ™DataFrame"""
        schema = StructType([
            StructField("tag_id", IntegerType(), False),
            StructField("rule_conditions", StringType(), True),
            StructField("tag_name", StringType(), True),
            StructField("description", StringType(), True)
        ])
        
        return self.spark.createDataFrame([], schema)
    
    def _createEmptyExistingTagsDataFrame(self) -> DataFrame:
        """åˆ›å»ºç©ºçš„ç°æœ‰æ ‡ç­¾DataFrame"""
        schema = StructType([
            StructField("user_id", StringType(), False),
            StructField("existing_tag_ids", ArrayType(IntegerType()), True)
        ])
        
        return self.spark.createDataFrame([], schema)
    
    def _executeSimpleUpsert(self, temp_table: str, record_count: int) -> bool:
        """æ‰§è¡Œç®€å•çš„UPSERTï¼Œåˆ©ç”¨ç°æœ‰çš„user_tagsè¡¨ç»“æ„"""
        print(f"ğŸ”„ æ‰§è¡ŒUPSERTæ“ä½œï¼Œä» {temp_table} åˆ° user_tags...")
        
        try:
            connection = pymysql.connect(**self.mysqlConfig)
            
            with connection.cursor() as cursor:
                # ç®€å•UPSERTï¼Œä¿æŒåŸæœ‰è¡¨ç»“æ„å’Œä¸šåŠ¡é€»è¾‘
                upsert_sql = f"""
                INSERT INTO user_tags (user_id, tag_ids)
                SELECT user_id, tag_ids
                FROM {temp_table}
                ON DUPLICATE KEY UPDATE
                    updated_time = CASE 
                        WHEN JSON_EXTRACT(user_tags.tag_ids, '$') <> JSON_EXTRACT(VALUES(tag_ids), '$')
                        THEN CURRENT_TIMESTAMP 
                        ELSE user_tags.updated_time 
                    END,
                    tag_ids = VALUES(tag_ids)
                """
                
                print(f"   ğŸ“ æ‰§è¡ŒSQL: INSERT INTO user_tags ... FROM {temp_table}")
                cursor.execute(upsert_sql)
                affected_rows = cursor.rowcount
                connection.commit()
                
                print(f"   âœ… UPSERTå®Œæˆï¼Œå½±å“è¡Œæ•°: {affected_rows}")
                return True
                
        except Exception as e:
            print(f"   âŒ UPSERTå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
        finally:
            connection.close()
    
    def _dropTempTable(self, temp_table: str):
        """æ¸…ç†ä¸´æ—¶è¡¨"""
        print(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶è¡¨: {temp_table}")
        
        try:
            connection = pymysql.connect(**self.mysqlConfig)
            
            with connection.cursor() as cursor:
                cursor.execute(f"DROP TABLE IF EXISTS {temp_table}")
                connection.commit()
                print(f"   âœ… ä¸´æ—¶è¡¨ {temp_table} å·²æ¸…ç†")
                
        except Exception as e:
            print(f"   âš ï¸  æ¸…ç†ä¸´æ—¶è¡¨å¤±è´¥: {e}")
        finally:
            connection.close()