import logging
from typing import Dict, Any, List, Optional, Tuple
from pyspark.sql import DataFrame, SparkSession
from pyspark.sql.functions import col, collect_list, array_distinct, struct, lit
from datetime import date
import json

from .tag_computer import TagComputeEngine

logger = logging.getLogger(__name__)


class ParallelTagEngine:
    """å¹¶è¡Œæ ‡ç­¾è®¡ç®—å¼•æ“ - æ”¯æŒå¤šæ ‡ç­¾å¹¶è¡Œè®¡ç®—å’Œå†…å­˜åˆå¹¶"""
    
    def __init__(self, spark: SparkSession, max_workers: int = 4, mysql_config=None):
        self.spark = spark
        self.max_workers = max_workers
        self.mysql_config = mysql_config
        self.tag_engine = TagComputeEngine(spark, max_workers)
    
    def compute_tags_with_memory_merge(self, data_df: DataFrame, rules: List[Dict[str, Any]]) -> Optional[DataFrame]:
        """
        å¤šæ ‡ç­¾å¹¶è¡Œè®¡ç®— + å†…å­˜åˆå¹¶
        
        Args:
            data_df: ç”¨æˆ·æ•°æ®
            rules: æ ‡ç­¾è§„åˆ™åˆ—è¡¨
            
        Returns:
            å†…å­˜åˆå¹¶åçš„ç”¨æˆ·æ ‡ç­¾DataFrame (user_id, tag_ids, tag_details, computed_date)
        """
        try:
            logger.info(f"ğŸš€ å¼€å§‹å¤šæ ‡ç­¾å¹¶è¡Œè®¡ç®—ï¼Œå…± {len(rules)} ä¸ªæ ‡ç­¾")
            
            # 1. å¹¶è¡Œè®¡ç®—æ‰€æœ‰æ ‡ç­¾
            tag_results = self.tag_engine.compute_tags_parallel(data_df, rules)
            
            if not tag_results:
                logger.warning("æ²¡æœ‰ä»»ä½•æ ‡ç­¾è®¡ç®—å‡ºç»“æœ")
                return None
            
            # 2. å†…å­˜åˆå¹¶ï¼šåŒä¸€ç”¨æˆ·çš„å¤šä¸ªæ ‡ç­¾åˆå¹¶ä¸ºä¸€æ¡è®°å½•
            merged_result = self._merge_user_tags_in_memory(tag_results)
            
            logger.info(f"âœ… å¤šæ ‡ç­¾å¹¶è¡Œè®¡ç®—å’Œå†…å­˜åˆå¹¶å®Œæˆ")
            return merged_result
            
        except Exception as e:
            logger.error(f"å¤šæ ‡ç­¾å¹¶è¡Œè®¡ç®—å¤±è´¥: {str(e)}")
            return None
    
    def _merge_user_tags_in_memory(self, tag_results: List[DataFrame]) -> Optional[DataFrame]:
        """å†…å­˜åˆå¹¶ï¼šå°†åŒä¸€ç”¨æˆ·çš„å¤šä¸ªæ ‡ç­¾åˆå¹¶ä¸ºä¸€æ¡è®°å½•"""
        try:
            if not tag_results:
                return None
                
            logger.info(f"å¼€å§‹å†…å­˜åˆå¹¶ {len(tag_results)} ä¸ªæ ‡ç­¾ç»“æœ...")
            
            from functools import reduce
            
            # 1. åˆå¹¶æ‰€æœ‰æ ‡ç­¾ç»“æœ
            all_tags = reduce(lambda df1, df2: df1.union(df2), tag_results)
            
            if all_tags.count() == 0:
                logger.warning("åˆå¹¶åæ²¡æœ‰æ ‡ç­¾æ•°æ®")
                return None
            
            # 2. å»é‡ï¼šç§»é™¤åŒä¸€ç”¨æˆ·çš„é‡å¤æ ‡ç­¾
            deduplicated_tags = all_tags.dropDuplicates(["user_id", "tag_id"])
            
            # 3. ä¸°å¯Œæ ‡ç­¾ä¿¡æ¯
            enriched_tags = self._enrich_with_tag_info(deduplicated_tags)
            
            # 4. æŒ‰ç”¨æˆ·èšåˆï¼šå°†ç”¨æˆ·çš„å¤šä¸ªæ ‡ç­¾åˆå¹¶ä¸ºæ•°ç»„
            user_aggregated = enriched_tags.groupBy("user_id").agg(
                collect_list("tag_id").alias("tag_ids_raw"),
                collect_list(struct("tag_id", "tag_name", "tag_category")).alias("tag_info_list")
            )
            
            # 5. ç¡®ä¿æ ‡ç­¾æ•°ç»„å»é‡
            user_aggregated = user_aggregated.select(
                "user_id",
                array_distinct("tag_ids_raw").alias("tag_ids"),
                "tag_info_list"
            )
            
            # 6. æ ¼å¼åŒ–è¾“å‡º
            final_result = self._format_memory_merge_output(user_aggregated)
            
            logger.info(f"âœ… å†…å­˜åˆå¹¶å®Œæˆï¼Œå½±å“ {final_result.count()} ä¸ªç”¨æˆ·")
            return final_result
            
        except Exception as e:
            logger.error(f"å†…å­˜åˆå¹¶å¤±è´¥: {str(e)}")
            return None
    
    def _enrich_with_tag_info(self, tags_df: DataFrame) -> DataFrame:
        """ä¸°å¯Œæ ‡ç­¾ä¿¡æ¯"""
        try:
            # ä½¿ç”¨ä¼ é€’çš„é…ç½®æˆ–ä»é…ç½®ç®¡ç†å™¨è·å–
            if self.mysql_config:
                mysql_config = self.mysql_config
            else:
                from src.config.manager import ConfigManager
                config = ConfigManager.load_config('local')
                mysql_config = config.mysql
            
            # è¯»å–æ ‡ç­¾å®šä¹‰
            tag_definitions = self.spark.read.jdbc(
                url=mysql_config.jdbc_url,
                table="tag_definition",
                properties=mysql_config.connection_properties
            ).select("tag_id", "tag_name", "tag_category")
            
            # å…³è”æ ‡ç­¾å®šä¹‰ä¿¡æ¯
            enriched_df = tags_df.join(
                tag_definitions,
                "tag_id",
                "left"
            ).select(
                "user_id",
                "tag_id", 
                col("tag_name").alias("tag_name"),
                col("tag_category").alias("tag_category"),
                "tag_detail"
            )
            
            return enriched_df
            
        except Exception as e:
            logger.error(f"ä¸°å¯Œæ ‡ç­¾ä¿¡æ¯å¤±è´¥: {str(e)}")
            # é™çº§å¤„ç†
            return tags_df.select(
                "user_id",
                "tag_id",
                lit("unknown").alias("tag_name"),
                lit("unknown").alias("tag_category"),
                "tag_detail"
            )
    
    def _format_memory_merge_output(self, user_tags_df: DataFrame) -> DataFrame:
        """æ ¼å¼åŒ–å†…å­˜åˆå¹¶è¾“å‡º"""
        from pyspark.sql.functions import udf
        from pyspark.sql.types import StringType
        
        @udf(returnType=StringType())
        def build_tag_details(tag_info_list):
            if not tag_info_list:
                return "{}"
            
            tag_details = {}
            for tag_info in tag_info_list:
                tag_id = str(tag_info['tag_id'])
                tag_details[tag_id] = {
                    'tag_name': tag_info['tag_name'],
                    'tag_category': tag_info['tag_category']
                }
            return json.dumps(tag_details, ensure_ascii=False)
        
        formatted_df = user_tags_df.select(
            col("user_id"),
            col("tag_ids"),
            build_tag_details(col("tag_info_list")).alias("tag_details"),
            lit(date.today()).alias("computed_date")
        )
        
        return formatted_df