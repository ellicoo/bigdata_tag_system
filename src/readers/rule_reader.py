import json
import logging
from typing import List, Dict, Any, Optional
from pyspark.sql import SparkSession, DataFrame
from pyspark import StorageLevel
from src.config.base import MySQLConfig

logger = logging.getLogger(__name__)


class RuleReader:
    """æ ‡ç­¾è§„åˆ™è¯»å–å™¨ - ä½¿ç”¨DataFrame + persistæœºåˆ¶ä¼˜åŒ–æ€§èƒ½"""
    
    def __init__(self, spark: SparkSession, mysql_config: MySQLConfig):
        self.spark = spark
        self.mysql_config = mysql_config
        # ä½¿ç”¨DataFrameç¼“å­˜ï¼Œæ”¯æŒpersistæœºåˆ¶ï¼ˆJOINç»“æœå·²åŒ…å«å®Œæ•´ä¿¡æ¯ï¼‰
        self._rules_df = None  # å·²åŒ…å«æ ‡ç­¾å®šä¹‰ä¿¡æ¯çš„å®Œæ•´è§„åˆ™DataFrame
        self._initialized = False
    
    def initialize(self):
        """ä¸€æ¬¡æ€§åˆå§‹åŒ–æ‰€æœ‰è§„åˆ™æ•°æ®ï¼Œä½¿ç”¨persistç¼“å­˜"""
        if self._initialized:
            logger.info("è§„åˆ™è¯»å–å™¨å·²åˆå§‹åŒ–ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®")
            return
        
        logger.info("ğŸ”„ å¼€å§‹ä¸€æ¬¡æ€§åŠ è½½å®Œæ•´è§„åˆ™æ•°æ®ï¼ˆJOINåŒ…å«æ ‡ç­¾å®šä¹‰ï¼‰...")
        
        try:
            # åŠ è½½æ ‡ç­¾è§„åˆ™ï¼ˆJOINå·²åŒ…å«æ ‡ç­¾å®šä¹‰ï¼Œæ— éœ€å•ç‹¬ç¼“å­˜ï¼‰
            self._load_rules_df()
            
            self._initialized = True
            logger.info("âœ… è§„åˆ™è¯»å–å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ è§„åˆ™è¯»å–å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def _load_rules_df(self):
        """åŠ è½½æ ‡ç­¾è§„åˆ™DataFrameå¹¶persist"""
        logger.info("ğŸ“– åŠ è½½æ ‡ç­¾è§„åˆ™...")
        
        query = """
        (SELECT 
            tr.rule_id,
            tr.tag_id,
            tr.rule_conditions,
            tr.is_active as rule_active,
            td.tag_name,
            td.tag_category,
            td.description as tag_description,
            td.is_active as tag_active
         FROM tag_rules tr 
         JOIN tag_definition td ON tr.tag_id = td.tag_id 
         WHERE tr.is_active = 1 AND td.is_active = 1) as active_rules
        """
        
        self._rules_df = self.spark.read.jdbc(
            url=self.mysql_config.jdbc_url,
            table=query,
            properties=self.mysql_config.connection_properties
        ).persist(StorageLevel.MEMORY_AND_DISK)
        
        # è§¦å‘æŒä¹…åŒ–å¹¶è·å–ç»Ÿè®¡
        rule_count = self._rules_df.count()
        logger.info(f"âœ… å®Œæ•´è§„åˆ™DataFrameå·²persist(å†…å­˜&ç£ç›˜)ï¼Œå…± {rule_count} æ¡ï¼ˆåŒ…å«æ ‡ç­¾å®šä¹‰ï¼‰")
    
    def get_active_rules_df(self) -> DataFrame:
        """è·å–æ´»è·ƒæ ‡ç­¾è§„åˆ™DataFrame"""
        if not self._initialized:
            self.initialize()
        return self._rules_df
    
    def get_tag_definitions_df(self) -> DataFrame:
        """è·å–æ ‡ç­¾å®šä¹‰DataFrame - ç›´æ¥ä»å®Œæ•´è§„åˆ™DataFrameæå–"""
        if not self._initialized:
            self.initialize()
        # ä»å®Œæ•´è§„åˆ™DataFrameä¸­æå–æ ‡ç­¾å®šä¹‰ä¿¡æ¯
        return self._rules_df.select("tag_id", "tag_name", "tag_category", "tag_description").distinct()
    
    def read_active_rules(self) -> List[Dict[str, Any]]:
        """è¯»å–æ‰€æœ‰å¯ç”¨çš„æ ‡ç­¾è§„åˆ™ - å…¼å®¹åŸæ¥å£ï¼Œå†…éƒ¨ä½¿ç”¨DataFrameç¼“å­˜"""
        try:
            # ä½¿ç”¨persistçš„DataFrameï¼Œé¿å…é‡å¤æ•°æ®åº“è¿æ¥
            rules_df = self.get_active_rules_df()
            rules_list = rules_df.collect()
            
            logger.info(f"ä»ç¼“å­˜è·å– {len(rules_list)} æ¡æ´»è·ƒæ ‡ç­¾è§„åˆ™")
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            result = []
            for row in rules_list:
                rule_dict = row.asDict()
                # è§£æJSONè§„åˆ™æ¡ä»¶
                try:
                    rule_dict['rule_conditions'] = json.loads(rule_dict['rule_conditions'])
                except (json.JSONDecodeError, TypeError):
                    logger.warning(f"è§„åˆ™ {rule_dict['rule_id']} çš„æ¡ä»¶æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡")
                    continue
                result.append(rule_dict)
            
            return result
            
        except Exception as e:
            logger.error(f"è¯»å–æ ‡ç­¾è§„åˆ™å¤±è´¥: {str(e)}")
            raise
    
    def read_rules_by_category(self, category_name: str) -> List[Dict[str, Any]]:
        """æŒ‰åˆ†ç±»è¯»å–æ ‡ç­¾è§„åˆ™"""
        all_rules = self.read_active_rules()
        return [rule for rule in all_rules if rule['tag_category'] == category_name]
    
    def get_all_required_fields(self, rules: List[Dict[str, Any]]) -> str:
        """è·å–è§„åˆ™éœ€è¦çš„æ‰€æœ‰å­—æ®µï¼Œç”¨äºæ•°æ®è£å‰ª"""
        fields_set = set(['user_id'])  # user_idæ˜¯å¿…éœ€å­—æ®µ
        
        for rule in rules:
            # ä»è§„åˆ™æ¡ä»¶ä¸­æå–å­—æ®µ
            try:
                conditions = rule['rule_conditions']['conditions']
                for condition in conditions:
                    if 'field' in condition:
                        fields_set.add(condition['field'])
            except (KeyError, TypeError):
                continue
        
        return ','.join(sorted(fields_set))
    
    def group_rules_by_table(self, rules: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """æŒ‰æ•°æ®è¡¨åˆ†ç»„è§„åˆ™ - æ ¹æ®è§„åˆ™æ¡ä»¶ä¸­çš„å­—æ®µæ¨æ–­æ•°æ®æºè¡¨"""
        table_groups = {}
        
        # å®šä¹‰å­—æ®µåˆ°è¡¨çš„æ˜ å°„å…³ç³»
        field_to_table_mapping = {
            # ç”¨æˆ·åŸºæœ¬ä¿¡æ¯è¡¨å­—æ®µ
            'user_id': 'user_basic_info',
            'age': 'user_basic_info', 
            'registration_date': 'user_basic_info',
            'user_level': 'user_basic_info',
            'kyc_status': 'user_basic_info',
            'last_login_date': 'user_basic_info',
            
            # ç”¨æˆ·èµ„äº§æ±‡æ€»è¡¨å­—æ®µ
            'total_asset_value': 'user_asset_summary',
            'cash_balance': 'user_asset_summary',
            'total_deposit_amount': 'user_asset_summary',
            
            # ç”¨æˆ·æ´»åŠ¨æ±‡æ€»è¡¨å­—æ®µ
            'trade_count_30d': 'user_activity_summary',
            'last_30d_trading_volume': 'user_activity_summary',
            'login_count_7d': 'user_activity_summary',
            'risk_score': 'user_activity_summary'
        }
        
        for rule in rules:
            try:
                # åˆ†æè§„åˆ™æ¡ä»¶ä¸­ä½¿ç”¨çš„å­—æ®µ
                conditions = rule['rule_conditions']['conditions']
                rule_tables = set()
                
                for condition in conditions:
                    field = condition.get('field', '')
                    if field in field_to_table_mapping:
                        rule_tables.add(field_to_table_mapping[field])
                
                # å¦‚æœè§„åˆ™è·¨å¤šè¡¨ï¼Œé€‰æ‹©ä¸»è¡¨ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºé€‰æ‹©ç¬¬ä¸€ä¸ªè¡¨ï¼‰
                # åœ¨å®é™…ç”Ÿäº§ä¸­ï¼Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„åˆå¹¶é€»è¾‘
                if rule_tables:
                    primary_table = list(rule_tables)[0]
                else:
                    # é»˜è®¤è¡¨ï¼ˆå¦‚æœæ— æ³•æ¨æ–­ï¼‰
                    primary_table = 'user_basic_info'
                
                if primary_table not in table_groups:
                    table_groups[primary_table] = []
                
                table_groups[primary_table].append(rule)
                
            except (KeyError, TypeError) as e:
                logger.warning(f"è§„åˆ™ {rule.get('rule_id', 'unknown')} åˆ†ç»„å¤±è´¥: {str(e)}")
                # é»˜è®¤åˆ†ç»„
                if 'user_basic_info' not in table_groups:
                    table_groups['user_basic_info'] = []
                table_groups['user_basic_info'].append(rule)
        
        logger.info(f"è§„åˆ™æŒ‰è¡¨åˆ†ç»„ç»“æœ: {[(table, len(rules)) for table, rules in table_groups.items()]}")
        return table_groups
    
    def validate_rule_format(self, rule: Dict[str, Any]) -> bool:
        """éªŒè¯è§„åˆ™æ ¼å¼æ˜¯å¦æ­£ç¡®"""
        required_fields = ['rule_id', 'tag_id', 'rule_conditions', 'tag_name']
        
        for field in required_fields:
            if field not in rule:
                logger.warning(f"è§„åˆ™ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                return False
        
        # éªŒè¯è§„åˆ™æ¡ä»¶æ ¼å¼
        try:
            conditions = rule['rule_conditions']
            if not isinstance(conditions, dict):
                return False
            
            if 'conditions' not in conditions:
                return False
            
            for condition in conditions['conditions']:
                if not all(key in condition for key in ['field', 'operator', 'value']):
                    return False
            
            return True
            
        except Exception as e:
            logger.warning(f"è§„åˆ™æ ¼å¼éªŒè¯å¤±è´¥: {str(e)}")
            return False
    
    def cleanup(self):
        """æ¸…ç†ç¼“å­˜ï¼Œé‡Šæ”¾èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†è§„åˆ™è¯»å–å™¨ç¼“å­˜...")
        
        try:
            if self._rules_df is not None:
                logger.info("ğŸ§¹ é‡Šæ”¾è§„åˆ™DataFrame persistç¼“å­˜")
                self._rules_df.unpersist()
                
            if self._tag_definitions_df is not None:
                logger.info("ğŸ§¹ é‡Šæ”¾æ ‡ç­¾å®šä¹‰DataFrame persistç¼“å­˜")
                self._tag_definitions_df.unpersist()
                
            # æ¸…ç©ºå¼•ç”¨
            self._rules_df = None
            self._tag_definitions_df = None
            self._initialized = False
            
            logger.info("âœ… è§„åˆ™è¯»å–å™¨ç¼“å­˜æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ è§„åˆ™è¯»å–å™¨ç¼“å­˜æ¸…ç†å¼‚å¸¸: {str(e)}")
    
    def get_statistics(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_rules": self._rules_df.count() if self._rules_df else 0,
            "total_tag_definitions": self._tag_definitions_df.count() if self._tag_definitions_df else 0,
            "initialized": self._initialized
        }