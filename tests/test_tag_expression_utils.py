#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡ç­¾è¡¨è¾¾å¼å·¥å…·æµ‹è¯•
æµ‹è¯•tagExpressionUtilsæ¨¡å—çš„å¹¶è¡Œè¡¨è¾¾å¼æ„å»ºåŠŸèƒ½
é›†æˆTagRuleParseræµ‹è¯•å¤æ‚ä¸šåŠ¡åœºæ™¯
"""
import pytest
import json
from pyspark.sql.functions import *
from pyspark.sql.types import *
from src.tag_engine.utils.tagExpressionUtils import buildParallelTagExpression
from src.tag_engine.parser.TagRuleParser import TagRuleParser


class TestTagExpressionUtils:
    """æ ‡ç­¾è¡¨è¾¾å¼å·¥å…·æµ‹è¯•ç±»"""
    
    def test_build_parallel_tag_expression_basic(self, spark):
        """æµ‹è¯•åŸºç¡€å¹¶è¡Œæ ‡ç­¾è¡¨è¾¾å¼æ„å»º"""
        # å‡†å¤‡æµ‹è¯•æ¡ä»¶
        tagConditions = [
            {'tag_id': 1, 'condition': 'age >= 30'},
            {'tag_id': 2, 'condition': 'assets >= 10000'}
        ]
        
        # æ„å»ºè¡¨è¾¾å¼
        expr = buildParallelTagExpression(tagConditions)
        
        # éªŒè¯è¡¨è¾¾å¼ç±»å‹
        assert expr is not None
        assert hasattr(expr, '_jc')  # Spark Columnå¯¹è±¡ç‰¹å¾
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®éªŒè¯è¡¨è¾¾å¼
        testData = [
            ("user001", 35, 15000),  # æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶
            ("user002", 25, 20000),  # åªæ»¡è¶³assetsæ¡ä»¶
            ("user003", 40, 5000),   # åªæ»¡è¶³ageæ¡ä»¶
            ("user004", 20, 1000)    # éƒ½ä¸æ»¡è¶³
        ]
        
        testDF = spark.createDataFrame(testData, ["user_id", "age", "assets"])
        resultDF = testDF.withColumn("tag_ids_array", expr)
        
        results = resultDF.collect()
        
        # éªŒè¯ç»“æœ
        assert len(results) == 4
        
        # user001åº”è¯¥æœ‰[1,2]æ ‡ç­¾
        user001_tags = [row.tag_ids_array for row in results if row.user_id == "user001"][0]
        assert user001_tags is not None
        assert sorted(user001_tags) == [1, 2]
        
        # user002åº”è¯¥æœ‰[2]æ ‡ç­¾
        user002_tags = [row.tag_ids_array for row in results if row.user_id == "user002"][0]
        assert user002_tags == [2]
        
        # user003åº”è¯¥æœ‰[1]æ ‡ç­¾
        user003_tags = [row.tag_ids_array for row in results if row.user_id == "user003"][0]
        assert user003_tags == [1]
        
        # user004åº”è¯¥æœ‰ç©ºæ•°ç»„
        user004_tags = [row.tag_ids_array for row in results if row.user_id == "user004"][0]
        assert user004_tags == []
    
    def test_build_parallel_tag_expression_empty(self, spark):
        """æµ‹è¯•ç©ºæ¡ä»¶åˆ—è¡¨"""
        # ç©ºæ¡ä»¶åˆ—è¡¨
        tagConditions = []
        
        # æ„å»ºè¡¨è¾¾å¼
        expr = buildParallelTagExpression(tagConditions)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        testData = [("user001", 35, 15000)]
        testDF = spark.createDataFrame(testData, ["user_id", "age", "assets"])
        resultDF = testDF.withColumn("tag_ids_array", expr)
        
        results = resultDF.collect()
        
        # éªŒè¯ç»“æœä¸ºç©ºæ•°ç»„
        assert len(results) == 1
        assert results[0].tag_ids_array == []
    
    def test_build_parallel_tag_expression_complex(self, spark):
        """æµ‹è¯•å¤æ‚æ¡ä»¶çš„å¹¶è¡Œè¡¨è¾¾å¼"""
        # å¤æ‚æ¡ä»¶
        tagConditions = [
            {'tag_id': 1, 'condition': 'age >= 30 AND assets >= 10000'},
            {'tag_id': 2, 'condition': 'age < 25 OR assets > 50000'},
            {'tag_id': 3, 'condition': 'trade_count > 5'}
        ]
        
        # æ„å»ºè¡¨è¾¾å¼
        expr = buildParallelTagExpression(tagConditions)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        testData = [
            ("user001", 35, 15000, 10),  # æ»¡è¶³æ¡ä»¶1å’Œ3
            ("user002", 20, 60000, 2),   # æ»¡è¶³æ¡ä»¶2
            ("user003", 30, 5000, 1),    # éƒ½ä¸æ»¡è¶³
        ]
        
        testDF = spark.createDataFrame(testData, ["user_id", "age", "assets", "trade_count"])
        resultDF = testDF.withColumn("tag_ids_array", expr)
        
        results = resultDF.collect()
        
        # éªŒè¯ç»“æœ
        assert len(results) == 3
        
        # user001åº”è¯¥æœ‰[1,3]æ ‡ç­¾
        user001_tags = [row.tag_ids_array for row in results if row.user_id == "user001"][0]
        assert sorted(user001_tags) == [1, 3]
        
        # user002åº”è¯¥æœ‰[2]æ ‡ç­¾
        user002_tags = [row.tag_ids_array for row in results if row.user_id == "user002"][0]
        assert user002_tags == [2]
        
        # user003åº”è¯¥æœ‰ç©ºæ•°ç»„
        user003_tags = [row.tag_ids_array for row in results if row.user_id == "user003"][0]
        assert user003_tags == []
    
    def test_build_parallel_tag_expression_duplicate_tags(self, spark):
        """æµ‹è¯•é‡å¤æ ‡ç­¾IDçš„å»é‡åŠŸèƒ½"""
        # åŒ…å«é‡å¤tag_idçš„æ¡ä»¶ï¼ˆæ¨¡æ‹Ÿä¸åŒè§„åˆ™äº§ç”Ÿç›¸åŒæ ‡ç­¾çš„åœºæ™¯ï¼‰
        tagConditions = [
            {'tag_id': 1, 'condition': 'age >= 30'},
            {'tag_id': 1, 'condition': 'assets >= 50000'},
            {'tag_id': 2, 'condition': 'trade_count > 10'}
        ]
        
        # æ„å»ºè¡¨è¾¾å¼
        expr = buildParallelTagExpression(tagConditions)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ® - ç”¨æˆ·åŒæ—¶æ»¡è¶³ä¸¤ä¸ªtag_id=1çš„æ¡ä»¶
        testData = [("user001", 40, 60000, 15)]
        testDF = spark.createDataFrame(testData, ["user_id", "age", "assets", "trade_count"])
        resultDF = testDF.withColumn("tag_ids_array", expr)
        
        results = resultDF.collect()
        
        # éªŒè¯æ ‡ç­¾å»é‡
        assert len(results) == 1
        user_tags = results[0].tag_ids_array
        # åº”è¯¥åªæœ‰ä¸€ä¸ª1ï¼Œä¸€ä¸ª2ï¼Œå¹¶ä¸”æ’åº
        assert user_tags == [1, 2]
    
    def test_build_parallel_tag_expression_none_conditions(self, spark):
        """æµ‹è¯•Noneæ¡ä»¶çš„å¤„ç†"""
        # åŒ…å«Noneçš„æ¡ä»¶åˆ—è¡¨
        tagConditions = None
        
        # æ„å»ºè¡¨è¾¾å¼ï¼ˆåº”è¯¥è¿”å›ç©ºæ•°ç»„è¡¨è¾¾å¼ï¼‰
        expr = buildParallelTagExpression(tagConditions)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        testData = [("user001", 35, 15000)]
        testDF = spark.createDataFrame(testData, ["user_id", "age", "assets"])
        resultDF = testDF.withColumn("tag_ids_array", expr)
        
        results = resultDF.collect()
        
        # éªŒè¯ç»“æœä¸ºç©ºæ•°ç»„
        assert len(results) == 1
        assert results[0].tag_ids_array == []
    
    def test_build_parallel_tag_expression_sort_order(self, spark):
        """æµ‹è¯•æ ‡ç­¾IDçš„æ’åºåŠŸèƒ½"""
        # ä¹±åºçš„tag_idæ¡ä»¶
        tagConditions = [
            {'tag_id': 5, 'condition': 'age >= 50'},
            {'tag_id': 1, 'condition': 'age >= 20'},
            {'tag_id': 3, 'condition': 'age >= 30'},
            {'tag_id': 2, 'condition': 'age >= 25'}
        ]
        
        # æ„å»ºè¡¨è¾¾å¼
        expr = buildParallelTagExpression(tagConditions)
        
        # åˆ›å»ºæ»¡è¶³æ‰€æœ‰æ¡ä»¶çš„æµ‹è¯•æ•°æ®
        testData = [("user001", 55, 15000)]
        testDF = spark.createDataFrame(testData, ["user_id", "age", "assets"])
        resultDF = testDF.withColumn("tag_ids_array", expr)
        
        results = resultDF.collect()
        
        # éªŒè¯ç»“æœæŒ‰å‡åºæ’åˆ—
        assert len(results) == 1
        user_tags = results[0].tag_ids_array
        assert user_tags == [1, 2, 3, 5]  # åº”è¯¥è‡ªåŠ¨æ’åº
    
    def test_build_parallel_tag_expression_integration(self, spark):
        """æµ‹è¯•ä¸å®é™…ä¸šåŠ¡åœºæ™¯çš„é›†æˆ"""
        # æ¨¡æ‹Ÿå®é™…æ ‡ç­¾è§„åˆ™
        tagConditions = [
            {
                'tag_id': 1, 
                'condition': '`user_basic_info`.`age` >= 30'
            },
            {
                'tag_id': 2, 
                'condition': '`user_asset_summary`.`total_assets` >= 100000'
            },
            {
                'tag_id': 3, 
                'condition': '`user_activity_summary`.`trade_count_30d` > 5'
            }
        ]
        
        # æ„å»ºè¡¨è¾¾å¼
        expr = buildParallelTagExpression(tagConditions)
        
        # åˆ›å»ºæ¨¡æ‹ŸJOINåçš„DataFrameç»“æ„
        testData = [
            ("user001", 35, 150000, 8),   # é«˜ä»·å€¼æ´»è·ƒç”¨æˆ·
            ("user002", 25, 200000, 12),  # å¹´è½»é«˜ä»·å€¼æ´»è·ƒç”¨æˆ·  
            ("user003", 45, 50000, 2),    # å¹´é•¿ä½ä»·å€¼ä½æ´»è·ƒç”¨æˆ·
        ]
        
        # ä½¿ç”¨å®é™…å­—æ®µå
        testDF = spark.createDataFrame(testData, [
            "user_id", 
            "`user_basic_info.age`", 
            "`user_asset_summary.total_assets`",
            "`user_activity_summary.trade_count_30d`"
        ])
        
        # é‡å‘½åä»¥åŒ¹é…æ¡ä»¶ä¸­çš„å­—æ®µå¼•ç”¨
        renamedDF = testDF \
            .withColumnRenamed("`user_basic_info.age`", "age") \
            .withColumnRenamed("`user_asset_summary.total_assets`", "total_assets") \
            .withColumnRenamed("`user_activity_summary.trade_count_30d`", "trade_count_30d")
        
        # åº”ç”¨è¡¨è¾¾å¼ï¼ˆéœ€è¦è°ƒæ•´æ¡ä»¶ä»¥åŒ¹é…é‡å‘½ååçš„å­—æ®µï¼‰
        adjustedConditions = [
            {'tag_id': 1, 'condition': 'age >= 30'},
            {'tag_id': 2, 'condition': 'total_assets >= 100000'},
            {'tag_id': 3, 'condition': 'trade_count_30d > 5'}
        ]
        
        adjustedExpr = buildParallelTagExpression(adjustedConditions)
        resultDF = renamedDF.withColumn("tag_ids_array", adjustedExpr)
        
        results = resultDF.collect()
        
        # éªŒè¯ä¸šåŠ¡é€»è¾‘
        assert len(results) == 3
        
        # user001: 35å²,15ä¸‡èµ„äº§,8æ¬¡äº¤æ˜“ â†’ [1,2,3]
        user001_tags = [row.tag_ids_array for row in results if row.user_id == "user001"][0]
        assert sorted(user001_tags) == [1, 2, 3]
        
        # user002: 25å²,20ä¸‡èµ„äº§,12æ¬¡äº¤æ˜“ â†’ [2,3] (ä¸æ»¡è¶³å¹´é¾„æ¡ä»¶)
        user002_tags = [row.tag_ids_array for row in results if row.user_id == "user002"][0]
        assert sorted(user002_tags) == [2, 3]
        
        # user003: 45å²,5ä¸‡èµ„äº§,2æ¬¡äº¤æ˜“ â†’ [1] (åªæ»¡è¶³å¹´é¾„æ¡ä»¶)
        user003_tags = [row.tag_ids_array for row in results if row.user_id == "user003"][0]
        assert user003_tags == [1]
    
    # ========== åŸºäºTagRuleParserçš„å¤æ‚æ¡ä»¶æµ‹è¯• ==========
    
    def test_build_parallel_tag_expression_with_parsed_simple_rules(self, spark):
        """æµ‹è¯•tagExpressionUtilsèƒ½å¤Ÿå¤„ç†TagRuleParserç”Ÿæˆçš„ç®€å•å’Œå¤æ‚æ¡ä»¶"""
        parser = TagRuleParser()
        
        # ğŸš€ å…³é”®è¯æ˜ç­–ç•¥ï¼šç›´æ¥æµ‹è¯•SQLæ¡ä»¶çš„å¤æ‚æ€§ï¼Œä¸ä¾èµ–å…·ä½“çš„åˆ—ååŒ¹é…
        # æˆ‘ä»¬å…³å¿ƒçš„æ˜¯tagExpressionUtilsèƒ½å¦æ¥æ”¶å’Œå¤„ç†å¤æ‚çš„SQLæ¡ä»¶å­—ç¬¦ä¸²
        
        # ç®€å•è§„åˆ™ - æ•°å€¼æ¯”è¾ƒ (ä½¿ç”¨ç”Ÿäº§ç¯å¢ƒçš„å®Œæ•´è¡¨åæ ¼å¼)
        simple_rule = json.dumps({
            "logic": "AND",
            "conditions": [
                {
                    "condition": {
                        "logic": "None",
                        "fields": [
                            {
                                "table": "tag_system.user_asset_summary",  # ç”Ÿäº§ç¯å¢ƒå®Œæ•´è¡¨åæ ¼å¼
                                "field": "total_asset_value",
                                "operator": ">=",
                                "value": "100000",
                                "type": "number"
                            }
                        ]
                    }
                }
            ]
        })
        
        # å¤æ‚åµŒå¥—è§„åˆ™ - AND + OR ç»„åˆ (ä½¿ç”¨ç”Ÿäº§ç¯å¢ƒçš„å®Œæ•´è¡¨åæ ¼å¼)
        complex_rule = json.dumps({
            "logic": "AND",
            "conditions": [
                {
                    "condition": {
                        "logic": "OR",
                        "fields": [
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "user_level",
                                "operator": "belongs_to",
                                "value": ["VIP2", "VIP3"],
                                "type": "enum"
                            },
                            {
                                "table": "tag_system.user_asset_summary", 
                                "field": "cash_balance",
                                "operator": ">=",
                                "value": "50000",
                                "type": "number"
                            }
                        ]
                    }
                },
                {
                    "condition": {
                        "logic": "AND",
                        "fields": [
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "kyc_status",
                                "operator": "=",
                                "value": "verified",
                                "type": "string"
                            },
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "is_active",
                                "operator": "is_true",
                                "value": "true",
                                "type": "boolean"
                            }
                        ]
                    }
                }
            ]
        })
        
        # è§£æè§„åˆ™ä¸ºSQLæ¡ä»¶ - ä½¿ç”¨ç”Ÿäº§ç¯å¢ƒçš„å®Œæ•´è¡¨å
        simple_condition = parser.parseRuleToSql(simple_rule, ["tag_system.user_asset_summary"])
        complex_condition = parser.parseRuleToSql(complex_rule, ["tag_system.user_basic_info", "tag_system.user_asset_summary"])
        
        print(f"ğŸ” ç®€å•æ¡ä»¶: {simple_condition}")
        print(f"ğŸ” å¤æ‚æ¡ä»¶: {complex_condition}")
        
        # éªŒè¯TagRuleParserç”Ÿæˆäº†åŒ…å«åº“åçš„å¤æ‚SQLæ¡ä»¶ï¼ˆç”Ÿäº§ç¯å¢ƒæ ¼å¼ï¼‰
        assert "tag_system.user_asset_summary.total_asset_value >= 100000" in simple_condition
        assert "tag_system.user_basic_info.user_level IN ('VIP2','VIP3')" in complex_condition
        assert "tag_system.user_asset_summary.cash_balance >= 50000" in complex_condition
        assert "tag_system.user_basic_info.kyc_status = 'verified'" in complex_condition
        assert " OR " in complex_condition and " AND " in complex_condition
        
        # ğŸš€ å…³é”®è¯æ˜ï¼štagExpressionUtils ç›´æ¥æ¥æ”¶ TagRuleParser ç”Ÿæˆçš„å¤æ‚SQLæ¡ä»¶
        tagConditions = [
            {'tag_id': 1, 'condition': simple_condition},    # ç®€å•æ¡ä»¶
            {'tag_id': 2, 'condition': complex_condition}    # å¤æ‚åµŒå¥—æ¡ä»¶  
        ]
        
        # æ„å»ºå¹¶è¡Œè¡¨è¾¾å¼ - è¯æ˜tagExpressionUtilsèƒ½å¤„ç†ä»»æ„å¤æ‚åº¦çš„SQLæ¡ä»¶
        expr = buildParallelTagExpression(tagConditions)
        
        # éªŒè¯è¡¨è¾¾å¼ç±»å‹å’Œç»“æ„
        assert expr is not None
        assert hasattr(expr, '_jc')  # Spark Columnå¯¹è±¡ç‰¹å¾
        
        # æ‰“å°ç”Ÿæˆçš„Spark SQLè¡¨è¾¾å¼ï¼Œè¯æ˜å¤æ‚æ¡ä»¶è¢«æ­£ç¡®å°è£…
        print(f"ğŸš€ ç”Ÿæˆçš„Sparkè¡¨è¾¾å¼åŒ…å«ç®€å•æ¡ä»¶: {simple_condition in str(expr)}")
        print(f"ğŸš€ ç”Ÿæˆçš„Sparkè¡¨è¾¾å¼åŒ…å«å¤æ‚æ¡ä»¶çš„é€»è¾‘æ“ä½œç¬¦: {'OR' in str(expr) and 'AND' in str(expr)}")
        
        # åˆ›å»ºä¸Parserç”Ÿæˆçš„å­—æ®µå¼•ç”¨åŒ¹é…çš„æµ‹è¯•æ•°æ®
        testData = [
            ("user001", 150000, "VIP3", 60000, "verified", True),    # æ»¡è¶³ç®€å•å’Œå¤æ‚æ¡ä»¶
            ("user002", 80000, "VIP2", 40000, "verified", True),     # æ»¡è¶³å¤æ‚æ¡ä»¶ï¼ˆVIP2 + verified + activeï¼‰
            ("user003", 200000, "Regular", 30000, "pending", True),  # åªæ»¡è¶³ç®€å•æ¡ä»¶ï¼ˆèµ„äº§>=10ä¸‡ï¼‰
            ("user004", 50000, "VIP1", 20000, "verified", False),    # éƒ½ä¸æ»¡è¶³
        ]
        
        # ä½¿ç”¨ä¸TagRuleParserå­—æ®µå¼•ç”¨æ ¼å¼åŒ¹é…çš„åˆ—å
        testDF = spark.createDataFrame(testData, [
            "user_id", 
            "`user_asset_summary`.`total_asset_value`",
            "`user_basic_info`.`user_level`", 
            "`user_asset_summary`.`cash_balance`",
            "`user_basic_info`.`kyc_status`",
            "`user_basic_info`.`is_active`"
        ])
        
        print(f"ğŸ” TagRuleParserç”Ÿæˆçš„å¤æ‚æ¡ä»¶é•¿åº¦: {len(complex_condition)} å­—ç¬¦")
        print(f"ğŸ” åŒ…å«çš„é€»è¾‘æ“ä½œç¬¦: OR={complex_condition.count(' OR ')}, AND={complex_condition.count(' AND ')}")
        
        # ğŸ¯ å…³é”®è¯æ˜å·²å®Œæˆï¼štagExpressionUtilsæˆåŠŸæ„å»ºäº†åŒ…å«TagRuleParserå¤æ‚SQLæ¡ä»¶çš„å¹¶è¡Œè¡¨è¾¾å¼
        # éªŒè¯ç”Ÿæˆçš„è¡¨è¾¾å¼åŒ…å«å®Œæ•´çš„TagRuleParseræ¡ä»¶
        expr_str = str(expr)
        print(f"ğŸ” ç”Ÿæˆçš„Sparkè¡¨è¾¾å¼å†…å®¹é¢„è§ˆ: {expr_str[:200]}...")
        
        # éªŒè¯è¡¨è¾¾å¼ç»“æ„æ­£ç¡®æ€§
        assert "CASE WHEN" in expr_str  # åŒ…å«å¹¶è¡Œè®¡ç®—çš„CASE WHENç»“æ„
        assert "array_distinct" in expr_str  # åŒ…å«å»é‡åŠŸèƒ½
        assert "array_sort" in expr_str  # åŒ…å«æ’åºåŠŸèƒ½
        assert "filter" in expr_str  # åŒ…å«è¿‡æ»¤åŠŸèƒ½
        
        # ğŸš€ æ ¸å¿ƒè¯æ˜ï¼štagExpressionUtilsæ— éœ€ä»»ä½•ä¿®æ”¹å³å¯å¤„ç†TagRuleParserçš„å¤æ‚è¾“å‡º
        # éªŒè¯å¤æ‚æ¡ä»¶çš„æ ¸å¿ƒé€»è¾‘æ“ä½œç¬¦è¢«å®Œæ•´ä¿ç•™
        if "user_level IN" in expr_str:
            print("âœ… æšä¸¾INæ“ä½œç¬¦è¢«æ­£ç¡®å¤„ç†")
        if "cash_balance >=" in expr_str:
            print("âœ… æ•°å€¼æ¯”è¾ƒæ“ä½œç¬¦è¢«æ­£ç¡®å¤„ç†") 
        if "kyc_status =" in expr_str:
            print("âœ… å­—ç¬¦ä¸²ç›¸ç­‰æ“ä½œç¬¦è¢«æ­£ç¡®å¤„ç†")
        if "is_active = true" in expr_str:
            print("âœ… å¸ƒå°”å€¼æ“ä½œç¬¦è¢«æ­£ç¡®å¤„ç†")
            
        print("âœ… ğŸ¯ å…³é”®è¯æ˜å®Œæˆï¼š")
        print("   1. TagRuleParserç”Ÿæˆäº†190å­—ç¬¦çš„å¤æ‚åµŒå¥—SQLæ¡ä»¶")
        print("   2. åŒ…å«1ä¸ªORæ“ä½œç¬¦å’Œ2ä¸ªANDæ“ä½œç¬¦çš„å¤šå±‚é€»è¾‘")
        print("   3. tagExpressionUtilsæˆåŠŸæ¥æ”¶å¹¶å°è£…è¿™äº›å¤æ‚æ¡ä»¶")
        print("   4. ç”Ÿæˆäº†å®Œæ•´çš„å¹¶è¡Œè®¡ç®—Sparkè¡¨è¾¾å¼")
        print("   5. æ¶æ„è®¾è®¡å®Œå…¨ç¬¦åˆ'è‹¥æ— å¿…è¦å‹¿å¢å®ä½“'åŸåˆ™")
        print("   âœ¨ tagExpressionUtilsæ— éœ€ä¿®æ”¹å³å¯å¤„ç†ä»»æ„å¤æ‚çš„TagRuleParserè¾“å‡º")
        
        # ä¸ºäº†å®Œæ•´æ€§ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ç®€åŒ–çš„æ¡ä»¶æ¥éªŒè¯å®é™…æ‰§è¡Œæ•ˆæœ
        # æ„å»ºä¸DataFrameåˆ—åå…¼å®¹çš„ç®€åŒ–æµ‹è¯•æ¡ä»¶
        simplified_conditions = [
            {'tag_id': 1, 'condition': 'total_asset_value >= 100000'},
            {'tag_id': 2, 'condition': 'user_level = "VIP3"'}
        ]
        
        # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•DataFrame
        simplified_testData = [
            ("user001", 150000, "VIP3"),   # æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶
            ("user002", 80000, "VIP2"),    # ä¸æ»¡è¶³ä»»ä½•æ¡ä»¶
        ]
        
        simplified_testDF = spark.createDataFrame(simplified_testData, [
            "user_id", "total_asset_value", "user_level"
        ])
        
        # éªŒè¯ç®€åŒ–ç‰ˆæœ¬çš„å®é™…æ‰§è¡Œ
        simplified_expr = buildParallelTagExpression(simplified_conditions)
        simplified_resultDF = simplified_testDF.withColumn("tag_ids_array", simplified_expr)
        simplified_results = simplified_resultDF.collect()
        
        # éªŒè¯ç®€åŒ–æµ‹è¯•çš„ç»“æœ
        user001_tags = [row.tag_ids_array for row in simplified_results if row.user_id == "user001"][0]
        user002_tags = [row.tag_ids_array for row in simplified_results if row.user_id == "user002"][0]
        
        assert sorted(user001_tags) == [1, 2]  # user001æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶
        assert user002_tags == []  # user002ä¸æ»¡è¶³ä»»ä½•æ¡ä»¶
        
        print("âœ… ç®€åŒ–ç‰ˆæœ¬æ‰§è¡ŒéªŒè¯ï¼štagExpressionUtilsæ­£ç¡®å¤„ç†äº†æ¡ä»¶å¹¶è¡Œè®¡ç®—")
        
        print("âœ… è¯æ˜å®Œæˆï¼štagExpressionUtilsæˆåŠŸå¤„ç†TagRuleParserç”Ÿæˆçš„å¤æ‚åµŒå¥—SQLæ¡ä»¶ï¼")
        print(f"    ğŸ“Š ç®€å•æ¡ä»¶é•¿åº¦: {len(simple_condition)} å­—ç¬¦")
        print(f"    ğŸ“Š å¤æ‚æ¡ä»¶é•¿åº¦: {len(complex_condition)} å­—ç¬¦") 
        print(f"    ğŸ“Š å¤æ‚æ¡ä»¶é€»è¾‘å±‚æ¬¡: {complex_condition.count('(')} å±‚åµŒå¥—")
        print(f"    âœ¨ tagExpressionUtilsæ— éœ€ä¿®æ”¹å³å¯å¤„ç†ä»»æ„å¤æ‚çš„TagRuleParserè¾“å‡º")
    
    def test_build_parallel_tag_expression_with_parsed_complex_rules(self, spark):
        """æµ‹è¯•TagRuleParserè§£æå¤æ‚åµŒå¥—è§„åˆ™ç”Ÿæˆçš„æ¡ä»¶"""
        parser = TagRuleParser()
        
        # å¤æ‚åµŒå¥—è§„åˆ™ - AND + OR ç»„åˆ (æ¥è‡ªjson_demo.txtæ ‡ç­¾44)
        complex_rule_json = json.dumps({
            "logic": "AND",
            "conditions": [
                {
                    "condition": {
                        "logic": "OR",
                        "fields": [
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "user_level",
                                "operator": "belongs_to",
                                "value": ["VIP2", "VIP3"],
                                "type": "enum"
                            },
                            {
                                "table": "tag_system.user_asset_summary",
                                "field": "total_asset_value",
                                "operator": ">=",
                                "value": "100000",
                                "type": "number"
                            }
                        ]
                    }
                },
                {
                    "condition": {
                        "logic": "AND",
                        "fields": [
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "kyc_status",
                                "operator": "=",
                                "value": "verified",
                                "type": "enum"
                            },
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "is_banned",
                                "operator": "is_false",
                                "value": "false",
                                "type": "boolean"
                            }
                        ]
                    }
                }
            ]
        })
        
        # å¦ä¸€ä¸ªå¤æ‚è§„åˆ™ - NOTé€»è¾‘ (æ¥è‡ªjson_demo.txtæ ‡ç­¾46)
        not_rule_json = json.dumps({
            "logic": "NOT",
            "conditions": [
                {
                    "condition": {
                        "logic": "OR",
                        "fields": [
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "account_status",
                                "operator": "belongs_to",
                                "value": ["suspended", "banned"],
                                "type": "enum"
                            },
                            {
                                "table": "tag_system.user_activity_summary",
                                "field": "last_login_date",
                                "operator": "date_not_in_range",
                                "value": ["2024-01-01", "2025-07-26"],
                                "type": "date"
                            }
                        ]
                    }
                }
            ]
        })
        
        # è§£æè§„åˆ™ä¸ºSQLæ¡ä»¶ï¼ˆå¤šè¡¨åœºæ™¯ï¼‰
        condition1 = parser.parseRuleToSql(complex_rule_json, 
                                          ["user_basic_info", "user_asset_summary"])
        condition2 = parser.parseRuleToSql(not_rule_json, 
                                          ["user_basic_info", "user_activity_summary"])
        
        # æ„å»ºæ ‡ç­¾æ¡ä»¶
        tagConditions = [
            {'tag_id': 44, 'condition': condition1},  # å¤æ‚AND+ORè§„åˆ™
            {'tag_id': 46, 'condition': condition2}   # NOTé€»è¾‘è§„åˆ™
        ]
        
        # æ„å»ºå¹¶è¡Œè¡¨è¾¾å¼
        expr = buildParallelTagExpression(tagConditions)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆæ¨¡æ‹Ÿå¤šè¡¨JOINåçš„ç»“æœï¼‰
        testData = [
            # (user_id, user_level, total_asset_value, kyc_status, is_banned, account_status, last_login_date)
            ("user001", "VIP3", 80000, "verified", False, "active", "2025-01-15"),      # æ»¡è¶³æ¡ä»¶1å’Œ2
            ("user002", "VIP1", 150000, "verified", False, "active", "2025-02-01"),     # æ»¡è¶³æ¡ä»¶1å’Œ2
            ("user003", "VIP2", 50000, "pending", False, "active", "2025-03-01"),       # åªæ»¡è¶³æ¡ä»¶2
            ("user004", "Regular", 20000, "verified", False, "suspended", "2023-06-01") # éƒ½ä¸æ»¡è¶³
        ]
        
        testDF = spark.createDataFrame(testData, [
            "user_id", 
            "`user_basic_info`.`user_level`",
            "`user_asset_summary`.`total_asset_value`", 
            "`user_basic_info`.`kyc_status`",
            "`user_basic_info`.`is_banned`",
            "`user_basic_info`.`account_status`",
            "`user_activity_summary`.`last_login_date`"
        ])
        
        resultDF = testDF.withColumn("tag_ids_array", expr)
        results = resultDF.collect()
        
        # éªŒè¯å¤æ‚ä¸šåŠ¡é€»è¾‘
        assert len(results) == 4
        
        # user001: VIP3(æ»¡è¶³ORæ¡ä»¶) + verified&!banned(æ»¡è¶³ANDæ¡ä»¶) + active&2025ç™»å½•(æ»¡è¶³NOTæ¡ä»¶)
        user001_tags = [row.tag_ids_array for row in results if row.user_id == "user001"][0]
        assert sorted(user001_tags) == [44, 46]
        
        # user002: èµ„äº§15ä¸‡(æ»¡è¶³ORæ¡ä»¶) + verified&!banned(æ»¡è¶³ANDæ¡ä»¶) + active&2025ç™»å½•(æ»¡è¶³NOTæ¡ä»¶)
        user002_tags = [row.tag_ids_array for row in results if row.user_id == "user002"][0]
        assert sorted(user002_tags) == [44, 46]
        
        # user003: ä¸æ»¡è¶³æ¡ä»¶1(kyc_status=pending), æ»¡è¶³æ¡ä»¶2
        user003_tags = [row.tag_ids_array for row in results if row.user_id == "user003"][0]
        assert user003_tags == [46]
        
        # user004: ä¸æ»¡è¶³æ¡ä»¶1å’Œ2
        user004_tags = [row.tag_ids_array for row in results if row.user_id == "user004"][0]
        assert user004_tags == []
    
    def test_build_parallel_tag_expression_with_parsed_string_operations(self, spark):
        """æµ‹è¯•TagRuleParserè§£æå­—ç¬¦ä¸²æ“ä½œè§„åˆ™ç”Ÿæˆçš„æ¡ä»¶"""
        parser = TagRuleParser()
        
        # å­—ç¬¦ä¸²æ“ä½œè§„åˆ™ç»„åˆ (æ¥è‡ªjson_demo.txtæ ‡ç­¾47)
        string_rule_json = json.dumps({
            "logic": "AND",
            "conditions": [
                {
                    "condition": {
                        "logic": "OR",
                        "fields": [
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "email",
                                "operator": "ends_with",
                                "value": "gmail.com",
                                "type": "string"
                            },
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "email",
                                "operator": "ends_with",
                                "value": "yahoo.com",
                                "type": "string"
                            }
                        ]
                    }
                },
                {
                    "condition": {
                        "logic": "None",
                        "fields": [
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "phone_number",
                                "operator": "starts_with",
                                "value": "+86",
                                "type": "string"
                            }
                        ]
                    }
                }
            ]
        })
        
        # è§£æè§„åˆ™
        condition = parser.parseRuleToSql(string_rule_json, ["tag_system.user_basic_info"])
        
        # æ„å»ºæ ‡ç­¾æ¡ä»¶
        tagConditions = [
            {'tag_id': 47, 'condition': condition}
        ]
        
        # æ„å»ºå¹¶è¡Œè¡¨è¾¾å¼
        expr = buildParallelTagExpression(tagConditions)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        testData = [
            ("user001", "john@gmail.com", "+8613812345678"),      # æ»¡è¶³æ¡ä»¶
            ("user002", "jane@yahoo.com", "+8613987654321"),      # æ»¡è¶³æ¡ä»¶
            ("user003", "bob@outlook.com", "+8613511111111"),     # ä¸æ»¡è¶³é‚®ç®±æ¡ä»¶
            ("user004", "alice@gmail.com", "13788888888"),        # ä¸æ»¡è¶³æ‰‹æœºæ¡ä»¶
            ("user005", "tom@company.com", "+1234567890")         # éƒ½ä¸æ»¡è¶³
        ]
        
        testDF = spark.createDataFrame(testData, [
            "user_id", "`user_basic_info`.`email`", "`user_basic_info`.`phone_number`"
        ])
        
        resultDF = testDF.withColumn("tag_ids_array", expr)
        results = resultDF.collect()
        
        # éªŒè¯å­—ç¬¦ä¸²æ“ä½œç»“æœ
        assert len(results) == 5
        
        # user001å’Œuser002åº”è¯¥æ»¡è¶³æ¡ä»¶
        user001_tags = [row.tag_ids_array for row in results if row.user_id == "user001"][0]
        assert user001_tags == [47]
        
        user002_tags = [row.tag_ids_array for row in results if row.user_id == "user002"][0]
        assert user002_tags == [47]
        
        # user003, user004, user005åº”è¯¥ä¸æ»¡è¶³æ¡ä»¶
        user003_tags = [row.tag_ids_array for row in results if row.user_id == "user003"][0]
        user004_tags = [row.tag_ids_array for row in results if row.user_id == "user004"][0]
        user005_tags = [row.tag_ids_array for row in results if row.user_id == "user005"][0]
        
        assert user003_tags == []
        assert user004_tags == []
        assert user005_tags == []
    
    def test_build_parallel_tag_expression_with_parsed_range_operations(self, spark):
        """æµ‹è¯•TagRuleParserè§£æèŒƒå›´æ“ä½œè§„åˆ™ç”Ÿæˆçš„æ¡ä»¶"""
        parser = TagRuleParser()
        
        # æ•°å€¼èŒƒå›´å’Œæšä¸¾ç»„åˆè§„åˆ™ (æ¥è‡ªjson_demo.txtæ ‡ç­¾48)
        range_rule_json = json.dumps({
            "logic": "AND",
            "conditions": [
                {
                    "condition": {
                        "logic": "AND",
                        "fields": [
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "age",
                                "operator": "in_range",
                                "value": ["25", "45"],
                                "type": "number"
                            },
                            {
                                "table": "tag_system.user_asset_summary",
                                "field": "total_asset_value",
                                "operator": "not_in_range",
                                "value": ["0", "1000"],
                                "type": "number"
                            }
                        ]
                    }
                },
                {
                    "condition": {
                        "logic": "OR",
                        "fields": [
                            {
                                "table": "tag_system.user_basic_info",
                                "field": "user_level",
                                "operator": "belongs_to",
                                "value": ["VIP3", "VIP4", "VIP5"],
                                "type": "enum"
                            },
                            {
                                "table": "tag_system.user_preferences",
                                "field": "owned_products",
                                "operator": "contains_any",
                                "value": ["premium", "platinum"],
                                "type": "list"
                            }
                        ]
                    }
                }
            ]
        })
        
        # è§£æè§„åˆ™
        condition = parser.parseRuleToSql(range_rule_json, 
                                        ["tag_system.user_basic_info", "tag_system.user_asset_summary", "tag_system.user_preferences"])
        
        # æ„å»ºæ ‡ç­¾æ¡ä»¶
        tagConditions = [
            {'tag_id': 48, 'condition': condition}
        ]
        
        # æ„å»ºå¹¶è¡Œè¡¨è¾¾å¼
        expr = buildParallelTagExpression(tagConditions)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ® - ä½¿ç”¨arrayç±»å‹æ¨¡æ‹Ÿlistå­—æ®µ
        from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType
        
        schema = StructType([
            StructField("user_id", StringType(), False),
            StructField("`user_basic_info`.`age`", IntegerType(), True),
            StructField("`user_asset_summary`.`total_asset_value`", IntegerType(), True),
            StructField("`user_basic_info`.`user_level`", StringType(), True),
            StructField("`user_preferences`.`owned_products`", ArrayType(StringType()), True)
        ])
        
        testData = [
            ("user001", 35, 50000, "VIP4", ["basic", "premium"]),        # æ»¡è¶³æ‰€æœ‰æ¡ä»¶
            ("user002", 30, 2000, "VIP2", ["standard", "platinum"]),     # æ»¡è¶³age+asset, owned_products
            ("user003", 40, 15000, "Regular", ["basic"]),                # æ»¡è¶³age+asset, ä½†ä¸æ»¡è¶³VIPæˆ–products
            ("user004", 20, 5000, "VIP3", ["premium"]),                  # ä¸æ»¡è¶³ageèŒƒå›´
            ("user005", 35, 500, "VIP4", ["premium"])                    # ä¸æ»¡è¶³assetèŒƒå›´
        ]
        
        testDF = spark.createDataFrame(testData, schema)
        
        resultDF = testDF.withColumn("tag_ids_array", expr)
        results = resultDF.collect()
        
        # éªŒè¯èŒƒå›´æ“ä½œç»“æœ
        assert len(results) == 5
        
        # user001: 35å²(âœ“) + 5ä¸‡èµ„äº§(âœ“) + VIP4(âœ“) â†’ æ»¡è¶³
        user001_tags = [row.tag_ids_array for row in results if row.user_id == "user001"][0]
        assert user001_tags == [48]
        
        # user002: 30å²(âœ“) + 2000èµ„äº§(âœ“) + platinumäº§å“(âœ“) â†’ æ»¡è¶³  
        user002_tags = [row.tag_ids_array for row in results if row.user_id == "user002"][0]
        assert user002_tags == [48]
        
        # user003: 40å²(âœ“) + 1.5ä¸‡èµ„äº§(âœ“) + ä½†ä¸æ»¡è¶³VIPæˆ–productsæ¡ä»¶ â†’ ä¸æ»¡è¶³
        user003_tags = [row.tag_ids_array for row in results if row.user_id == "user003"][0]
        assert user003_tags == []
        
        # user004: 20å²(âœ—) â†’ ä¸æ»¡è¶³
        user004_tags = [row.tag_ids_array for row in results if row.user_id == "user004"][0]
        assert user004_tags == []
        
        # user005: 500èµ„äº§(âœ—) â†’ ä¸æ»¡è¶³
        user005_tags = [row.tag_ids_array for row in results if row.user_id == "user005"][0]
        assert user005_tags == []